import json
import os

from openai import OpenAI
from functions import get_weather, python_inter, tools_dict, sql_inter, write_file


def call_tools(client, model, tool_call_messages, user_messages, tools, available_tools):
    # å¤šå·¥å…·è°ƒç”¨
    for tool_call_message in tool_call_messages:
        # è·å–å‡½æ•°å
        function_name = tool_call_message.function.name
        # è·å–å‡½æ•°å‚æ•°
        function_args = json.loads(tool_call_message.function.arguments)
        # è·å–å‡½æ•°å¯¹è±¡
        function_to_call = available_tools[function_name]

        # æ¨¡å‹è°ƒç”¨äº†å·¥å…·
        print("\n>>>>>>>>>> ğŸ”§ å·¥å…·è°ƒç”¨ ğŸ”§ >>>>>>>>>>")
        print(f"Function nameï¼š{tool_call_message.function.name}")
        print(f"Function argsï¼š{tool_call_message.function.arguments}")
        print("<<<<<<<<<< ğŸ”§ å·¥å…·è°ƒç”¨ ğŸ”§ <<<<<<<<<<\n")

        # å°†å‡½æ•°å‚æ•°è¾“å…¥åˆ°å‡½æ•°ä¸­ï¼Œè·å–å‡½æ•°è¿”å›å€¼
        try:
            function_response = function_to_call(**function_args)
        except Exception as e:
            function_response = f"å‡½æ•°è¿è¡ŒæŠ¥é”™ï¼š{str(e)}"

        # messages ä¸­è¿½åŠ  tool response æ¶ˆæ¯
        user_messages.append(
            {
                "role": "tool",
                "content": function_response,
                "tool_call_id": tool_call_message.id,
            }
        )

    # å·¥å…·è°ƒç”¨ç»“æŸï¼Œæ­¤æ—¶å†æ¬¡è°ƒç”¨æ¨¡å‹ï¼Œè·å–ä¸‹ä¸€æ¬¡å¯¹è¯çš„å“åº”
    next_response = client.chat.completions.create(
        model=model,
        messages=user_messages,
        tools=tools,
    )
    next_message = next_response.choices[0].message
    # å°†ä¸‹ä¸€æ¬¡å¯¹è¯çš„å“åº”æ·»åŠ åˆ° messages ä¸­
    user_messages.append(next_message.model_dump())

    # è¿”å›æ¨¡å‹çš„å“åº”
    return next_response


def run_conv(messages: list[dict],
             api_key,
             model="deepseek-chat",
             base_url="https://api.deepseek.com/v1",
             tools=None,
             function_list=None) -> str:
    """
    èƒ½å¤Ÿè‡ªåŠ¨æ‰§è¡Œå¤–éƒ¨å‡½æ•°è°ƒç”¨çš„ Chat å¯¹è¯æ¨¡æ¿ï¼ŒåŒæ—¶æ”¯æŒå·¥å…·å¹¶è¡Œå’Œä¸²è¡Œçš„è°ƒç”¨
    :param messages: å¿…è¦å‚æ•°ï¼Œæ¶ˆæ¯åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†å²
    :param api_key: å¿…è¦å‚æ•°ï¼Œè°ƒç”¨æ¨¡å‹çš„ API Key
    :param model: å¯é€‰å‚æ•°ï¼Œæ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º "deepseek-chat"
    :param base_url: å¿…è¦å‚æ•°ï¼Œè°ƒç”¨æ¨¡å‹çš„ Base URL
    :param tools: å¯é€‰å‚æ•°ï¼Œå·¥å…·åˆ—è¡¨ï¼Œç”¨äºæŒ‡å®šæ¨¡å‹å¯ä»¥è°ƒç”¨çš„å·¥å…·åˆ—è¡¨ï¼Œé»˜è®¤ä¸º None
    :param function_list: å¯é€‰å‚æ•°ï¼Œå‡½æ•°åˆ—è¡¨ï¼Œç”¨äºæŒ‡å®šæ¨¡å‹å¯ä»¥è°ƒç”¨çš„å¤–éƒ¨å‡½æ•°åˆ—è¡¨ï¼Œé»˜è®¤ä¸º None
    :return: è¿”å›æ¨¡å‹çš„å“åº”å¯¹è±¡
    """
    user_messages = messages

    client = OpenAI(api_key=api_key, base_url=base_url)

    # å¦‚æœæ²¡æœ‰å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™æ‰§è¡Œæ™®é€šçš„å¯¹è¯ä»»åŠ¡
    if tools is None or function_list is None:
        response = client.chat.completions.create(
            model=model,
            messages=user_messages,
        )
        final_response = response.choices[0].message.content
    # å¦‚æœå­˜åœ¨å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™éœ€è¦çµæ´»é€‰å–å¤–éƒ¨å‡½æ•°è¿›è¡Œå›ç­”
    else:
        # åˆ›å»ºå¤–éƒ¨å‡½æ•°åº“å­—å…¸
        available_tools = {func.__name__: func for func in function_list}

        # ç¬¬ä¸€æ¬¡è°ƒç”¨æ¨¡å‹
        current_response = client.chat.completions.create(
            model=model,
            messages=user_messages,
            tools=tools,
            tool_choice="auto",
        )
        # å¦‚æœæ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œåˆ™ç›´æ¥è¿”å›æ¨¡å‹çš„å“åº”
        tool_calls = current_response.choices[0].message.tool_calls
        if len(tool_calls) == 0:
            final_response = current_response.choices[0].message.content
            return f"Assistant: {final_response}"

        # æ­¤æ—¶çš„æ¶ˆæ¯æ˜¯ä¸€ä¸ª tool_calls æ¶ˆæ¯
        response_message = current_response.choices[0].message
        # messages ä¸­è¿½åŠ  tool_calls æ¶ˆæ¯ï¼Œ
        user_messages.append(response_message.model_dump())

        # æœ€ç»ˆçš„å“åº”ç»“æœ
        final_response = None
        while True:
            next_response = call_tools(client, model, tool_calls, user_messages, tools, available_tools)
            # æ¨¡å‹ä¾ç„¶éœ€è¦è°ƒç”¨å·¥å…·ï¼ˆå·¥å…·ä¸²è¡Œçš„æƒ…å†µï¼‰
            if next_response.choices[0].finish_reason == "tool_calls":
                tool_calls = next_response.choices[0].message.tool_calls
            # å¦‚æœæ¨¡å‹ä¸éœ€è¦å†è°ƒç”¨å·¥å…·ï¼Œåˆ™ç›´æ¥è¿”å›æ¨¡å‹çš„å“åº”
            else:
                # æœ€ç»ˆå“åº”
                final_response = next_response.choices[0].message.content
                break

    return f"Assistant: {final_response}"


available_tools = [get_weather, python_inter, sql_inter, write_file]

tools_schema = [tools_dict["get_weather"], tools_dict["python_inter"], tools_dict["sql_inter"], tools_dict["write_file"]]

if __name__ == "__main__":
    api_key = os.getenv("DEEPSEEK_API_KEY") or input("è¯·è¾“å…¥ API Keyï¼š")

    # messages = [
    #     {"role": "user", "content": "åˆè‚¥çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}
    # ]
    # response = run_conv(messages, api_key=api_key, tools=tools_schema, function_list=available_tools)
    # print(response)

    # messages = [
    #     {"role": "user", "content": "å¸®æˆ‘ç”¨ python ä»£ç æ¨¡æ‹Ÿä¸€ç»„æ•°æ®ï¼Œç”Ÿæˆä¸€ä¸ªè‚¡å¸‚ K çº¿å›¾"}
    # ]
    # response = run_conv(messages, api_key=api_key, tools=tools_schema, function_list=available_tools)
    # print(response)

    # messages = [
    #     {"role": "user", "content": "æŸ¥è¯¢ä¸€ä¸‹å½“å‰æ•°æ®åº“æœ‰å“ªäº›è¡¨ï¼Ÿ"}
    # ]
    # response = run_conv(messages, api_key=api_key, tools=tools_schema, function_list=available_tools)
    # print(response)

    # messages = [
    #     {"role": "user", "content": "åˆè‚¥çš„å¤©æ°”å¦‚ä½•ï¼Œå¹¶æŸ¥è¯¢ä¸€ä¸‹å½“å‰æ•°æ®åº“æœ‰å“ªäº›è¡¨ï¼Ÿ"}
    # ]
    # response = run_conv(messages, api_key=api_key, tools=tools_schema, function_list=available_tools)
    # print(response)

    messages = [
        {"role": "user", "content": "æŸ¥è¯¢åˆè‚¥çš„å¤©æ°”ï¼Œå¹¶å†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶ï¼Ÿ"}
    ]
    # response = run_conv(messages, api_key=api_key, model="qwen2.5:7b", base_url="http://127.0.0.1:11434/v1", tools=tools_schema, function_list=available_tools)
    response = run_conv(messages, api_key=api_key, tools=tools_schema, function_list=available_tools)
    print(response)