{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 第5章 LangChain多任务应用开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 学习目标\n",
    "\n",
    "1. 如何使用 LangChain：一套在大模型能力上封装的工具框架\n",
    "2. 如何用几行代码实现一个复杂的 AI 应用\n",
    "3. 面向大模型的流程开发的过程抽象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写在前面\n",
    "\n",
    "- LangChain 也是一套面向大模型的开发框架（SDK）\n",
    "- LangChain 是 AGI 时代软件工程的一个探索和原型\n",
    "- 学习 LangChain 要关注接口变更\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 的核心组件\n",
    "\n",
    "1. 模型 I/O 封装\n",
    "   - Chat Models：对语言模型接口的封装\n",
    "   - PromptTemple：提示词模板\n",
    "   - OutputParser：解析输出\n",
    "2. 数据连接封装（弱于 LlamaIndex）\n",
    "   - Document Loaders：各种格式文件的加载器\n",
    "   - Document Transformers：对文档的常用操作，如：split, filter, translate, extract metadata, etc\n",
    "   - Text Embedding Models：文本向量化表示，用于检索等操作\n",
    "   - Verctorstores & Retrievers：向量数据库与向量检索\n",
    "3. 架构封装\n",
    "   - Chain/LCEL：实现一个功能或者一系列顺序功能组合\n",
    "   - Agent：根据用户输入，自动规划执行步骤，自动选择每步需要的工具，最终完成用户指定的功能\n",
    "     - Tools：调用外部功能的函数，例如：调 google 搜索、文件 I/O、Linux Shell 等等\n",
    "   - LangGraph：工作流开发框架\n",
    "5. LangSmith：过程监控与调试框架\n",
    "\n",
    "<img src=\"./assets/langchain.svg\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档（以 Python 版为例）\n",
    "\n",
    "- 功能模块：https://python.langchain.com/docs/tutorials\n",
    "- API 文档：https://python.langchain.com/api_reference/\n",
    "- 三方组件集成：https://python.langchain.com/docs/integrations/providers/\n",
    "- 更多 HowTo：https://python.langchain.com/docs/how_to/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain 是开源项目\n",
    "\n",
    "项目地址：https://github.com/langchain-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 模型 I/O 封装\n",
    "\n",
    "把不同的模型，统一封装成一个接口，方便更换模型而不用重构代码。\n",
    "\n",
    "### 1.1 模型 API: ChatModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 OpenAI 模型封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain\n",
    "# !pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI助手，旨在回答问题和提供信息。如果你有什么想问的，或者需要帮助的，请告诉我！\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "response = model.invoke(\"你是谁\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 多轮对话 Session 封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是学员小聚。很高兴与你交流！有什么问题或者需要帮助的地方吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,  # 等价于OpenAI接口中的assistant role\n",
    "    HumanMessage,  # 等价于OpenAI接口中的user role\n",
    "    SystemMessage  # 等价于OpenAI接口中的system role\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是聚客AI大模型课的课程助理。\"),\n",
    "    HumanMessage(content=\"我是学员，我叫小聚。\"),\n",
    "    AIMessage(content=\"欢迎！\"),\n",
    "    HumanMessage(content=\"我是谁？\")\n",
    "]\n",
    "\n",
    "ret = model.invoke(messages)\n",
    "\n",
    "print(ret.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>通过模型封装，实现不同模型的统一接口调用\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 换个国产模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T04:36:30.159790Z",
     "start_time": "2025-05-22T04:36:22.823501Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "response = model.invoke(\"你是谁\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是DeepSeek Chat，由深度求索公司（DeepSeek）开发的智能AI助手！✨ 我的使命是帮助你解答问题、提供信息、陪你聊天，还能帮你处理各种文本、文件内容。无论是学习、工作，还是日常生活中的疑问，我都会尽力帮你找到答案！😊  \n",
      "\n",
      "有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 流式输出"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T04:55:05.392587Z",
     "start_time": "2025-05-22T04:54:56.464027Z"
    }
   },
   "source": [
    "for token in model.stream(\"你是谁\"):\n",
    "    print(token.content, end=\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是DeepSeek Chat，由深度求索公司（DeepSeek）开发的智能AI助手！✨ 我的目标是为你提供各种问题的解答、知识分享、创意灵感以及日常帮助。无论是学习、工作，还是生活中的小烦恼，都可以来问我哦！😊  \n",
      "\n",
      "有什么我可以帮你的吗？"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型的输入与输出\n",
    "\n",
    "<img src=\"./assets/model_io.jpg\" style=\"margin-left: 0px\" width=1400px>\n",
    "\n",
    "#### 1.2.1 Prompt 模板封装\n",
    "\n",
    "1. PromptTemplate 可以在模板中自定义变量\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T05:59:17.550488Z",
     "start_time": "2025-05-22T05:59:17.515387Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"给我讲个关于{subject}的笑话\")\n",
    "print(\"===Template===\")\n",
    "print(template)\n",
    "print(\"===Prompt===\")\n",
    "print(template.format(subject='小明'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Template===\n",
      "input_variables=['subject'] input_types={} partial_variables={} template='给我讲个关于{subject}的笑话'\n",
      "===Prompt===\n",
      "给我讲个关于小明的笑话\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:04:42.822385Z",
     "start_time": "2025-05-22T06:04:32.491089Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 定义 LLM\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "# 通过 Prompt 调用 LLM\n",
    "ret = llm.invoke(template.format(subject='小明'))\n",
    "# 打印输出\n",
    "print(ret.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的！来一个关于小明的经典校园笑话：\n",
      "\n",
      "**数学课的疑问**  \n",
      "数学老师问小明：“如果你有5块巧克力，妈妈又给你3块，爸爸给你2块，最后你分给妹妹4块，还剩多少？”  \n",
      "\n",
      "小明认真回答：“**零块**。”  \n",
      "\n",
      "老师皱眉：“你根本没算对！”  \n",
      "小明委屈：“可如果妹妹没拿到4块，我现在应该正在医院抢救……”  \n",
      "\n",
      "（笑点：小明理解的“分给妹妹”是“不给她就会挨揍”，而老师只想考减法😂）  \n",
      "\n",
      "需要其他类型的小明笑话还可以再问我哦！\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ChatPromptTemplate 用模板表示的对话上下文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是聚客AI大模型课程的客服助手。你的名字叫小聚', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁', additional_kwargs={}, response_metadata={})]\n",
      "我是小聚，聚客AI大模型课程的客服助手。如果你有任何问题或者需要帮助，随时可以问我！\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "open_ai_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"你是{product}的客服助手。你的名字叫{name}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    product=\"聚客AI大模型课程\",\n",
    "    name=\"小聚\",\n",
    "    query=\"你是谁\"\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "ret = open_ai_llm.invoke(prompt)\n",
    "\n",
    "print(ret.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MessagesPlaceholder 把多轮对话变成模板\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:04:49.188267Z",
     "start_time": "2025-05-22T06:04:49.185357Z"
    }
   },
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "human_prompt = \"Translate your answer to {language}.\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    # variable_name 是 message placeholder 在模板中的变量名\n",
    "    # 用于在赋值时使用\n",
    "    [human_message_template, MessagesPlaceholder(\"history\")]\n",
    ")\n",
    "\n",
    "chat_prompt.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Translate your answer to \u001B[33;1m\u001B[1;3m{language}\u001B[0m.\n",
      "\n",
      "=============================\u001B[1m Messages Placeholder \u001B[0m=============================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{history}\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:04:54.700094Z",
     "start_time": "2025-05-22T06:04:54.697276Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "human_message = HumanMessage(content=\"Who is Elon Musk?\")\n",
    "ai_message = AIMessage(\n",
    "    content=\"Elon Musk is a billionaire entrepreneur, inventor, and industrial designer\"\n",
    ")\n",
    "\n",
    "messages = chat_prompt.format_prompt(\n",
    "    # 对 \"history\" 和 \"language\" 赋值\n",
    "    history=[human_message, ai_message], language=\"中文\"\n",
    ")\n",
    "\n",
    "print(messages.to_messages())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Translate your answer to 中文.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Who is Elon Musk?', additional_kwargs={}, response_metadata={}), AIMessage(content='Elon Musk is a billionaire entrepreneur, inventor, and industrial designer', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:05:02.594793Z",
     "start_time": "2025-05-22T06:04:57.737099Z"
    }
   },
   "source": [
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "埃隆·马斯克（Elon Musk）是一位亿万富翁企业家、发明家和工业设计师。\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>把Prompt模板看作带有参数的函数\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 从文件加载 Prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:06:15.945237Z",
     "start_time": "2025-05-22T06:06:15.942466Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_file(\"example_prompt_template.txt\")\n",
    "print(\"===Template===\")\n",
    "print(template)\n",
    "print(\"===Prompt===\")\n",
    "print(template.format(topic='黑色幽默'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Template===\n",
      "input_variables=['topic'] input_types={} partial_variables={} template='举一个关于{topic}的例子'\n",
      "===Prompt===\n",
      "举一个关于黑色幽默的例子\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 结构化输出\n",
    "\n",
    "#### 1.3.1 直接输出 Pydantic 对象"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:11:03.857175Z",
     "start_time": "2025-05-22T06:11:03.854203Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# 定义你的输出对象\n",
    "class Date(BaseModel):\n",
    "    year: int = Field(description=\"Year\")\n",
    "    month: int = Field(description=\"Month\")\n",
    "    day: int = Field(description=\"Day\")\n",
    "    era: str = Field(description=\"BC or AD\")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T06:13:45.109189Z",
     "start_time": "2025-05-22T06:13:17.514928Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "# llm = ChatTongyi(model=\"qwen-max\")\n",
    "\n",
    "# 定义结构化输出的模型\n",
    "structured_llm = llm.with_structured_output(Date)\n",
    "\n",
    "template = \"\"\"提取用户输入中的日期。\n",
    "用户输入:\n",
    "{query}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "query = \"2023年四月6日天气晴...\"\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "\n",
    "response = structured_llm.invoke(input_prompt)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year=2023 month=4 day=6 era='AD'\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 输出指定格式的 JSON"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:15:59.255282Z",
     "start_time": "2025-05-22T06:15:56.591453Z"
    }
   },
   "source": [
    "# OpenAI 模型的JSON格式\n",
    "json_schema = {\n",
    "    \"title\": \"Date\",\n",
    "    \"description\": \"Formated date expression\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"year\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"year, YYYY\",\n",
    "        },\n",
    "        \"month\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"month, MM\",\n",
    "        },\n",
    "        \"day\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"day, DD\",\n",
    "        },\n",
    "        \"era\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"BC or AD\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "structured_llm.invoke(input_prompt)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 2023, 'month': 4, 'day': 6, 'era': 'AD'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 使用 OutputParser\n",
    "\n",
    "[`OutputParser`](https://python.langchain.com/v0.2/docs/concepts/#output-parsers) 可以按指定格式解析模型的输出"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:18:39.648626Z",
     "start_time": "2025-05-22T06:18:24.631461Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Date)\n",
    "\n",
    "# 获取格式说明\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"提取用户输入中的日期。\\n用户输入:{query}\\n{format_instructions}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "print(format_instructions)\n",
    "\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "output = llm.invoke(input_prompt)\n",
    "print(\"原始输出:\\n\" + output.content)\n",
    "\n",
    "print(\"\\n解析后:\")\n",
    "parser.invoke(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"year\": {\"description\": \"Year\", \"title\": \"Year\", \"type\": \"integer\"}, \"month\": {\"description\": \"Month\", \"title\": \"Month\", \"type\": \"integer\"}, \"day\": {\"description\": \"Day\", \"title\": \"Day\", \"type\": \"integer\"}, \"era\": {\"description\": \"BC or AD\", \"title\": \"Era\", \"type\": \"string\"}}, \"required\": [\"year\", \"month\", \"day\", \"era\"]}\n",
      "```\n",
      "原始输出:\n",
      "根据用户输入“2023年四月6日天气晴...”，我们可以提取出日期信息并按照给定的JSON Schema格式化输出。从这个句子中，我们可以看出年份是2023年，月份是四月（4月），日期是6日。由于没有特别指明是公元前还是公元后，我们默认为公元（AD）。\n",
      "\n",
      "基于这些信息，以下是符合要求的JSON实例：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"year\": 2023,\n",
      "  \"month\": 4,\n",
      "  \"day\": 6,\n",
      "  \"era\": \"AD\"\n",
      "}\n",
      "```\n",
      "\n",
      "这段JSON表示了用户提到的具体日期，并且满足了提供的JSON Schema的要求。\n",
      "\n",
      "解析后:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'year': 2023, 'month': 4, 'day': 6, 'era': 'AD'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以用 `PydanticOutputParser`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:25:50.626144Z",
     "start_time": "2025-05-22T06:25:34.264170Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# 解析成对象\n",
    "parser = PydanticOutputParser(pydantic_object=Date)\n",
    "\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "output = llm.invoke(input_prompt)\n",
    "print(\"原始输出:\\n\" + output.content)\n",
    "\n",
    "print(\"\\n解析后:\")\n",
    "parser.invoke(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输出:\n",
      "根据用户输入\"2023年四月6日天气晴...\"，我们可以提取出日期信息，并按照给定的JSON Schema格式化输出。这里我们假设所有提到的日期都是公元（AD）纪年的。提取的信息包括年、月、日。因此，对于这个例子，输出将是：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"year\": 2023,\n",
      "  \"month\": 4,\n",
      "  \"day\": 6,\n",
      "  \"era\": \"AD\"\n",
      "}\n",
      "```\n",
      "\n",
      "这符合提供的JSON Schema要求，其中包含了必须的`year`, `month`, `day`字段以及指定了时代的`era`字段。在这个场景下，“era”被设置为\"AD\"表示公元纪年。\n",
      "\n",
      "解析后:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date(year=2023, month=4, day=6, era='AD')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OutputFixingParser` 利用大模型做格式自动纠错"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T06:57:38.922382Z",
     "start_time": "2025-05-22T06:57:33.779607Z"
    }
   },
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "# 纠错能力与大模型能力相关\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "bad_output = output.content.replace(\"4\", \"四\")\n",
    "print(\"PydanticOutputParser:\")\n",
    "try:\n",
    "    parser.invoke(bad_output)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"OutputFixingParser:\")\n",
    "new_parser.invoke(bad_output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PydanticOutputParser:\n",
      "Invalid json output: 根据用户输入\"2023年四月6日天气晴...\"，我们可以提取出日期信息，并按照给定的JSON Schema格式化输出。这里我们假设所有提到的日期都是公元（AD）纪年的。提取的信息包括年、月、日。因此，对于这个例子，输出将是：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"year\": 2023,\n",
      "  \"month\": 四,\n",
      "  \"day\": 6,\n",
      "  \"era\": \"AD\"\n",
      "}\n",
      "```\n",
      "\n",
      "这符合提供的JSON Schema要求，其中包含了必须的`year`, `month`, `day`字段以及指定了时代的`era`字段。在这个场景下，“era”被设置为\"AD\"表示公元纪年。\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "OutputFixingParser:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date(year=2023, month=4, day=6, era='AD')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:10:53.638968Z",
     "start_time": "2025-05-22T07:10:53.627727Z"
    }
   },
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"The sum of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiplication of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:11:03.872945Z",
     "start_time": "2025-05-22T07:10:58.076202Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "query = \"3.5的4倍是多少?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "output = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(json.dumps(output.tool_calls, indent=4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"multiply\",\n",
      "        \"args\": {\n",
      "            \"a\": 3.5,\n",
      "            \"b\": 4\n",
      "        },\n",
      "        \"id\": \"call_0_028ca877-9d59-4581-af32-72765449f185\",\n",
      "        \"type\": \"tool_call\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回传 Funtion Call 的结果"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:11:41.264009Z",
     "start_time": "2025-05-22T07:11:37.074367Z"
    }
   },
   "source": [
    "messages.append(output)\n",
    "\n",
    "available_tools = {\"add\": add, \"multiply\": multiply}\n",
    "\n",
    "for tool_call in output.tool_calls:\n",
    "    selected_tool = available_tools[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "new_output = llm_with_tools.invoke(messages)\n",
    "for message in messages:\n",
    "    print(json.dumps(message.model_dump(), indent=4, ensure_ascii=False))\n",
    "print(new_output.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"3.5的4倍是多少?\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {},\n",
      "    \"type\": \"human\",\n",
      "    \"name\": null,\n",
      "    \"id\": null,\n",
      "    \"example\": false\n",
      "}\n",
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "            {\n",
      "                \"id\": \"call_0_028ca877-9d59-4581-af32-72765449f185\",\n",
      "                \"function\": {\n",
      "                    \"arguments\": \"{\\\"a\\\":3.5,\\\"b\\\":4}\",\n",
      "                    \"name\": \"multiply\"\n",
      "                },\n",
      "                \"type\": \"function\",\n",
      "                \"index\": 0\n",
      "            }\n",
      "        ],\n",
      "        \"refusal\": null\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 24,\n",
      "            \"prompt_tokens\": 250,\n",
      "            \"total_tokens\": 274,\n",
      "            \"completion_tokens_details\": null,\n",
      "            \"prompt_tokens_details\": {\n",
      "                \"audio_tokens\": null,\n",
      "                \"cached_tokens\": 0\n",
      "            },\n",
      "            \"prompt_cache_hit_tokens\": 0,\n",
      "            \"prompt_cache_miss_tokens\": 250\n",
      "        },\n",
      "        \"model_name\": \"deepseek-chat\",\n",
      "        \"system_fingerprint\": \"fp_8802369eaa_prod0425fp8\",\n",
      "        \"id\": \"ce5626e9-633b-42dc-aecf-9803389b2069\",\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run--a8cb773e-c3fb-4515-b821-cfc7275e3001-0\",\n",
      "    \"example\": false,\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"name\": \"multiply\",\n",
      "            \"args\": {\n",
      "                \"a\": 3.5,\n",
      "                \"b\": 4\n",
      "            },\n",
      "            \"id\": \"call_0_028ca877-9d59-4581-af32-72765449f185\",\n",
      "            \"type\": \"tool_call\"\n",
      "        }\n",
      "    ],\n",
      "    \"invalid_tool_calls\": [],\n",
      "    \"usage_metadata\": {\n",
      "        \"input_tokens\": 250,\n",
      "        \"output_tokens\": 24,\n",
      "        \"total_tokens\": 274,\n",
      "        \"input_token_details\": {\n",
      "            \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {}\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"content\": \"14.0\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {},\n",
      "    \"type\": \"tool\",\n",
      "    \"name\": \"multiply\",\n",
      "    \"id\": null,\n",
      "    \"tool_call_id\": \"call_0_028ca877-9d59-4581-af32-72765449f185\",\n",
      "    \"artifact\": null,\n",
      "    \"status\": \"success\"\n",
      "}\n",
      "3.5的4倍是14.0。\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 小结\n",
    "\n",
    "1. LangChain 统一封装了各种模型的调用接口，包括补全型和对话型两种\n",
    "2. LangChain 提供了 PromptTemplate 类，可以自定义带变量的模板\n",
    "3. LangChain 提供了一些列输出解析器，用于将大模型的输出解析成结构化对象\n",
    "4. LangChain 提供了 Function Calling 的封装\n",
    "5. 上述模型属于 LangChain 中较为实用的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据连接封装\n",
    "\n",
    "<img src=\"./assets/data_connection.jpg\" style=\"margin-left: 0px\" width=1400px>\n",
    "\n",
    "### 2.1 文档加载器：Document Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:14:23.878143Z",
     "start_time": "2025-05-23T02:14:23.811686Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(pages[0].page_content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Accuracy / Percentile (%)\n",
      "75.9\n",
      "59.1\n",
      "90.2\n",
      "39.2\n",
      "51.6\n",
      "42.0\n",
      "66.2\n",
      "41.3\n",
      "74.7\n",
      "16.7\n",
      "35.6\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3\n",
      "24.8\n",
      "23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3\n",
      "DeepSeek-V2.5\n",
      "Qwen2.5-72B-Inst\n",
      "Llama-3.1-405B-Inst\n",
      "GPT-4o-0513\n",
      "Claude-3.5-Sonnet-1022\n",
      "Figure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\n",
      "arXiv:2412.19437v2  [cs.CL]  18 Feb 2025\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 文档处理器\n",
    "\n",
    "#### 2.2.1 TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:14:29.216045Z",
     "start_time": "2025-05-23T02:14:29.213882Z"
    }
   },
   "source": [
    "# !pip install --upgrade langchain-text-splitters"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T02:14:43.616176Z",
     "start_time": "2025-05-23T02:14:43.613620Z"
    }
   },
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "paragraphs = text_splitter.create_documents([pages[0].page_content])\n",
    "for para in paragraphs:\n",
    "    print(para.page_content)\n",
    "    print('-------')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "-------\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "-------\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "-------\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "-------\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Accuracy / Percentile (%)\n",
      "75.9\n",
      "59.1\n",
      "90.2\n",
      "39.2\n",
      "51.6\n",
      "42.0\n",
      "66.2\n",
      "41.3\n",
      "74.7\n",
      "16.7\n",
      "35.6\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3\n",
      "24.8\n",
      "23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3\n",
      "DeepSeek-V2.5\n",
      "Qwen2.5-72B-Inst\n",
      "Llama-3.1-405B-Inst\n",
      "GPT-4o-0513\n",
      "-------\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3\n",
      "24.8\n",
      "23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3\n",
      "DeepSeek-V2.5\n",
      "Qwen2.5-72B-Inst\n",
      "Llama-3.1-405B-Inst\n",
      "GPT-4o-0513\n",
      "Claude-3.5-Sonnet-1022\n",
      "Figure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\n",
      "arXiv:2412.19437v2  [cs.CL]  18 Feb 2025\n",
      "-------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "类似 LlamaIndex，LangChain 也提供了丰富的 <code><a href=\"https://python.langchain.com/v0.2/docs/how_to/#document-loaders\">Document Loaders</a></code> 和 <code><a href=\"https://python.langchain.com/v0.2/docs/how_to/#text-splitters\">Text Splitters</a></code>。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3、向量数据库与向量检索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dashscope\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:18:44.677001Z",
     "start_time": "2025-05-23T09:18:43.219315Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 加载文档\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# 文档切分\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(\n",
    "    [page.page_content for page in pages[:1]]\n",
    ")\n",
    "\n",
    "# 灌库\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\", dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "index = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 检索 top-5 结果\n",
    "retriever = index.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "docs = retriever.invoke(\"deepseek v3有多少参数\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"----\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3\n",
      "24.8\n",
      "23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3\n",
      "DeepSeek-V2.5\n",
      "Qwen2.5-72B-Inst\n",
      "Llama-3.1-405B-Inst\n",
      "GPT-4o-0513\n",
      "Claude-3.5-Sonnet-1022\n",
      "Figure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\n",
      "arXiv:2412.19437v2  [cs.CL]  18 Feb 2025\n",
      "----\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "----\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "----\n",
      "DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "----\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多的三方检索组件链接，参考：https://python.langchain.com/docs/integrations/vectorstores/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 小结\n",
    "\n",
    "1. 文档处理部分，建议在实际应用中详细测试后使用\n",
    "2. 与向量数据库的链接部分本质是接口封装，向量数据库需要自己选型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chain 和 LangChain Expression Language (LCEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Expression Language（LCEL）是一种声明式语言，可轻松组合不同的调用顺序构成 Chain。LCEL 自创立之初就被设计为能够支持将原型投入生产环境，**无需代码更改**，从最简单的“提示+LLM”链到最复杂的链（已有用户成功在生产环境中运行包含数百个步骤的 LCEL Chain）。\n",
    "\n",
    "LCEL 的一些亮点包括：\n",
    "\n",
    "1. **流支持**：使用 LCEL 构建 Chain 时，你可以获得最佳的首个令牌时间（即从输出开始到首批输出生成的时间）。对于某些 Chain，这意味着可以直接从 LLM 流式传输令牌到流输出解析器，从而以与 LLM 提供商输出原始令牌相同的速率获得解析后的、增量的输出。\n",
    "\n",
    "2. **异步支持**：任何使用 LCEL 构建的链条都可以通过同步 API（例如，在 Jupyter 笔记本中进行原型设计时）和异步 API（例如，在 LangServe 服务器中）调用。这使得相同的代码可用于原型设计和生产环境，具有出色的性能，并能够在同一服务器中处理多个并发请求。\n",
    "\n",
    "3. **优化的并行执行**：当你的 LCEL 链条有可以并行执行的步骤时（例如，从多个检索器中获取文档），我们会自动执行，无论是在同步还是异步接口中，以实现最小的延迟。\n",
    "\n",
    "4. **重试和回退**：为 LCEL 链的任何部分配置重试和回退。这是使链在规模上更可靠的绝佳方式。目前我们正在添加重试/回退的流媒体支持，因此你可以在不增加任何延迟成本的情况下获得增加的可靠性。\n",
    "\n",
    "5. **访问中间结果**：对于更复杂的链条，访问在最终输出产生之前的中间步骤的结果通常非常有用。这可以用于让最终用户知道正在发生一些事情，甚至仅用于调试链条。你可以流式传输中间结果，并且在每个 LangServe 服务器上都可用。\n",
    "\n",
    "6. **输入和输出模式**：输入和输出模式为每个 LCEL 链提供了从链的结构推断出的 Pydantic 和 JSONSchema 模式。这可以用于输入和输出的验证，是 LangServe 的一个组成部分。\n",
    "\n",
    "7. **无缝 LangSmith 跟踪集成**：随着链条变得越来越复杂，理解每一步发生了什么变得越来越重要。通过 LCEL，所有步骤都自动记录到 LangSmith，以实现最大的可观察性和可调试性。\n",
    "\n",
    "8. **无缝 LangServe 部署集成**：任何使用 LCEL 创建的链都可以轻松地使用 LangServe 进行部署。\n",
    "\n",
    "原文：https://python.langchain.com/docs/expression_language/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pipeline 式调用 PromptTemplate, LLM 和 OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:23:17.521450Z",
     "start_time": "2025-05-23T09:23:17.439305Z"
    }
   },
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "import json\n",
    "from langchain.chat_models import init_chat_model"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T09:32:35.215997Z",
     "start_time": "2025-05-23T09:32:28.240792Z"
    }
   },
   "source": [
    "# 输出结构\n",
    "class SortEnum(str, Enum):\n",
    "    data = 'data'\n",
    "    price = 'price'\n",
    "\n",
    "\n",
    "class OrderingEnum(str, Enum):\n",
    "    ascend = 'ascend'\n",
    "    descend = 'descend'\n",
    "\n",
    "\n",
    "class Semantics(BaseModel):\n",
    "    name: Optional[str] = Field(description=\"流量包名称\", default=None)\n",
    "    price_lower: Optional[int] = Field(description=\"价格下限\", default=None)\n",
    "    price_upper: Optional[int] = Field(description=\"价格上限\", default=None)\n",
    "    data_lower: Optional[int] = Field(description=\"流量下限\", default=None)\n",
    "    data_upper: Optional[int] = Field(description=\"流量上限\", default=None)\n",
    "    sort_by: Optional[SortEnum] = Field(description=\"按价格或流量排序\", default=None)\n",
    "    ordering: Optional[OrderingEnum] = Field(\n",
    "        description=\"升序或降序排列\", default=None)\n",
    "\n",
    "\n",
    "# Prompt 模板\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个语义解析器。你的任务是将用户的输入解析成JSON表示。不要回答用户的问题。\"),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 模型\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Semantics)\n",
    "\n",
    "# LCEL 表达式\n",
    "runnable = (\n",
    "        {\"text\": RunnablePassthrough()} | prompt | structured_llm\n",
    ")\n",
    "\n",
    "# 直接运行\n",
    "ret = runnable.invoke(\"不超过100元的流量大的套餐有哪些\")\n",
    "print(\n",
    "    json.dumps(\n",
    "        ret.model_dump(),\n",
    "        indent=4,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": null,\n",
      "    \"price_lower\": null,\n",
      "    \"price_upper\": 100,\n",
      "    \"data_lower\": null,\n",
      "    \"data_upper\": null,\n",
      "    \"sort_by\": \"data\",\n",
      "    \"ordering\": \"descend\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>使用 LCEL 的价值，也就是 LangChain 的核心价值。</b> <br />\n",
    "官方从不同角度给出了举例说明：<a href=\"https://python.langchain.com/docs/concepts/lcel/\">https://python.langchain.com/docs/concepts/lcel/</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 用 LCEL 实现 RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:35:24.267854Z",
     "start_time": "2025-05-23T09:35:23.849928Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "\n",
    "# 加载文档\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# 文档切分\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(\n",
    "    [page.page_content for page in pages[:1]]\n",
    ")\n",
    "\n",
    "# 灌库\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\", dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 检索 top-5 结果\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:35:28.220997Z",
     "start_time": "2025-05-23T09:35:28.019205Z"
    }
   },
   "source": [
    "docs = retriever.invoke(\"deepseek v3有多少参数\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"----\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3\n",
      "24.8\n",
      "23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3\n",
      "DeepSeek-V2.5\n",
      "Qwen2.5-72B-Inst\n",
      "Llama-3.1-405B-Inst\n",
      "GPT-4o-0513\n",
      "Claude-3.5-Sonnet-1022\n",
      "Figure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\n",
      "arXiv:2412.19437v2  [cs.CL]  18 Feb 2025\n",
      "----\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "----\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "----\n",
      "DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "----\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:35:55.359847Z",
     "start_time": "2025-05-23T09:35:47.849117Z"
    }
   },
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Prompt模板\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "        {\"question\": RunnablePassthrough(), \"context\": retriever}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"deepseek V3有多少参数\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepSeek-V3 是一个混合专家（MoE）语言模型，总参数为 **6710亿（671B）**，其中每个 token 激活的参数为 **370亿（37B）**。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 用 LCEL 实现模型切换（工厂模式）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个人工智能助手，旨在为你提供信息和支持。我可以回答问题、提供建议、帮助学习新知识，或者协助处理各种事务。如果你有任何特定的问题或需要帮助的地方，请随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.utils import ConfigurableField\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "\n",
    "# 模型1\n",
    "ds_model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "# 模型2\n",
    "gpt_model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "# 通过 configurable_alternatives 按指定字段选择模型\n",
    "model = gpt_model.configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    default_key=\"gpt\",\n",
    "    deepseek=ds_model,\n",
    "    # claude=claude_model,\n",
    ")\n",
    "\n",
    "# Prompt 模板\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LCEL\n",
    "chain = (\n",
    "        {\"query\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 运行时指定模型 \"gpt\" or \"deepseek\"\n",
    "ret = chain.with_config(configurable={\"llm\": \"gpt\"}).invoke(\"请自我介绍\")\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扩展阅读：什么是[**工厂模式**](https://www.runoob.com/design-pattern/factory-pattern.html)；[**设计模式**](https://www.runoob.com/design-pattern/design-pattern-intro.html)概览。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>从模块间解依赖角度，LCEL的意义是什么？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 通过 LCEL，还可以实现\n",
    "\n",
    "1. 配置运行时变量：https://python.langchain.com/docs/how_to/configure/\n",
    "2. 故障回退：https://python.langchain.com/docs/how_to/fallbacks/\n",
    "3. 并行调用：https://python.langchain.com/docs/how_to/parallel/\n",
    "4. 逻辑分支：https://python.langchain.com/docs/how_to/routing/\n",
    "5. 动态创建 Chain: https://python.langchain.com/docs/how_to/dynamic_chain/\n",
    "\n",
    "更多例子：https://python.langchain.com/docs/how_to/lcel_cheatsheet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 工作流框架：LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph 是为智能体和工作流设计一套底层编排框架\n",
    "\n",
    "安装：`pip install langgraph`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 几个基础概念\n",
    "\n",
    "- `StateGraph` 将工作流定义成一个状态机\n",
    "- `Node` 工作流中的节点\n",
    "- `Edge` 边，定义节点之间的跳转\n",
    "- `State` 状态，随着工作流的进行可以被更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 先从一个最基础的例子开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现一个带上下文的 Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 定义 State\n",
    "class State(TypedDict):\n",
    "    # 状态变量 messages 类型是 list，更新方式是 add_messages\n",
    "    # add_messages 是内置的一个方法，将新的消息列表追加在原列表后面\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# 创建 Graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "\n",
    "# 定义一个执行节点\n",
    "# 输入是 State，输出是系统回复\n",
    "def chatbot(state: State):\n",
    "    # 调用大模型，并返回消息（列表）\n",
    "    # 返回值会触发状态更新 add_messages\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFt5JREFUeJztnWlgFEXax2u65z4zmZBjJgmZXASSADFgsnGXcARRThU5xJeVhXcFWQ4FF2FRFq/VhUVADYggBGEFRTEICCQi2eVcCNGEQCBMTnJnjmTuo4/3Q/uGrM6ZniE9sX+fJlPVPU//011V/dRT9TBwHAc0fQXqbwOCG1o+UtDykYKWjxS0fKSg5SMFk+TxBq2jW+MwG1CzHkUcOIYFwTCIzYU4PIgvggUSZpicQ+ZUjL6N+zSttpoKU90NE5vPADiDL4L5YpgnYGJoEMgHwaCr02E2oFw+1FJrVaYJEtIF0cn8PpzKZ/mMXcil42ocgJAwljJdEB7N7cOvUgeDzlFXaeposnW1O34zTaZI4Pl0uG/yXSvSVl7qzpkWNiRT5LuplKa13nL5uEYawR43O9z7o3yQ79jO5sQMYWq2pK8WBgH37ppP7W17Zk2MSMry6gDcO/a8Wttw2+Rl5aDGakb2bayzGBFvKnsl355Xa9UtVtKGBRMFb9Rp22weq3mWr3BH06/kvusNgmD5q+56rOah7Sst1vKEcOpvBnJ75wp1i/X62a5J8yPd1HH31mHsQm5c7P51agcACJNzGQDcuW5wU8edfJeOq3OmhQXAsKAhZ1rYpeNqNxVcyqdpteEADLzxnU8IQ5hpOZJb/+l2VcGlfDUVppAw78Y+A5ooJfdOqdFVqUv56m6YlOmCgFnlnLy8vJaWFl+PqqmpmTp1amAsAtFJ/I57VrsVc1rqXD691sHhQw/4fbatra2rq6sPB1ZVVQXAnPsMyxbX3zI5LXLusNJrHIGbgEMQ5MMPPywuLtZqtVKpNC8vb/ny5eXl5UuWLAEATJ8+PTc3d8uWLVqtdtu2bVevXtXr9REREXPmzJk7dy5xhry8vIULF165cuXatWvz5s3bv38/AGDUqFGrVq2aN2+e3w3m8mFtm915mdPR4J3r+tP7WwMwGsVxHN+9e3deXt7ly5fv3bt3/vz5SZMmffDBBw6Ho6ioKDMzs6qqymg04ji+cuXKGTNmXL9+vb6+vrCwcPTo0efOnSPOMGnSpJkzZ27fvr28vNxgMGzevHny5Mk6nc5qDcirUeXlrrOH2p0WOb/7zHqUL4b9/m8kUKlUiYmJ2dnZAIDo6OiPPvqIwWAwmUyBQAAAEIvFxIfVq1dDEKRQKAAAgwcPPnLkyJUrV8aOHQsAYDAYXC53xYoVxAk5HA6DwQgJCQmQwQIx06T35eEFALDYgfLjjxkzZsOGDevWrZswYcLDDz8cFxfntBqPxysoKCgtLe3q6sIwTK/Xx8TE9JQOHz48QOb9EpjJgJkMp0XO5eMKoM5mW4CsmTx5skAgOHLkyIYNG1AUzc3NXbt2bWhoaO86CIIsW7YMRdGXX345Li4OhuHVq1f3riAUCgNk3i8xdiFsrvObybl8fBHTbEACZ1Bubm5ubq7FYrlw4cKWLVvefPPNrVu39q5QWVmpUql2796dkZFBfKPT6eRyeeBMcoObpsy5qEIpzOEF6uEtKSkhBnc8Hm/ixIlPPPGESqXqKSVcGDabDQAgkfz0ul1RUdHS0tJf4TgogknD2U6LnGsUGsHpbLJ3dbrorclx6NChdevWlZWVNTc3l5aWfvfdd5mZmUSnAQC4cOFCbW1tcnIym80+fPiwWq2+cuXKpk2bsrOzGxoatFrtL08oEonUavUPP/zQ2toaCINvXtHHuJpIctVbny/sLPteG4hxgEajWb9+/YQJE7KysqZMmfLOO+8YDAYcxxEEWb58eVZW1uLFi3EcP3369NSpU3NychYtWnT37t2LFy+OGTNm1qxZOI4/9thj+fn5PSdsbW2dOXNmVlbWzp07/W5te6Pl8D8aXZW69Pe11Fqq/qOf8ExEIP6fQcSPJTrAYIzMdT4qctnAyeN5Bh1yr9ocSNuoDobhF7/RuNLOw0xbxz3ruS8656yOcV7a0TF79mynRUKh0Gh07qVQKpX79u3zwvK+UFBQUFBQ4LSIwXB5pUuXLnV1IReOqQViOGOc1NUvenDW//vrzthkflyqE9cLhmEmk/OxuMPhYLGcO7sgCCJeKgKBzWaz2513d1arlct17gHhcDhstpOO1WJCiw+2TV+scPeTHtvOgjfqutV2f7fIQcC+jXV6rYcL9yyfzYp+tEblP6uCg6Mf3qutNHqs5tU8r92G7lqnMnY7/GFYEHA0v6mjySvnjbdRBmYD8slrtU13B/iEr7HLsfevtfW3PN93BL6FCJ37vEOvczwyLSxMQSosjoLYrdilE2q9Bhk/J1wY4m3Yo88Bao23zRePq2NT+BExXGWawJUnJ4houmturbOWfa/LmRqW/lvfJrX7GB5ZU2GsLjPUVZqGZIpYHEggZgokMJcPB0NwKQAYrtciJj0CGKDyYnd4DDdxpCD9kb54W/soXw+Nt826DrtJj5i6UQzDEbs/9dNoNAaDwZU/tc/wRTCTzRCImeJQZmyKwJUvzxvIyhdQTpw4UVpaunHjxv42xCV0ZD0paPlIQWn52Gz2z+ZAqAal5bPb7U7dy9SB0vJBEMThUHp8Tmn5MAwj5owoC6Xl6wk9oCyUlg9BEFceWYpAafk4HE5YGKWjgyktn81mU6vdhRb3O5SWj/pQWj4Yhnk835Y4PmAoLR+KohaLpb+tcAel5aPvPlLQd98Ah9LysViswEUs+wVKy+dwOPq20uOBQWn5qA+l5WOz2TKZrL+tcAel5bPb7RqNpr+tcAel5aM+lJaP9riQgva4DHAoLR89UUkKeqJygENp+eh5XlLQ87ykoD0upKA9LgMcSstHB2mQgg7SIAXt7yMF7e8jBe2wIgXtsCIFk8kUiSi9/yIVl8XMnDnT4XDgOG42mxEEkUgkxOezZ8/2t2k/h2zGhECQlpZ24sQJBuOnxYYmkwnDsJSUlP62ywlUfHgXLFgQGflf2/3yeLxAbMxHHirKp1QqR48e3btVUSgUgdtekwxUlA8A8Nxzz4WH/5S5gM1mz58/v78tcg5F5VMqldnZ2cQNGB0dPW3atP62yDkUlQ8AMH/+/IiICDab/eyzz/a3LS7xree1WzF1s81qcb4Lr7+JeCTjqdra2vSEvNrKB+E4YLEYoVFsgdgHTXwY9xUfbKu9YYpU8hlBv32Bc/hiZkOVMSKGk/v0IC/TnXglH4riX+c3J2aIE4aL/WEnpenqtJd80frkUoU3+2l4Jd/X+c1Ds0MUiZT2XPoRDMMPvlnzp/cSPdb03HXU3TQJQ1i/Hu0AABDEyJ466D+nPPvKPMunbraxeYHaw5myiEJZLbVWj9U8y2c1oyFhzjc+HcCIQtnepOzzLJ/DhiPBkPvPz+DA2OV562XqDpuDAlo+UtDykYKWjxS0fKSg5SMFLR8paPlIQctHClo+UtDykeKByjdrzuOf7N1B5gx/3bhm9csv+M8isgTB3bfx9VdOnzlO5gxfF37x7qaAbIAaBPJVV5PNoUj+DK4ISIyLw+Eo2L+rqPik0WhITByy+I8r0tJGEEUQBO3/dPexb44YjYaMjNFr12yUSkMBALfv3Nqz58O7qjt2uy1ucPyiRX8alZkFABg3YRQA4O+bXs/fseX4sRIi88a3p44dOLBHo1XHKxNXrVqfnJRCxFJ+snfHuZIinU4rk4XlTXh8wXOLmUzmi6ueLy8vAwCUlV394vC3/r3SgNx9Oz/aevLbwqUvrNq2dbdCEbNm7bKW1mai6FxJcXe37p2/bX91/du3blUU7N9FxPG9snY5i83+x+YdO/M/HZY6/LUNqzs7OwAAxAUvX/bngweOEWdoaKw7e/b0urVvbP57vt1hf/W1VQ6HAwCwbfu7p05/s2TxiwX7vly08E9fF36+6+P3AQBvvfFeclLK+HGP7v74kN+v1P93n8lkOvlt4eLnV44bOxEAsPql9Razubn5njxKAQAQCIQrlq8BAAxJHnr+wrmqqkpit6CtW3bJZGESSQgAYOGCF44ePVx5s3zc2IlisQQAwOfzJeKftkPv6tJ9sudzsUgMAHhhyUtrXln2Y/n15KSUouKTSxavHD/uUQCAQh7d2Fj35VefPf/H5UKhEGYyWWx2zxn8iP/lq6+vsdvtQ1NSiT9ZLNbrGzf1lKYOu58cURoSest8gwiDdCCO9z/YpKqpNhoNxOSfXu88J3O8MpHQDgAwbGg6AKCxsR6GYRRFiT8JhgwZZrVam5oalcoEv19jD/6Xz2DQAwA4HOeZbXrvScX4/xC+pqbG1S8vyRg5+i/r3gyTDcIwbPbcya7OLxDcT69InM1ms5rNJgAAny/oVcQHAFgsgU1V5X/5JCFSAABxPV7y/bkiFEVfXf82sX6yvb3NTWWL9f6uVmazGQDA5fIITXv/KPG5t9aBwP9dR0z0YC6XW15RRvyJYdjKl/545swJN4c4HHYOh9uz9rT4u5/3j73n8uvra3rScN2pvgUAiIuLj49PgmG48mZ5T7WbNyuEQqFCEfPLM/gR/8snFAoff2z6Pz/bW1R08k511Xtb/1ZdXZWWPtLNIUNT0rq7u06d/kajURceO3L7zs2QEGlNTbXRaORwOBwOp7yi7K7qDoIgxBO6+R9v1NfX1taq9nySHxkRNTw9QyKWPP7Y9H9+tu/ChZL29rYzZ04c++bIzKeeYTKZAACRUKRS3amrq/H7xQZk3Lf4+ZUMCPro4+0Wi1mpTHzn7e0KebSb+jk5Y+bMnr/r4/d37Hwv6+FH1q55/cuv/nno8H4Igl5cufaZuQsOf77/8uXzBw8UIiiSOmx4ZmbW2r+s0GjUSUkpb735HqHRiuVr+HzBtvff7erShQ+K+J9nF817ZgFx/iefnPvOuxs2bPzzgf1H/XulnmNcvv+8QxLOTX5o4AcH9cbYhRTtb3pug4dUIUHw0kZlaPlIQctHClo+UtDykYKWjxS0fKSg5SMFLR8paPlIQctHClo+UtDykcKzfHwRDP3qlnUADMdD5Z63DvQsn0jK7GjwvEBkgKFptrJYnpc+epYvJplv1jv8ZFXQoGmxxad7XofmWT6xjJX8kKjki1Y/GRYE/PgvDeJAkx/yvIWMt+t5q38wlp3VJT0kDpNzOfyB2RZiGK5utmpabYgdnTgvwptDfFgO3dlsvXFe3612dGse0LOMoiiGYSyWVyuTySNTcFgsRny6wJv7joCKuwj1QCfXHuDQ8pGC0vLR+/eRgt6/jxT0ttekoLe9JgWdr4MUdL4OUtBtHynotm+AQ2n52Gy2VCrtbyvcQWn57Ha7TqfrbyvcQWn5qA+l5WMwGETcMmWhtHw4jhPR9JSF0vJBEMRmU3rzNkrLh2GY3W7vbyvcQWn5qA+l5WMymUJhYBelkYTS8iEI0rN8jZpQWj7qQ2n5aI8LKWiPywCH0vLRE5WkoCcqBziUlo/ueUlB97ykoFO7k4JO7T7AobR8dJAGKeggDVLQybVJQSfXJgXd9pGCbvtIQf22j4rLYubPn89gMBAE6e7uttlscrkcQRCz2VxYWNjfpv0cKoZAhISEXLp0qSe5NvHaK5fL+9suJ1Dx4V24cKFI9PNVZU8++WQ/meMOKsqXkZGRkZHR+xu5XD5nzpz+s8glVJSPyO7eM2SBYXjGjBl8Pr+/jXICReUbMWJEeno60a3FxsbOnTu3vy1yDkXlI/rfsLAwGIanTJkiEFA0P6ufe167DbOZUOCP/NEJg9NGpGY3NjZOmfS0QeeXKD+cxYa4An8uhSc77rNbsdpKY22FqeOezWJEAQNII7kmHRW3joCYDLsFRRwYVwBHKfnyeI4yTSCRkVqq3nf5dO320mJdTYUxJIrPC+FzxRwWG4aY1G0NCHAMR+yo3YqY1CZDpzkilpuWI4ob1sfGoS/yYShe/FlHc401PCFUGEbFDtF7rEa7pk7LYuFjnw4Lj3G+z74bfJavpc525tM2abQkRO7tfgnUx6SzmtSGhDRe5njfklL4Jl/9TWPJV9q40QrfLQwCOqo7B8mhcbPCvT/Eh6aq8Y750qnugaodACA8eVBnO7hW7MNCHG/la2uw/usrjTw1sq+2BQfhCbJGleNakbdORq/kc9jRYztbYjKo6PPwO7I42d1yS/0tr4KCvZLv273t8tRBpA0LGiJTwk/ta/empmf5Wmoseh0mCvIBik9ATCg8XnL1tOdZKs/yXTqplcVRelVoIJDFSX883404MPfVPMinabUZdAg/xOfx5IPBZOp6+bWs8sqzgTi5JFxw84refR0P8tXeMAlCf0WPbW8EMoHqRw8JqzzIpyo3BftrWZ8Rynjt9RYUcfda4c5hhWO4SY9EBezJNZp0x09tr6kvM5m7oiKSJk9cmhifCQBo76jb/MHcJX/Ycf7y4brGcogBjUjLm/74SzAMAwAuXz169t8FRpMuOirlsYlLAmQbgVTOb623RCe6vIHcyWc2oLiHprPvYBi2e/+LVptxzlMbxELZpatf7Tnw4srF+6IiE2GYCQA4dmrrzGlr/hC7+W7NtV0Fy5SDR45Mz6ut/+Gr438fkzMve9QTGl3z8VPvB8o+AgbD3I26KXf38Jr0CIsbqH0279ZcbW69PWvGX5LiR0WEK2dMXiUNibpw5YueCiNSx8fFDgcAJCWMlkkVTc1VAIDrP54SCWVTHl0WPmjw0OSc3N/OC5B5BBATNundeWrdyWc1o3xpoGJjG5oqYZiVoHzoJzsgKH7wyObW6p4KUZFJPZ+5XJHFagAAtHfWRytSiKcYABAbnRog8wiYXBaK9rXt4wmYZq0NBCZDps1mRlHH2td/1/MNhqEi4f2QDBbzv/5zOMABADabSSy6X4fN4oFAYjc7mEx3y9ndyccXw3aruyefDFyugMlkr1p6oPeXDIaHkQCbzbNa77+NErdk4MAcKF/srvlyK58QZnMD5XyPVaQiiB3F0KiIn25vra5VKPDwejNIFntbdRnDMAiCiAY0QOYRQEzAl7iTz506DIjBE8ImXUB2XE+MH62IGnLoy42quutaXUtZ+ZmtO+Zfuvql+6MyRkwyGrXfnNrW2q6quHmu9Ac/J8v+GZpGkyLeXfvgYaIycaRAVWkSSP0/9INh+H9/v+3E6fc/PbzObreEhsjzxi7MfcRDTzokMWv64y+WXDh4+drRaHnKrBnrtu78fYCCxAydZkUSn+F20tWDs17XYT+a35qQ7S5B50Cl9bY6PYubluNu9sND0yYNZ0tkTKPG4r7awAPHcO09g3vtvIoyGPOU7Nu9HUKZyymOV9+e4PR7DEMhBuQq4mDdS0cFfL/lWv/k4Kq6hnKnRQKexGRxnub8rfUuXTUdNdrfTPUc2OrVTNvJvW0IxJNEON8TRKtrcfq9w2GDYRbRRf6SEEmkq6I+oNerEdT5hjl2u5XNdt52h0qdTz8gdrThevOiN5Qef9fbicr81aqh4+MgyA/BK9Sn4XrLo8+GRSk9j8m9/f/PeyW2/mozacOCgPbqzoyxIm+0822avKPJWnRQHT0iipx5lKblVufI3/GHPextKmwfWp/waO742TLVxUYUCZgbq19pudkeP5TlvXZ9iXExdiHHdrVyJIKwwX7rN/sdfbvJ2m3KHCdKGO7blll9DFAr+VJ9p1QfOUQmDhcwgrk/MemsnTVa6SDm2KdlkjCf9wrse3yfxYhePa2tvNwtCefxQ/lcEYfFgZlsmOJqIjbUYUMcVtSoNna3m5VpwpG5ksjBfXwr9cOqooYqU02Fqa3BZjEiViMqjeTqtVTcsxCGGTYzyuHDPCEcGceNSeIp0wQkXUr+X5RlNWP+CG0OBDibA/n34aDimrYgguqhyBSHlo8UtHykoOUjBS0fKWj5SPF/NrUE1gmZwDsAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 可视化展示这个工作流\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 向 graph 传入一条消息（触发状态更新 add_messages）\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "def run():\n",
    "    # 执行这个工作流\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  你好\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 你好！有什么我可以帮助你的吗？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  今天心情好吗\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 谢谢你的关心！作为一个AI，我没有情感，但我很高兴能帮助你。有什么我可以为你做的吗？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 加入 RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 加载文档\n",
    "loader = PyMuPDFLoader(\"./data/deepseek-v3-1-4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# 文档切分\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(\n",
    "    [page.page_content for page in pages[:2]]\n",
    ")\n",
    "\n",
    "# 灌库\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# 检索 top-3 结果\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Prompt模板\n",
    "template = \"\"\"请根据对话历史和下面提供的信息回答上面用户提出的问题:\n",
    "{input}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(state: State):\n",
    "    user_query = \"\"\n",
    "    if len(state[\"messages\"]) >= 1:\n",
    "        # 获取最后一轮用户输入\n",
    "        user_query = state[\"messages\"][-1]\n",
    "    else:\n",
    "        return {\"messages\": []}\n",
    "    # 检索\n",
    "    docs = retriever.invoke(str(user_query))\n",
    "    # 填 prompt 模板\n",
    "    messages = prompt.invoke(\"\\n\".join([doc.page_content for doc in docs])).messages\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_edge(\"retrieval\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  llama2有多少参数\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Llama 2有7B、13B和70B参数的版本。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 加入分支：如果找不到答案则转人工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "\n",
    "def verify(state: State) -> Literal[\"chatbot\", \"ask_human\"]:\n",
    "    message = HumanMessage(\"请根据对话历史和上面提供的信息判断，已知的信息是否能够回答用户的问题。直接输出你的判断'Y'或'N'\")\n",
    "    ret = llm.invoke(state[\"messages\"] + [message])\n",
    "    if 'Y' in ret.content:\n",
    "        return \"chatbot\"\n",
    "    else:\n",
    "        return \"ask_human\"\n",
    "\n",
    "\n",
    "def ask_human(state: State):\n",
    "    user_query = state[\"messages\"][-2].content\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": user_query\n",
    "        }\n",
    "    )\n",
    "    # Update the state with the human's input or route the graph based on the input.\n",
    "    return {\n",
    "        \"messages\": [AIMessage(human_response)]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()  # 用于持久化存储 state (这里以内存模拟）\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"retrieval\", retrieval)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieval\")\n",
    "graph_builder.add_conditional_edges(\"retrieval\", verify)\n",
    "graph_builder.add_edge(\"ask_human\", END)\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 中途会被转人工打断，所以需要 checkpointer 存储状态\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 当使用 checkpointer 时，需要配置读取 state 的 thread_id\n",
    "# 可以类比 OpenAI Assistants API 理解，或者想象 Redis 中的 key \n",
    "thread_config = {\"configurable\": {\"thread_id\": \"my_thread_id\"}}\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 向 graph 传入一条消息（触发状态更新 add_messages）\n",
    "    for event in graph.stream(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "            thread_config\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if isinstance(value, tuple):\n",
    "                return value[0].value[\"question\"]\n",
    "            elif \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def resume_graph_updates(human_input: str):\n",
    "    for event in graph.stream(\n",
    "            Command(resume=human_input), thread_config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and isinstance(value[\"messages\"][-1], AIMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "def run():\n",
    "    # 执行这个工作流\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            break\n",
    "        question = stream_graph_updates(user_input)\n",
    "        if question:\n",
    "            human_answer = input(\"Ask Human: \" + question + \"\\nHuman: \")\n",
    "            resume_graph_updates(human_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 可视化展示这个工作流\n",
    "try:\n",
    "    display(Image(data=graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
