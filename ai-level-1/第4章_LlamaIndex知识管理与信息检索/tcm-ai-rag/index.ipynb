{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸­åŒ»ä¸´åºŠè¯Šç–—æ™ºèƒ½åŠ©æ‰‹ \n",
    "\n",
    "1. RAG æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ¡ˆ\n",
    "2. Fine tuning å¾®è°ƒæ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n",
    "\n",
    "1. å¦‚ä½•ç”¨ä½ çš„å‚åŸŸæ•°æ®è¡¥å…… LLM çš„èƒ½åŠ›\n",
    "2. å¦‚ä½•æ„å»ºä½ çš„å‚åŸŸï¼ˆå‘é‡ï¼‰çŸ¥è¯†åº“\n",
    "3. æ­å»ºä¸€å¥—å®Œæ•´ RAG ç³»ç»Ÿéœ€è¦å“ªäº›æ¨¡å—\n",
    "4. æ­å»º RAG ç³»ç»Ÿæ—¶æ›´å¤šçš„æœ‰ç”¨æŠ€å·§\n",
    "5. å¦‚ä½•æå‡ RAG æ£€ç´¢çš„æ•ˆæœåŠä¼˜åŒ–å®è·µ\n",
    "6. ç”Ÿæˆçº§éƒ¨ç½² RAG ç³»ç»Ÿæ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**å­¦ä¹ ç›®æ ‡ï¼š**\n",
    "1. RAG æŠ€æœ¯æ¦‚è¿°\n",
    "2. RAG WorkFlow åŠ RAG å·¥ç¨‹åŒ–\n",
    "3. åŸºäº LlamaIndex å¿«é€Ÿæ„å»º RAG é¡¹ç›®\n",
    "4. ä½¿ç”¨ LlamaIndex å­˜å‚¨å’Œè¯»å– Embedding å‘é‡\n",
    "5. è¿½è¸ªå“ªäº›æ–‡æ¡£ç‰‡æ®µè¢«ç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆ\n",
    "6. æ·±åº¦å‰–æ RAG æ£€ç´¢åº•å±‚å®ç°ç»†èŠ‚\n",
    "7. è‡ªå®šä¹‰ RAG Prompt Template\n",
    "8. RAG é¡¹ç›®ä¼ä¸šçº§ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€ RAG æŠ€æœ¯æ¦‚è¿°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 å¤§æ¨¡å‹ç›®å‰å›ºæœ‰çš„å±€é™æ€§\n",
    "\n",
    "**å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯æ¦‚ç‡ç”Ÿæˆç³»ç»Ÿ**\n",
    "\n",
    "- **çŸ¥è¯†æ—¶æ•ˆæ€§**ï¼šæ¨¡å‹çŸ¥è¯†æˆªæ­¢äºè®­ç»ƒæ•°æ®æ—¶é—´ç‚¹ï¼ˆ**è”ç½‘æœç´¢**ï¼‰\n",
    "- **æ¨ç†å±€é™æ€§**ï¼šæœ¬è´¨æ˜¯æ¦‚ç‡é¢„æµ‹è€Œéé€»è¾‘è¿ç®—ï¼Œå¤æ‚æ•°å­¦æ¨ç†æ˜“å‡ºé”™ï¼ˆ**DeepSeek-R1çš„æ¶æ„æœ‰æ‰€ä¸åŒ**ï¼‰\n",
    "- **ä¸“ä¸šé¢†åŸŸç›²åŒº**ï¼šç¼ºä¹å‚ç›´é¢†åŸŸçŸ¥è¯†\n",
    "- **å¹»è§‰ç°è±¡**ï¼šå¯èƒ½ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…é”™è¯¯çš„å†…å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ä»€ä¹ˆæ˜¯ RAGï¼Ÿ\n",
    "\n",
    "RAGï¼ˆRetrieval Augmented Generationï¼‰é¡¾åæ€ä¹‰ï¼Œé€šè¿‡**æ£€ç´¢**çš„æ–¹æ³•æ¥å¢å¼º**ç”Ÿæˆæ¨¡å‹**çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "<img src=\"./assets/rag.jpg\" style=\"margin-left: 0px\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒã€RAG å·¥ç¨‹åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RAGç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹\n",
    "\n",
    "æ­å»ºè¿‡ç¨‹ï¼š\n",
    "\n",
    "1. æ–‡æ¡£åŠ è½½ï¼Œå¹¶æŒ‰ä¸€å®šæ¡ä»¶**åˆ‡å‰²**æˆç‰‡æ®µ\n",
    "2. å°†åˆ‡å‰²çš„æ–‡æœ¬ç‰‡æ®µçŒå…¥**æ£€ç´¢å¼•æ“**\n",
    "3. å°è£…**æ£€ç´¢æ¥å£**\n",
    "4. æ„å»º**è°ƒç”¨æµç¨‹**ï¼šQuery -> æ£€ç´¢ -> Prompt -> LLM -> å›å¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æ„å»ºç´¢å¼•\n",
    "\n",
    "<img src=\"./assets/rag-1.png\" style=\"margin-left: 0px\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æ£€ç´¢å’Œç”Ÿæˆ\n",
    "\n",
    "<img src=\"./assets/rag-2.png\" style=\"margin-left: 0px\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰ã€é¡¹ç›®ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ä½¿ç”¨ conda åˆ›å»ºé¡¹ç›®ç¯å¢ƒ\n",
    "\n",
    "```sh\n",
    "# åˆ›å»ºç¯å¢ƒ\n",
    "conda create -n tcm-ai-rag python=3.10\n",
    "\n",
    "# æ¿€æ´»ç¯å¢ƒ\n",
    "conda activate tcm-ai-rag\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 å®‰è£…é¡¹ç›®æ‰€éœ€ä¾èµ–åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… LlamaIndex ç›¸å…³åŒ…\n",
    "# !pip install llama-index\n",
    "# !pip install llama-index-embeddings-huggingface\n",
    "# !pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… CUDA ç‰ˆæœ¬ Pytorch\n",
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å››ã€æ¨¡å‹ä¸‹è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… modelscope\n",
    "# !pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ä¸‹è½½ Embedding æ¨¡å‹æƒé‡\n",
    "\n",
    "ä½¿ç”¨BAAIå¼€æºçš„ä¸­æ–‡bgeæ¨¡å‹ä½œä¸ºembeddingæ¨¡å‹ï¼Œä½¿ç”¨modlescopeæä¾›çš„SDKå°†æ¨¡å‹æƒé‡ä¸‹è½½åˆ°æœ¬åœ°æœåŠ¡å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ modelscope æä¾›çš„ sdk è¿›è¡Œæ¨¡å‹ä¸‹è½½\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# model_id æ¨¡å‹çš„id\n",
    "# cache_dir ç¼“å­˜åˆ°æœ¬åœ°çš„è·¯å¾„\n",
    "model_dir = snapshot_download(model_id=\"BAAI/bge-base-zh-v1.5\", cache_dir=\"/home/kevin/projects/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ä¸‹è½½ LLM å¤§æ¨¡å‹æƒé‡\n",
    "\n",
    "ä½¿ç”¨é˜¿é‡Œå¼€æºçš„é€šä¹‰åƒé—®å¤§æ¨¡å‹ï¼Œä½¿ç”¨modelscopeæä¾›çš„SDKå°†æ¨¡å‹æƒé‡ä¸‹è½½åˆ°æœåŠ¡å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ modelscope æä¾›çš„ sdk è¿›è¡Œæ¨¡å‹ä¸‹è½½\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# model_id æ¨¡å‹çš„id\n",
    "# cache_dir ç¼“å­˜åˆ°æœ¬åœ°çš„è·¯å¾„\n",
    "model_dir = snapshot_download(model_id=\"Qwen/Qwen1.5-7B-Chat\", cache_dir=\"/home/kevin/projects/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äº”ã€æ„å»ºä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­è¯å€™é—®ç­”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 è¯­æ–™å‡†å¤‡\n",
    "\n",
    "æœ¬åº”ç”¨ä½¿ç”¨çš„æ–‡æ¡£æ˜¯ç”±å›½å®¶å«ç”Ÿå¥åº·å§”å‘˜å’Œå›½å®¶ä¸­åŒ»è¯ç®¡ç†å±€å‘å¸ƒçš„ä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­ï¼š\n",
    "\n",
    "- ã€Šä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­ç¬¬1éƒ¨åˆ†ï¼šç–¾ç—…ã€‹ï¼ˆä¿®è®¢ç‰ˆï¼‰.docx\n",
    "- ã€Šä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­ç¬¬2éƒ¨åˆ†ï¼šè¯å€™ã€‹ï¼ˆä¿®è®¢ç‰ˆï¼‰.docx\n",
    "- ã€Šä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­ç¬¬3éƒ¨åˆ†ï¼šæ²»æ³•ã€‹ï¼ˆä¿®è®¢ç‰ˆï¼‰.docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <p><strong>éœ€è¦å¯¹è¯­æ–™è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå¦‚å»é™¤å™ªå£°æ•°æ®ã€æ•°æ®æ ¼å¼åŒ–ç­‰</strong></p>\n",
    "    <p>æœ¬æ–‡ä»¶ä¸­å…·æœ‰ç±»ç›®å±æ€§çš„æœ¯è¯­ä¸€èˆ¬ä¸é€‚ç”¨äºä¸´åºŠè¯Šæ–­ã€‚</p>\n",
    "    <p>æ³¨ï¼šç±»ç›®å±æ€§çš„æœ¯è¯­æ˜¯æŒ‡å®šä¹‰ä¸­æœ‰â€œæ³›æŒ‡â€¦â€¦ä¸€ç±»è¯å€™â€è¡¨è¿°æ–¹å¼çš„æœ¯è¯­ã€‚</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h3>éƒ¨åˆ†å†…å®¹å±•ç¤ºï¼š</h3>\n",
    "\n",
    "<p style=\"border:1px solid red;background:pink;padding:10px\">\n",
    "<span style=\"color:blue\"><i>è¿™ç§å™ªå£°æ•°æ®å°±éœ€è¦åˆ é™¤ï¼</i></span><br>\n",
    "4.1.1.2.1<br>\n",
    "    æ°”æœºé˜»æ»è¯  syndrome/pattern of obstructed qi movement<br>\n",
    "    <strong>æ³›æŒ‡å› å„ç§åŸå› å¯¼è‡´æ°”æœºä¸ç•…ï¼Œæˆ–æ°”éƒè€Œä¸æ•£ï¼Œé˜»æ»è„è…‘ã€ç»ç»œã€å®˜çªç­‰æ‰€å¼•èµ·çš„ä¸€ç±»è¯å€™ã€‚</strong><br>\n",
    "</p>\n",
    "\n",
    "4.1.1.2.1.1<br>\n",
    "    **æ°”æœºéƒæ»è¯  syndrome/pattern of qi activity stagnation**<br>\n",
    "    å› æ°”æœºéƒç»“ï¼Œé˜»æ»ç»ç»œæˆ–è„è…‘å®˜çªæ‰€è‡´ã€‚ä¸´åºŠä»¥å¤´é¢ˆè‚©èƒŒæˆ–èƒ¸èƒè„˜è…¹ç­‰å¤„é—·èƒ€ï¼Œæˆ–æ”»çªœä½œç—›ï¼Œå¸¸éšç´§å¼ ã€æŠ‘éƒç­‰æƒ…ç»ªç¼“è§£ï¼Œæˆ–å¾—å¤ªæ¯ã€å—³æ°”ã€è‚ é¸£ã€çŸ¢æ°”è€Œå‡è½»ï¼Œè„‰å¼¦ï¼Œå¯ä¼´è§å¤§ä¾¿æ—¶ç§˜æˆ–æ³»ï¼Œå°ä¾¿ä¸åˆ©ï¼Œè€³é¸£ã€è€³è‹ï¼Œå˜¶å“‘ã€å‘ƒé€†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚<br>\n",
    "\n",
    "4.1.1.2.1.2<br>\n",
    "    **æ°”æ»è€³çªè¯  syndrome/pattern of qi stagnation in the ears**<br>\n",
    "    å› è‚æ°”éƒç»“ï¼Œæ°”æœºä¸åˆ©ï¼Œæ°”æ»è€³çªæ‰€è‡´ã€‚ä¸´åºŠä»¥çªç„¶è€³çªå¤±èªï¼Œæˆ–è€³å†…å µå¡ï¼Œè€³é¸£ï¼Œçœ©æ™•ï¼Œè„‰å¼¦ï¼Œä¼´è§èƒ¸èƒèƒ€é—·ï¼Œæƒ…ç»ªæŠ‘éƒç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚<br>\n",
    "\n",
    "4.1.1.2.1.3<br>\n",
    "    **æ°”æ»å£°å¸¦è¯  syndrome/pattern of qi stagnation in the vocal fold**<br>\n",
    "    å› æ°”æœºé˜»æ»ï¼Œç—¹é˜»å£°å¸¦æ‰€è‡´ã€‚ä¸´åºŠä»¥å£°éŸ³ä¸æ‰¬ã€å˜¶å“‘ï¼Œè¨€è¯­è´¹åŠ²æˆ–ç£•å·´ï¼Œè„‰å¼¦ï¼Œå¯ä¼´è§å’½å–‰ä¸é€‚ï¼Œèƒ¸é—·ã€èƒèƒ€ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åˆ é™¤æ–‡ä»¶ä¸­çš„è‹±æ–‡å’Œ/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†å®Œæˆï¼Œå·²ç”Ÿæˆæ–°æ–‡ä»¶ï¼š./data/demo-2-1.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_english(input_file, output_file):\n",
    "    \"\"\"\n",
    "    å»é™¤æ–‡ä»¶ä¸­æ‰€æœ‰è‹±æ–‡å­—ç¬¦å¹¶ç”Ÿæˆæ–°æ–‡ä»¶\n",
    "    :param input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„\n",
    "    :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f_in:\n",
    "            content = f_in.read()\n",
    "\n",
    "        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤æ‰€æœ‰è‹±æ–‡å­—æ¯\n",
    "        filtered_content = re.sub('[A-Za-z/]', '', content)\n",
    "\n",
    "        with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "            f_out.write(filtered_content)\n",
    "            \n",
    "        print(f\"å¤„ç†å®Œæˆï¼Œå·²ç”Ÿæˆæ–°æ–‡ä»¶ï¼š{output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"å¤„ç†å‡ºé”™ï¼š{str(e)}\")\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "remove_english('./data/demo-2.txt', './data/demo-2-1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 åŸºäº LlamaIndex æ¥å¿«é€Ÿæ„å»ºçŸ¥è¯†åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 å¯¼å…¥æ‰€éœ€çš„åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, SimpleDirectoryReader, VectorStoreIndex, load_index_from_storage, StorageContext, QueryBundle\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 å®šä¹‰æ—¥å¿—é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 å®šä¹‰ System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 ä½¿ç”¨ llama_index_llms_huggingface è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_use_double_quant = True,  # å¯ç”¨åµŒå¥—é‡åŒ–ï¼Œåœ¨ç¬¬ä¸€è½®é‡åŒ–ä¹‹åä¼šè¿›è¡Œç¬¬äºŒè½®é‡åŒ–ï¼Œä¸ºæ¯ä¸ªå‚æ•°é¢å¤–èŠ‚çœ 0.4 æ¯”ç‰¹\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16, # æ›´æ”¹é‡åŒ–æ¨¡å‹çš„è®¡ç®—æ•°æ®ç±»å‹æ¥åŠ é€Ÿè®­ç»ƒ\n",
    ")\n",
    "\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window = 4096,\n",
    "    max_new_tokens = 2048,\n",
    "    generate_kwargs = {\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt = query_wrapper_prompt,\n",
    "    tokenizer_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    model_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    device_map = \"auto\", #\"auto\",\"balanced\",\"balanced_low_0\",\"sequential\"\n",
    "    model_kwargs = {\n",
    "        \"trust_remote_code\":True,\n",
    "        \"quantization_config\": quantization_config\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<p><strong>æ³¨æ„ï¼šä¸ºäº†è¾“å‡ºçš„å¯å¤ç°æ€§</strong></p>\n",
    "<ul>\n",
    "    <li>å°†å¤§æ¨¡å‹çš„temperatureè®¾ç½®ä¸º0ï¼Œdo_sampleè®¾ç½®ä¸ºFalseï¼Œæ‰€ä»¥ä¸¤æ¬¡å¾—åˆ°çš„è¾“å‡ºåŸºæœ¬ç›¸åŒï¼›</li>\n",
    "    <li>å¦‚æœå°†temperatureè®¾ç½®ä¸ºå¤§äº0çš„å°æ•°ï¼Œdo_sampleè®¾ç½®ä¸ºTrueï¼Œå¤§æ¨¡å‹æ¯æ¬¡çš„è¾“å‡ºå¯èƒ½éƒ½æ˜¯ä¸ä¸€æ ·çš„ã€‚</li>\n",
    "    <li>å¦å¤–ï¼Œå¦‚æœä½ åœ¨å®éªŒæ—¶è·å¾—çš„è¾“å‡ºä¸æ–‡ä¸­çš„è¾“å‡ºä¸ä¸€è‡´ï¼Œè¿™ä¹Ÿæ˜¯æ­£å¸¸çš„ï¼Œè¿™ä¸å¤šä¸ªå› ç´ æœ‰å…³ã€‚</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5 ä½¿ç”¨ llama_index_embeddings_huggingface è°ƒç”¨æœ¬åœ° embedding æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"/home/kevin/projects/models/BAAI/bge-base-zh-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.6 è¯»å–æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data\", required_exts=[\".txt\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7 å¯¹æ–‡æ¡£è¿›è¡Œåˆ‡åˆ†ï¼Œå°†åˆ‡åˆ†åçš„ç‰‡æ®µè½¬åŒ–ä¸ºembeddingå‘é‡ï¼Œæ„å»ºå‘é‡ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, transformations=[SentenceSplitter(chunk_size=256)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentenceSplitter å‚æ•°è¯¦ç»†è®¾ç½®ï¼š\n",
    "\n",
    "é¢„è®¾ä¼šä»¥ 1024 ä¸ª token ä¸ºç•Œåˆ‡å‰²ç‰‡æ®µ, æ¯ä¸ªç‰‡æ®µçš„å¼€å¤´é‡å ä¸Šä¸€ä¸ªç‰‡æ®µçš„ 200 ä¸ª token çš„å†…å®¹ã€‚\n",
    "\n",
    "```properties\n",
    "chunk_size = 1024,    # åˆ‡ç‰‡ token æ•°é™åˆ¶\n",
    "chunk_overlap = 200,  # åˆ‡ç‰‡å¼€å¤´ä¸å‰ä¸€ç‰‡æ®µå°¾ç«¯çš„é‡å¤ token æ•°\n",
    "paragraph_separator = '\\n\\n\\n', # æ®µè½çš„åˆ†ç•Œ\n",
    "secondary_chunking_regex = '[^,.;ã€‚ï¼Ÿï¼]+[,.;ã€‚ï¼Ÿï¼]?' # å•ä¸€å¥å­çš„æ ·å¼\n",
    "separator = ' ', # æœ€å°åˆ‡å‰²çš„åˆ†ç•Œå­—å…ƒ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.8 æ„å»ºæŸ¥è¯¢å¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming æµå¼è¾“å‡º\n",
    "# similarity_top_k æ£€ç´¢ç»“æœçš„æ•°é‡\n",
    "query_engine = index.as_query_engine(streaming=True, similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.9 ç”Ÿæˆç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»æä¾›çš„ä¿¡æ¯æ¥çœ‹ï¼Œä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç­‰ç—‡çŠ¶å¯èƒ½ä¸ä»¥ä¸‹å‡ ç§è¯å€™ç›¸å…³ï¼š\n",
    "\n",
    "1. **æ´¥æ¶²ä¸è¶³è¯ (Syndrome of Fluid and Humor Insufficiency)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰éƒ¨ä½å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ã€‚è¿™äº›ç—‡çŠ¶ä¸ä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç›¸ç¬¦ã€‚\n",
    "\n",
    "2. **æ´¥æ¶²äºæ¶¸è¯ (Syndrome of Fluid and Humor Scantiness)**ï¼šè¿™ç§è¯å€™è¡¨ç°ä¸ºå£å¹²ã€å”‡è£‚ï¼Œé¼»ç‡¥æ— æ¶•ï¼Œçš®è‚¤å¹²ç˜ªï¼Œç›®é™·ã€èºç˜ªï¼Œç”šåˆ™è‚Œè‚¤ç”²é”™ï¼ŒèˆŒè´¨çº¢è€Œå°‘æ´¥ï¼ŒèˆŒä¸­è£‚ï¼Œè„‰ç»†æˆ–æ•°ã€‚è¿™äº›ç—‡çŠ¶ä¹ŸåŒ…æ‹¬å£ç‡¥å’Œå’½å¹²ã€‚\n",
    "\n",
    "3. **ç‡¥é‚ªçŠ¯è‚ºè¯ (Syndrome of Pathogenic Dryness Invading the Lung)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å¹²å’³ã€å°‘ç—°æˆ–æ— ç—°ï¼Œç—°é»ä¸æ˜“å’³å‡ºï¼Œå”‡é¼»å’½å–‰å¹²ç‡¥ï¼Œå£°éŸ³å˜¶å“‘ï¼Œå£æ¸´ï¼Œå’³ç”šåˆ™èƒ¸ç—›ï¼Œæˆ–ç—°ä¸­è¡€ä¸ï¼ŒèˆŒå°–çº¢ï¼ŒèˆŒè‹”è–„é»„ã€å°‘æ´¥ï¼Œè„‰ç»†æˆ–æ•°ã€‚å…¶ä¸­å”‡é¼»å’½å–‰å¹²ç‡¥çš„ç—‡çŠ¶ä¸å£ç‡¥ã€å’½å¹²ç›¸ç¬¦ã€‚\n",
    "\n",
    "4. **ç‡¥å¹²æ¸…çªè¯ (Syndrome of Dryness Harassing the Upper Orifices)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ã€‚è¿™äº›ç—‡çŠ¶ä¹ŸåŒ…æ‹¬å£ç‡¥ã€å’½å¹²ã€‚\n",
    "\n",
    "ç»¼ä¸Šæ‰€è¿°ï¼Œä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç­‰ç—‡çŠ¶å¯èƒ½ä¸æ´¥æ¶²ä¸è¶³è¯ã€æ´¥æ¶²äºæ¶¸è¯ã€ç‡¥é‚ªçŠ¯è‚ºè¯ä»¥åŠç‡¥å¹²æ¸…çªè¯ç›¸å…³ã€‚å…·ä½“è¯Šæ–­éœ€è¦ç»“åˆå…¶ä»–ä¸´åºŠè¡¨ç°å’ŒèˆŒè„‰è±¡ç»¼åˆåˆ¤æ–­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…­ã€ä½¿ç”¨LlamaIndexå­˜å‚¨å’Œè¯»å–embeddingå‘é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 ä¸Šé¢é¢ä¸´çš„é—®é¢˜\n",
    "\n",
    "- ä½¿ç”¨llama-index-llms-huggingfaceæ„å»ºæœ¬åœ°å¤§æ¨¡å‹æ—¶ï¼Œä¼šèŠ±è´¹ç›¸å½“ä¸€éƒ¨åˆ†æ—¶é—´\n",
    "\n",
    "- åœ¨å¯¹æ–‡æ¡£è¿›è¡Œåˆ‡åˆ†ï¼Œå°†åˆ‡åˆ†åçš„ç‰‡æ®µè½¬åŒ–ä¸ºembeddingå‘é‡ï¼Œæ„å»ºå‘é‡ç´¢å¼•æ—¶ï¼Œä¼šèŠ±è´¹å¤§é‡çš„æ—¶é—´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 å‘é‡å­˜å‚¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†embeddingå‘é‡å’Œå‘é‡ç´¢å¼•å­˜å‚¨åˆ°æ–‡ä»¶ä¸­\n",
    "# ./doc_emb æ˜¯å­˜å‚¨è·¯å¾„\n",
    "index.storage_context.persist(persist_dir='./doc_emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰¾åˆ°åˆšæ‰å®šä¹‰çš„persist_diræ‰€åœ¨çš„è·¯å¾„ï¼Œå¯ä»¥å‘ç°è¯¥è·¯å¾„ä¸‹æœ‰ä»¥ä¸‹å‡ ä¸ªæ–‡ä»¶ï¼š\n",
    "\n",
    "- **default_vector_store.json**ï¼šç”¨äºå­˜å‚¨embeddingå‘é‡\n",
    "- **docstore.json**ï¼šç”¨äºå­˜å‚¨æ–‡æ¡£åˆ‡åˆ†å‡ºæ¥çš„ç‰‡æ®µ\n",
    "- graph_store.jsonï¼šç”¨äºå­˜å‚¨çŸ¥è¯†å›¾æ•°æ®\n",
    "- image__vector_store.jsonï¼šç”¨äºå­˜å‚¨å›¾åƒæ•°æ®\n",
    "- **index_store.json**ï¼šç”¨äºå­˜å‚¨å‘é‡ç´¢å¼•\n",
    "\n",
    "åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæˆ‘ä»¬åªç”¨åˆ°äº†çº¯æ–‡æœ¬æ–‡æ¡£ï¼Œæ‰€ä»¥ç”Ÿæˆå‡ºæ¥çš„`graph_store.json`å’Œ`image__vector_store.json`ä¸­æ²¡æœ‰æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 ä»å‘é‡æ•°æ®åº“æ£€ç´¢\n",
    "\n",
    "å°†embeddingå‘é‡å’Œå‘é‡ç´¢å¼•å­˜å‚¨åˆ°æ–‡ä»¶ä¸­åï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦é‡å¤åœ°æ‰§è¡Œå¯¹æ–‡æ¡£è¿›è¡Œåˆ‡åˆ†ï¼Œå°†åˆ‡åˆ†åçš„ç‰‡æ®µè½¬åŒ–ä¸ºembeddingå‘é‡ï¼Œæ„å»ºå‘é‡ç´¢å¼•çš„æ“ä½œäº†ã€‚\n",
    "\n",
    "ä»¥ä¸‹ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨LlamaIndexè¯»å–ç»“æ„åŒ–æ–‡ä»¶ä¸­çš„embeddingå‘é‡å’Œå‘é‡ç´¢å¼•æ•°æ®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»å­˜å‚¨æ–‡ä»¶ä¸­è¯»å–embeddingå‘é‡å’Œå‘é‡ç´¢å¼•\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./doc_emb\")\n",
    "\n",
    "# æ ¹æ®å­˜å‚¨çš„embeddingå‘é‡å’Œå‘é‡ç´¢å¼•é‡æ–°æ„å»ºæ£€ç´¢ç´¢å¼•\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = index.as_query_engine(streaming=True, similarity_top_k=5)\n",
    "\n",
    "# æŸ¥è¯¢è·å¾—ç­”æ¡ˆ\n",
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»æä¾›çš„ä¿¡æ¯æ¥çœ‹ï¼Œä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç­‰ç—‡çŠ¶å¯èƒ½ä¸ä»¥ä¸‹å‡ ç§è¯å€™ç›¸å…³ï¼š\n",
    "\n",
    "1. **æ´¥æ¶²ä¸è¶³è¯ (Syndrome of Fluid and Humor Insufficiency)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰éƒ¨ä½å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ã€‚è¿™äº›ç—‡çŠ¶ä¸ä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç›¸ç¬¦ã€‚\n",
    "\n",
    "2. **æ´¥æ¶²äºæ¶¸è¯ (Syndrome of Fluid and Humor Scantiness)**ï¼šè¿™ç§è¯å€™è¡¨ç°ä¸ºå£å¹²ã€å”‡è£‚ï¼Œé¼»ç‡¥æ— æ¶•ï¼Œçš®è‚¤å¹²ç˜ªï¼Œç›®é™·ã€èºç˜ªï¼Œç”šåˆ™è‚Œè‚¤ç”²é”™ï¼ŒèˆŒè´¨çº¢è€Œå°‘æ´¥ï¼ŒèˆŒä¸­è£‚ï¼Œè„‰ç»†æˆ–æ•°ã€‚è¿™äº›ç—‡çŠ¶ä¹ŸåŒ…æ‹¬å£ç‡¥å’Œå’½å¹²ã€‚\n",
    "\n",
    "3. **ç‡¥é‚ªçŠ¯è‚ºè¯ (Syndrome of Pathogenic Dryness Invading the Lung)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å¹²å’³ã€å°‘ç—°æˆ–æ— ç—°ï¼Œç—°é»ä¸æ˜“å’³å‡ºï¼Œå”‡é¼»å’½å–‰å¹²ç‡¥ï¼Œå£°éŸ³å˜¶å“‘ï¼Œå£æ¸´ï¼Œå’³ç”šåˆ™èƒ¸ç—›ï¼Œæˆ–ç—°ä¸­è¡€ä¸ï¼ŒèˆŒå°–çº¢ï¼ŒèˆŒè‹”è–„é»„ã€å°‘æ´¥ï¼Œè„‰ç»†æˆ–æ•°ã€‚å…¶ä¸­å”‡é¼»å’½å–‰å¹²ç‡¥çš„ç—‡çŠ¶ä¸å£ç‡¥ã€å’½å¹²ç›¸ç¬¦ã€‚\n",
    "\n",
    "4. **ç‡¥å¹²æ¸…çªè¯ (Syndrome of Dryness Harassing the Upper Orifices)**ï¼šè¿™ç§è¯å€™çš„ç‰¹ç‚¹æ˜¯å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ã€‚è¿™äº›ç—‡çŠ¶ä¹ŸåŒ…æ‹¬å£ç‡¥ã€å’½å¹²ã€‚\n",
    "\n",
    "ç»¼ä¸Šæ‰€è¿°ï¼Œä¸è€ç–²åŠ³ã€å£ç‡¥ã€å’½å¹²ç­‰ç—‡çŠ¶å¯èƒ½ä¸æ´¥æ¶²ä¸è¶³è¯ã€æ´¥æ¶²äºæ¶¸è¯ã€ç‡¥é‚ªçŠ¯è‚ºè¯ä»¥åŠç‡¥å¹²æ¸…çªè¯ç›¸å…³ã€‚å…·ä½“è¯Šæ–­éœ€è¦ç»“åˆå…¶ä»–ä¸´åºŠè¡¨ç°å’ŒèˆŒè„‰è±¡ç»¼åˆåˆ¤æ–­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸ƒã€è¿½è¸ªå“ªäº›æ–‡æ¡£ç‰‡æ®µè¢«æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»å­˜å‚¨æ–‡ä»¶ä¸­è¯»å–embeddingå‘é‡å’Œå‘é‡ç´¢å¼•\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./doc_emb\")\n",
    "\n",
    "# æ ¹æ®å­˜å‚¨çš„embeddingå‘é‡å’Œå‘é‡ç´¢å¼•é‡æ–°æ„å»ºæ£€ç´¢ç´¢å¼•\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# è·å–æˆ‘ä»¬æŠ½å–å‡ºçš„ç›¸ä¼¼åº¦ top 5 çš„ç‰‡æ®µ\n",
    "contexts = query_engine.retrieve(QueryBundle(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\"))\n",
    "print('-' * 10 + 'ref' + '-' * 10)\n",
    "for i, context in enumerate(contexts):\n",
    "    print('#' * 10 + f'chunk {i} start' + '#' * 10)\n",
    "    content = context.node.get_content(metadata_mode=MetadataMode.LLM)\n",
    "    print(content)\n",
    "    print('#' * 10 + f'chunk {i} end' + '#' * 10)\n",
    "print('-' * 10 + 'ref' + '-' * 10)\n",
    "\n",
    "# æŸ¥è¯¢è·å¾—ç­”æ¡ˆ\n",
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------ref----------\n",
    "\n",
    "##########chunk 0 start##########\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.1.2\n",
    "    æ´¥æ¶²äºæ¶¸è¯  syndrome/pattern of fluid and humor scantiness\n",
    "    æ´¥æ¶²äºè€—è¯\n",
    "    æ´¥æ¶²å¹²æ¯è¯\n",
    "    å› æ´¥æ¶²äºæŸï¼Œå½¢ä½“å®˜çªå¤±å…»æ‰€è‡´ã€‚ä¸´åºŠä»¥å£å¹²ã€å”‡è£‚ï¼Œé¼»ç‡¥æ— æ¶•ï¼Œçš®è‚¤å¹²ç˜ªï¼Œç›®é™·ã€èºç˜ªï¼Œç”šåˆ™è‚Œè‚¤ç”²é”™ï¼ŒèˆŒè´¨çº¢è€Œå°‘æ´¥ï¼ŒèˆŒä¸­è£‚ï¼Œè„‰ç»†æˆ–æ•°ï¼Œå¯ä¼´è§å£æ¸´ã€æ¬²é¥®ï¼Œå¹²å’³ï¼Œç›®æ¶©ï¼Œå¤§ä¾¿å¹²ï¼Œå°ä¾¿å°‘ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "##########chunk 0 end##########\n",
    "\n",
    "##########chunk 1 start##########\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£å¹²ã€èˆŒç‡¥ï¼Œé¢‘é¥®è€Œä¸è§£å…¶æ¸´ï¼Œé£Ÿå¤šã€å–„é¥¥ï¼Œå¤œå°¿é¢‘å¤šï¼Œé€æ¸æ¶ˆç˜¦ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”è–„é»„æˆ–å°‘ï¼Œè„‰å¼¦ç»†æˆ–æ»‘æ•°ï¼Œä¼´è§çš®è‚¤å¹²ç‡¥ï¼Œå››è‚¢ä¹åŠ›ï¼Œå¤§ä¾¿å¹²ç»“ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.3.2\n",
    "    æ´¥äºçƒ­ç»“è¯  syndrome/pattern of fluid depletion and heat binding\n",
    "    æ¶²å¹²çƒ­ç»“è¯\n",
    "    å› æ´¥æ¶²äºè™šï¼Œçƒ­é‚ªå†…ç»“æ‰€è‡´ã€‚\n",
    "##########chunk 1 end##########\n",
    "\n",
    "##########chunk 2 start##########\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.3\n",
    "    ç‡¥é‚ªçŠ¯è‚ºè¯  syndrome/pattern of pathogenic dryness invading the lung\n",
    "    ç‡¥é‚ªä¼¤è‚ºè¯\n",
    "    å› å¤–æ„Ÿç‡¥é‚ªï¼Œæˆ–æ„Ÿå—é£çƒ­ï¼ŒåŒ–ç‡¥ä¼¤é˜´ï¼Œè‚ºå¤±æ¸…è‚ƒæ‰€è‡´ã€‚ä¸´åºŠä»¥å¹²å’³ã€å°‘ç—°æˆ–æ— ç—°ï¼Œç—°é»ä¸æ˜“å’³å‡ºï¼Œå”‡é¼»å’½å–‰å¹²ç‡¥ï¼Œå£°éŸ³å˜¶å“‘ï¼Œå£æ¸´ï¼Œå’³ç”šåˆ™èƒ¸ç—›ï¼Œæˆ–ç—°ä¸­è¡€ä¸ï¼ŒèˆŒå°–çº¢ï¼ŒèˆŒè‹”è–„é»„ã€å°‘æ´¥ï¼Œè„‰ç»†æˆ–æ•°ï¼Œåˆèµ·æˆ–ä¼´è§å‘çƒ­ã€æ¶å¯’ï¼Œå¤´ç—›ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "##########chunk 2 end##########\n",
    "\n",
    "##########chunk 3 start##########\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥é¼»å’½å¹²æ¶©æˆ–ç—›ï¼Œå£å”‡ç‡¥å¹²ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”ç™½æˆ–ç‡¥ï¼Œè„‰æµ®æˆ–å¾®æ•°ï¼Œä¼´è§å‘çƒ­ã€æ— æ±—ï¼Œå¤´ç—›æˆ–è‚¢èŠ‚é…¸ç—›ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.2\n",
    "    ç‡¥å¹²æ¸…çªè¯  syndrome/pattern of dryness harassing the upper orifices\n",
    "    å› æ°”å€™æˆ–ç¯å¢ƒå¹²ç‡¥ï¼Œæ´¥æ¶²è€—æŸï¼Œæ¸…çªå¤±æ¿¡æ‰€è‡´ã€‚ä¸´åºŠä»¥å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "##########chunk 3 end##########\n",
    "\n",
    "##########chunk 4 start##########\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "4.6.1.1\n",
    "    æ´¥æ¶²ä¸è¶³è¯  syndrome/pattern of fluid and humor insufficiency\n",
    "    æ´¥äºè¯\n",
    "    å› æ´¥æ¶²ç”Ÿæˆä¸è¶³ï¼Œæˆ–å—œé£Ÿè¾›è¾£ï¼Œè•´çƒ­åŒ–ç‡¥ï¼Œé‚ªçƒ­ç¼æŸæ´¥æ¶²æ‰€è‡´ã€‚ä¸´åºŠä»¥å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "##########chunk 4 end##########\n",
    "\n",
    "----------ref----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUG:llama_index.core.indices.utils:> Top 5 nodes:\n",
    "\n",
    "> [Node 03e55531-d58c-4b27-a688-65eaf6dcbe49] [**Similarity score:             0.728016**] ä¸´åºŠä»¥å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.1.2\n",
    "    æ´¥æ¶²äºæ¶¸è¯  syndrome/pattern of fluid and h...\n",
    "> [Node 8061e5a1-ef80-4126-9caf-d85c09c5fc79] [**Similarity score:             0.717796**] ä¸´åºŠä»¥å£å¹²ã€èˆŒç‡¥ï¼Œé¢‘é¥®è€Œä¸è§£å…¶æ¸´ï¼Œé£Ÿå¤šã€å–„é¥¥ï¼Œå¤œå°¿é¢‘å¤šï¼Œé€æ¸æ¶ˆç˜¦ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”è–„é»„æˆ–å°‘ï¼Œè„‰å¼¦ç»†æˆ–æ»‘æ•°ï¼Œä¼´è§çš®è‚¤å¹²ç‡¥ï¼Œå››è‚¢ä¹åŠ›ï¼Œå¤§ä¾¿å¹²ç»“ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.3.2\n",
    "    æ´¥äºçƒ­ç»“è¯...\n",
    "> [Node e5fb66ab-4935-49b2-95c8-f3bc29dd3641] [**Similarity score:             0.716694**] ä¸´åºŠä»¥å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.3\n",
    "    ç‡¥é‚ªçŠ¯è‚ºè¯  syndrome/pattern of p...\n",
    "> [Node 09c59214-2197-4064-96a8-c6848aab2bcf] [**Similarity score:             0.714603**] ä¸´åºŠä»¥é¼»å’½å¹²æ¶©æˆ–ç—›ï¼Œå£å”‡ç‡¥å¹²ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”ç™½æˆ–ç‡¥ï¼Œè„‰æµ®æˆ–å¾®æ•°ï¼Œä¼´è§å‘çƒ­ã€æ— æ±—ï¼Œå¤´ç—›æˆ–è‚¢èŠ‚é…¸ç—›ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.2\n",
    "    ç‡¥å¹²æ¸…çªè¯  syndrome/pattern of...\n",
    "> [Node ebcad040-24a0-4f4e-9c99-907f4102cbbb] [**Similarity score:             0.711374**] 4.6.1.1\n",
    "    æ´¥æ¶²ä¸è¶³è¯  syndrome/pattern of fluid and humor insufficiency\n",
    "    æ´¥äºè¯\n",
    "    å› æ´¥æ¶²ç”Ÿæˆä¸è¶³ï¼Œæˆ–å—œé£Ÿè¾›è¾£..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<ul>\n",
    "    <li>è¿½è¸ªæ£€ç´¢ç‰‡æ®µï¼Œè°ƒæ•´chunk_sizeçš„å€¼ï¼Œå¯ä»¥è®©embeddingæ¨¡å‹åˆ‡åˆ†å‡ºçš„ç‰‡æ®µæ›´åˆç†ï¼Œæé«˜RAGç³»ç»Ÿçš„è¡¨ç°ã€‚\n",
    "    <li>å¦‚æœæƒ³è¿½è¸ªæ›´å¤šçš„æ£€ç´¢ç‰‡æ®µï¼Œå¯ä»¥æé«˜ similarity_top_k çš„å€¼ã€‚</li>\n",
    "    <li>å¦‚æœæƒ³è¿½è¸ªç‰‡æ®µå…·ä½“çš„ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆSimilarity Scoreï¼‰çš„å€¼ï¼Œå¯ä»¥å°†logä¸­çš„levelè®¾ç½®ä¸ºDEBUGçº§åˆ«ã€‚</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…«ã€RAG æ£€ç´¢åº•å±‚å®ç°ç»†èŠ‚\n",
    "\n",
    "çŸ¥é“äº†å¦‚ä½•è¿½è¸ªå“ªäº›æ–‡æ¡£ç‰‡æ®µè¢«ç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œä½†æˆ‘ä»¬ä»ä¸çŸ¥é“RAGè¿‡ç¨‹ä¸­åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå¤§æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ£€ç´¢å‡ºçš„æ–‡æ¡£ç‰‡æ®µè¿›è¡Œå›å¤ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# å®šä¹‰æ—¥å¿—\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "# å®šä¹‰system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨llama-indexåˆ›å»ºæœ¬åœ°å¤§æ¨¡å‹\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window = 4096,\n",
    "    max_new_tokens = 2048,\n",
    "    generate_kwargs = {\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt = query_wrapper_prompt,\n",
    "    tokenizer_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    model_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    device_map = \"auto\",\n",
    "    model_kwargs = {\"torch_dtype\": torch.float16},\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨LlamaDebugHandleræ„å»ºäº‹ä»¶å›æº¯å™¨ï¼Œä»¥è¿½è¸ªLlamaIndexæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿçš„äº‹ä»¶\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "# ä½¿ç”¨llama-index-embeddings-huggingfaceæ„å»ºæœ¬åœ°embeddingæ¨¡å‹\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = \"/home/kevin/projects/models/BAAI/bge-base-zh-v1.5\"\n",
    ")\n",
    "\n",
    "# ä»å­˜å‚¨æ–‡ä»¶ä¸­è¯»å–embeddingå‘é‡å’Œå‘é‡ç´¢å¼•\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./doc_emb\")\n",
    "\n",
    "# æ ¹æ®å­˜å‚¨çš„embeddingå‘é‡å’Œå‘é‡ç´¢å¼•é‡æ–°æ„å»ºæ£€ç´¢ç´¢å¼•\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# æŸ¥è¯¢è·å¾—ç­”æ¡ˆ\n",
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "print(response)\n",
    "\n",
    "# get_llm_inputs_outputs è¿”å›æ¯ä¸ªLLMè°ƒç”¨çš„å¼€å§‹/ç»“æŸäº‹ä»¶\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "\n",
    "# print(event_pairs[0][1].payload.keys()) # è¾“å‡ºäº‹ä»¶ç»“æŸæ—¶æ‰€æœ‰ç›¸å…³çš„å±æ€§\n",
    "\n",
    "# è¾“å‡º Promt æ„å»ºè¿‡ç¨‹\n",
    "print(event_pairs[0][1].payload[\"formatted_prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Query è¿‡ç¨‹åˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "**********\n",
    "Trace: query\n",
    "    |_query -> 63.648696 seconds\n",
    "      |_retrieve -> 1.186543 seconds\n",
    "        |_embedding -> 1.047233 seconds\n",
    "      |_synthesize -> 62.461404 seconds\n",
    "        |_templating -> 3.3e-05 seconds\n",
    "        |_llm -> 62.451146 seconds\n",
    "**********\n",
    "</pre>\n",
    "\n",
    "ä»¥ä¸Šçš„è¾“å‡ºè®°å½•äº†queryåœ¨ç¨‹åºè¿‡ç¨‹ä¸­ç»å†çš„é˜¶æ®µå’Œæ‰€ç”¨çš„æ—¶é—´ï¼Œæ•´ä¸ªè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š\n",
    "\n",
    "  - æŠ½å–ï¼ˆretrieveï¼‰\n",
    "  - åˆæˆï¼ˆsynthesizeï¼‰ã€‚\n",
    "\n",
    "åˆæˆé˜¶æ®µçš„templatingæ­¥éª¤ä¼šå°†queryå’ŒæŠ½å–å‡ºæ¥çš„æ–‡æ¡£ç‰‡æ®µç»„åˆæˆæ¨¡æ¿ï¼Œæ„æˆæ–°çš„queryï¼Œç„¶åè°ƒç”¨LLMï¼Œå¾—åˆ°æœ€ç»ˆçš„responseã€‚\n",
    "\n",
    "æ‰€ä»¥ï¼Œåªè¦æ‰¾åˆ°templatingæ‰€æ„å»ºçš„æ–°queryï¼Œå°±å¯ä»¥çŸ¥é“ä¸ºä»€ä¹ˆå¤§æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æˆ‘ä»¬æ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£è¿›è¡Œå›å¤äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 formatted_prompt\n",
    "\n",
    "ä¸‹é¢è¿™æ®µæ–‡æœ¬å°±æ˜¯ print(event_pairs[0][1].payload[\"formatted_prompt\"]) è¯­å¥è¾“å‡ºçš„ï¼Œ\n",
    "\n",
    "ä¸‹é¢è¿™æ®µæ–‡æœ¬å°±æ˜¯ `templating` åçš„æ–° `query`\n",
    "\n",
    "åŸå§‹queryç”±\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\"å˜æˆäº†ä¸‹é¢è¿™æ®µå¾ˆé•¿çš„æ–°queryï¼Œç”±äºæˆ‘ä»¬ç»™å¤§æ¨¡å‹æä¾›äº†ä¸€äº›æ–‡æ¡£ç‰‡æ®µçŸ¥è¯†ï¼Œå¹¶ä¸”è¦æ±‚å¤§æ¨¡å‹æ ¹æ®æä¾›çš„æ£€ç´¢çŸ¥è¯†å›ç­”åŸå§‹queryï¼Œå› æ­¤å¤§æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ£€ç´¢å‡ºçš„æ–‡æ¡£ç‰‡æ®µè¿›è¡Œå›å¤ã€‚ï¼ˆè¿™å…¶å®ä¹Ÿå°±æ˜¯RAGæŠ€æœ¯çš„æœ¬è´¨äº†ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "\n",
    "[INST]<<SYS>>\n",
    "You are a helpful AI assistant.<</SYS>>\n",
    "\n",
    "Context information is below.\n",
    "---------------------\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.1.2\n",
    "    æ´¥æ¶²äºæ¶¸è¯  syndrome/pattern of fluid and humor scantiness\n",
    "    æ´¥æ¶²äºè€—è¯\n",
    "    æ´¥æ¶²å¹²æ¯è¯\n",
    "    å› æ´¥æ¶²äºæŸï¼Œå½¢ä½“å®˜çªå¤±å…»æ‰€è‡´ã€‚ä¸´åºŠä»¥å£å¹²ã€å”‡è£‚ï¼Œé¼»ç‡¥æ— æ¶•ï¼Œçš®è‚¤å¹²ç˜ªï¼Œç›®é™·ã€èºç˜ªï¼Œç”šåˆ™è‚Œè‚¤ç”²é”™ï¼ŒèˆŒè´¨çº¢è€Œå°‘æ´¥ï¼ŒèˆŒä¸­è£‚ï¼Œè„‰ç»†æˆ–æ•°ï¼Œå¯ä¼´è§å£æ¸´ã€æ¬²é¥®ï¼Œå¹²å’³ï¼Œç›®æ¶©ï¼Œå¤§ä¾¿å¹²ï¼Œå°ä¾¿å°‘ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£å¹²ã€èˆŒç‡¥ï¼Œé¢‘é¥®è€Œä¸è§£å…¶æ¸´ï¼Œé£Ÿå¤šã€å–„é¥¥ï¼Œå¤œå°¿é¢‘å¤šï¼Œé€æ¸æ¶ˆç˜¦ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”è–„é»„æˆ–å°‘ï¼Œè„‰å¼¦ç»†æˆ–æ»‘æ•°ï¼Œä¼´è§çš®è‚¤å¹²ç‡¥ï¼Œå››è‚¢ä¹åŠ›ï¼Œå¤§ä¾¿å¹²ç»“ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.3.2\n",
    "    æ´¥äºçƒ­ç»“è¯  syndrome/pattern of fluid depletion and heat binding\n",
    "    æ¶²å¹²çƒ­ç»“è¯\n",
    "    å› æ´¥æ¶²äºè™šï¼Œçƒ­é‚ªå†…ç»“æ‰€è‡´ã€‚\n",
    "\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.3\n",
    "    ç‡¥é‚ªçŠ¯è‚ºè¯  syndrome/pattern of pathogenic dryness invading the lung\n",
    "    ç‡¥é‚ªä¼¤è‚ºè¯\n",
    "    å› å¤–æ„Ÿç‡¥é‚ªï¼Œæˆ–æ„Ÿå—é£çƒ­ï¼ŒåŒ–ç‡¥ä¼¤é˜´ï¼Œè‚ºå¤±æ¸…è‚ƒæ‰€è‡´ã€‚ä¸´åºŠä»¥å¹²å’³ã€å°‘ç—°æˆ–æ— ç—°ï¼Œç—°é»ä¸æ˜“å’³å‡ºï¼Œå”‡é¼»å’½å–‰å¹²ç‡¥ï¼Œå£°éŸ³å˜¶å“‘ï¼Œå£æ¸´ï¼Œå’³ç”šåˆ™èƒ¸ç—›ï¼Œæˆ–ç—°ä¸­è¡€ä¸ï¼ŒèˆŒå°–çº¢ï¼ŒèˆŒè‹”è–„é»„ã€å°‘æ´¥ï¼Œè„‰ç»†æˆ–æ•°ï¼Œåˆèµ·æˆ–ä¼´è§å‘çƒ­ã€æ¶å¯’ï¼Œå¤´ç—›ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "ä¸´åºŠä»¥é¼»å’½å¹²æ¶©æˆ–ç—›ï¼Œå£å”‡ç‡¥å¹²ï¼ŒèˆŒè´¨çº¢ï¼ŒèˆŒè‹”ç™½æˆ–ç‡¥ï¼Œè„‰æµ®æˆ–å¾®æ•°ï¼Œä¼´è§å‘çƒ­ã€æ— æ±—ï¼Œå¤´ç—›æˆ–è‚¢èŠ‚é…¸ç—›ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "3.6.3.2\n",
    "    ç‡¥å¹²æ¸…çªè¯  syndrome/pattern of dryness harassing the upper orifices\n",
    "    å› æ°”å€™æˆ–ç¯å¢ƒå¹²ç‡¥ï¼Œæ´¥æ¶²è€—æŸï¼Œæ¸…çªå¤±æ¿¡æ‰€è‡´ã€‚ä¸´åºŠä»¥å£é¼»ã€å’½å–‰å¹²ç‡¥ï¼Œä¸¤çœ¼å¹²æ¶©ï¼Œå°‘æ³ªã€å°‘æ¶•ã€å°‘æ´¥ã€ç”šåˆ™è¡„è¡€ï¼ŒèˆŒè´¨ç˜¦å°ã€èˆŒè‹”å¹²è€Œå°‘æ´¥ï¼Œè„‰ç»†ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "file_path: /home/jukeai/ai_projects/tcm-ai-rag/documents/demo-1.txt\n",
    "\n",
    "4.6.1.1\n",
    "    æ´¥æ¶²ä¸è¶³è¯  syndrome/pattern of fluid and humor insufficiency\n",
    "    æ´¥äºè¯\n",
    "    å› æ´¥æ¶²ç”Ÿæˆä¸è¶³ï¼Œæˆ–å—œé£Ÿè¾›è¾£ï¼Œè•´çƒ­åŒ–ç‡¥ï¼Œé‚ªçƒ­ç¼æŸæ´¥æ¶²æ‰€è‡´ã€‚ä¸´åºŠä»¥å£çœ¼å–‰é¼»åŠçš®è‚¤ç­‰å¹²ç‡¥ï¼Œå¤§ä¾¿å¹²ç»“ï¼Œå°ä¾¿çŸ­å°‘ï¼ŒèˆŒè´¨åçº¢è€Œå¹²ï¼Œè„‰ç»†æ•°ç­‰ä¸ºç‰¹å¾çš„è¯å€™ã€‚\n",
    "\n",
    "4.6.1.\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\n",
    "Answer: [/INST]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<ul>\n",
    "    <li>æ–°queryä¸­æ—¢æœ‰ä¸­æ–‡ï¼Œä¹Ÿæœ‰è‹±æ–‡ï¼Œè¿™æ˜¯å› ä¸ºLlamaIndexæ¡†æ¶é»˜è®¤æ„å»ºçš„æ¨¡æ¿éƒ½æ˜¯è‹±æ–‡çš„</li>\n",
    "    <li>LlamaIndexå…è®¸è‡ªå®šä¹‰æŸ¥è¯¢æµç¨‹ï¼Œæ„å»ºè‡ªå·±çš„ä¸­æ–‡æ¨¡æ¿</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Retrieve æ£€ç´¢è¿›é˜¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŠ½å–ï¼ˆretrieveï¼‰é˜¶æ®µçš„retrieversæ¨¡å—è§„å®šäº†é’ˆå¯¹æŸ¥è¯¢ä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¸Šä¸‹æ–‡çš„æŠ€æœ¯ã€‚æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„éƒ½æ˜¯é»˜è®¤çš„æ–¹æ³•ï¼Œå…¶å®LlamaIndexå®˜æ–¹ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›å…¶ä»–å¸¸ç”¨çš„æ–¹æ³•ï¼š\n",
    "\n",
    "- SimilarityPostprocessor: ä½¿ç”¨similarity_cutoffè®¾ç½®é˜ˆå€¼ã€‚ç§»é™¤ä½äºæŸä¸ªç›¸ä¼¼åº¦åˆ†æ•°çš„èŠ‚ç‚¹ã€‚\n",
    "- KeywordNodePostprocessor: ä½¿ç”¨required_keywordså’Œexclude_keywordsã€‚æ ¹æ®å…³é”®å­—åŒ…å«æˆ–æ’é™¤è¿‡æ»¤èŠ‚ç‚¹ã€‚\n",
    "- MetadataReplacementPostProcessor: ç”¨å…¶å…ƒæ•°æ®ä¸­çš„æ•°æ®æ›¿æ¢èŠ‚ç‚¹å†…å®¹ã€‚\n",
    "- LongContextReorder: é‡æ–°æ’åºèŠ‚ç‚¹ï¼Œè¿™æœ‰åˆ©äºéœ€è¦å¤§é‡é¡¶çº§ç»“æœçš„æƒ…å†µï¼Œå¯ä»¥è§£å†³æ¨¡å‹åœ¨æ‰©å±•ä¸Šä¸‹æ–‡ä¸­çš„å›°éš¾ã€‚\n",
    "- SentenceEmbeddingOptimizer: é€‰æ‹©percentile_cutoffæˆ–threshold_cutoffä½œä¸ºç›¸å…³æ€§ã€‚åŸºäºåµŒå…¥åˆ é™¤ä¸ç›¸å…³çš„å¥å­ã€‚\n",
    "- CohereRerank: ä½¿ç”¨coherence ReRankå¯¹èŠ‚ç‚¹é‡æ–°æ’åºï¼Œè¿”å›å‰Nä¸ªç»“æœã€‚\n",
    "- SentenceTransformerRerank: ä½¿ç”¨SentenceTransformeräº¤å‰ç¼–ç å™¨å¯¹èŠ‚ç‚¹é‡æ–°æ’åºï¼Œäº§ç”Ÿå‰Nä¸ªèŠ‚ç‚¹ã€‚\n",
    "- LLMRerank: ä½¿ç”¨LLMå¯¹èŠ‚ç‚¹é‡æ–°æ’åºï¼Œä¸ºæ¯ä¸ªèŠ‚ç‚¹æä¾›ç›¸å…³æ€§è¯„åˆ†ã€‚\n",
    "- FixedRecencyPostprocessor: è¿”å›æŒ‰æ—¥æœŸæ’åºçš„èŠ‚ç‚¹ã€‚\n",
    "- EmbeddingRecencyPostprocessor: æŒ‰æ—¥æœŸå¯¹èŠ‚ç‚¹è¿›è¡Œæ’åºï¼Œä½†ä¹Ÿä¼šæ ¹æ®åµŒå…¥ç›¸ä¼¼åº¦åˆ é™¤è¾ƒæ—§çš„ç›¸ä¼¼èŠ‚ç‚¹ã€‚\n",
    "- TimeWeightedPostprocessor: å¯¹èŠ‚ç‚¹é‡æ–°æ’åºï¼Œåå‘äºæœ€è¿‘æœªè¿”å›çš„ä¿¡æ¯ã€‚\n",
    "- PIINodePostprocessor(Î²): å¯ä»¥åˆ©ç”¨æœ¬åœ°LLMæˆ–NERæ¨¡å‹åˆ é™¤ä¸ªäººèº«ä»½ä¿¡æ¯ã€‚\n",
    "- PrevNextNodePostprocessor(Î²): æ ¹æ®èŠ‚ç‚¹å…³ç³»ï¼ŒæŒ‰é¡ºåºæ£€ç´¢åœ¨èŠ‚ç‚¹ä¹‹å‰ã€ä¹‹åæˆ–ä¸¤è€…åŒæ—¶å‡ºç°çš„èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 å“åº”åˆæˆå™¨ response synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆæˆï¼ˆsynthesizeï¼‰é˜¶æ®µçš„å“åº”åˆæˆå™¨ï¼ˆresponse synthesizerï¼‰ä¼šå¼•å¯¼LLMç”Ÿæˆå“åº”ï¼Œå°†ç”¨æˆ·æŸ¥è¯¢ä¸æ£€ç´¢åˆ°çš„æ–‡æœ¬å—æ··åˆåœ¨ä¸€èµ·ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„ç­”æ¡ˆã€‚\n",
    "\n",
    "LlamaIndexå®˜æ–¹ä¸ºæˆ‘ä»¬æä¾›äº†å¤šç§å“åº”åˆæˆå™¨ï¼š\n",
    "\n",
    "- Refine: è¿™ç§æ–¹æ³•éå†æ¯ä¸€æ®µæ–‡æœ¬ï¼Œä¸€ç‚¹ä¸€ç‚¹åœ°ç²¾ç‚¼ç­”æ¡ˆã€‚\n",
    "- Compact: æ˜¯Refineçš„ç²¾ç®€ç‰ˆã€‚å®ƒå°†æ–‡æœ¬é›†ä¸­åœ¨ä¸€èµ·ï¼Œå› æ­¤éœ€è¦å¤„ç†çš„æ­¥éª¤æ›´å°‘ã€‚\n",
    "- Tree Summarize: æƒ³è±¡ä¸€ä¸‹ï¼ŒæŠŠè®¸å¤šå°çš„ç­”æ¡ˆç»“åˆèµ·æ¥ï¼Œå†æ€»ç»“ï¼Œç›´åˆ°ä½ å¾—åˆ°ä¸€ä¸ªä¸»è¦çš„ç­”æ¡ˆã€‚\n",
    "- Simple Summarize: åªæ˜¯æŠŠæ–‡æœ¬ç‰‡æ®µå‰ªçŸ­ï¼Œç„¶åç»™å‡ºä¸€ä¸ªå¿«é€Ÿçš„æ€»ç»“ã€‚\n",
    "- No Text: è¿™ä¸ªé—®é¢˜ä¸ä¼šç»™ä½ ç­”æ¡ˆï¼Œä½†ä¼šå‘Šè¯‰ä½ å®ƒä¼šä½¿ç”¨å“ªäº›æ–‡æœ¬ã€‚\n",
    "- Accumulate: ä¸ºæ¯ä¸€ç¯‡æ–‡ç« æ‰¾ä¸€å †å°ç­”æ¡ˆï¼Œç„¶åæŠŠå®ƒä»¬ç²˜åœ¨ä¸€èµ·ã€‚\n",
    "- Compact Accumulate: æ˜¯â€œCompactâ€å’Œâ€œAccumulateâ€çš„åˆæˆè¯ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€ç§retrieverå’Œä¸€ç§response synthesizerã€‚retrieveré€‰æ‹©SimilarityPostprocessorï¼Œresponse synthesizeré€‰æ‹©Refineã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, SimpleDirectoryReader, VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.core.indices.vector_store import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# å®šä¹‰æ—¥å¿—\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# å®šä¹‰system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨ llama_index_llms_huggingface è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window = 4096,\n",
    "    max_new_tokens = 2048,\n",
    "    generate_kwargs = {\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt = query_wrapper_prompt,\n",
    "    tokenizer_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    model_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    device_map = \"auto\",\n",
    "    model_kwargs = {\"torch_dtype\": torch.float16},\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨LlamaDebugHandleræ„å»ºäº‹ä»¶å›æº¯å™¨ï¼Œä»¥è¿½è¸ªLlamaIndexæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿçš„äº‹ä»¶\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "# ä½¿ç”¨llama-index-embeddings-huggingfaceæ„å»ºæœ¬åœ°embeddingæ¨¡å‹\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"/home/kevin/projects/models/BAAI/bge-base-zh-v1.5\"\n",
    ")\n",
    "\n",
    "# è¯»å–æ–‡æ¡£å¹¶æ„å»ºç´¢å¼•\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# æ„å»ºretriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index = index,\n",
    "    similarity_top_k = 5,\n",
    ")\n",
    "\n",
    "# æ„å»ºresponse synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = ResponseMode.REFINE\n",
    ")\n",
    "\n",
    "# æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever = retriever,\n",
    "    response_synthesizer = response_synthesizer,\n",
    "    node_postprocessors = [SimilarityPostprocessor(similarity_cutoff=0.6)]\n",
    ")\n",
    "\n",
    "# æŸ¥è¯¢è·å¾—ç­”æ¡ˆ\n",
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "print(response)\n",
    "\n",
    "# get_llm_inputs_outputsè¿”å›æ¯ä¸ªLLMè°ƒç”¨çš„å¼€å§‹/ç»“æŸäº‹ä»¶\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "print(event_pairs[0][1].payload[\"formatted_prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "**********\n",
    "Trace: query\n",
    "    |_query -> 61.077074 seconds\n",
    "      |_synthesize -> 61.03387 seconds\n",
    "        |_templating -> 2.3e-05 seconds\n",
    "        |_llm -> 5.93741 seconds\n",
    "        |_templating -> 2.2e-05 seconds\n",
    "        |_llm -> 6.627645 seconds\n",
    "        |_templating -> 2.3e-05 seconds\n",
    "        |_llm -> 13.074158 seconds\n",
    "        |_templating -> 2.5e-05 seconds\n",
    "        |_llm -> 9.181957 seconds\n",
    "        |_templating -> 2.3e-05 seconds\n",
    "        |_llm -> 26.191079 seconds\n",
    "**********\n",
    "</pre>\n",
    "\n",
    "å¯ä»¥çœ‹å‡ºï¼Œå°†response synthesizerç”±é»˜è®¤çš„Compactæ›¿æ¢ä¸ºRefineä¹‹åï¼Œqueryåœ¨ç¨‹åºè¿‡ç¨‹ä¸­ç»å†çš„é˜¶æ®µå‘ç”Ÿäº†å˜åŒ–ï¼ŒREFINEæ¨¡å¼ä¼šè¿›è¡Œæ›´å¤šæ¬¡çš„templatingå’ŒLLMè°ƒç”¨ã€‚\n",
    "\n",
    "å®é™…å¼€å‘ä¸­å¯ä»¥è‡ªç”±ç»„åˆä¸åŒçš„retrieverå’Œresponse synthesizerï¼Œä»¥å®Œæˆæˆ‘ä»¬çš„éœ€æ±‚ã€‚å½“LlamaIndexæä¾›çš„retrieverå’Œresponse synthesizerä¸èƒ½æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚çš„æ—¶å€™ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è‡ªå®šä¹‰retrieverå’Œresponse synthesizerã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¹ã€è‡ªå®šä¹‰ Prompt\n",
    "\n",
    "LlamaIndexä¸­æä¾›çš„prompt templateéƒ½æ˜¯è‹±æ–‡çš„ï¼Œè¯¥å¦‚ä½•ä½¿ç”¨ä¸­æ–‡çš„prompt templateå‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# å®šä¹‰æ—¥å¿—\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "# å®šä¹‰system prompt\n",
    "SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")\n",
    "\n",
    "# å®šä¹‰qa prompt\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"ä¸Šä¸‹æ–‡ä¿¡æ¯å¦‚ä¸‹ã€‚\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯è€Œä¸æ˜¯å…ˆéªŒçŸ¥è¯†æ¥å›ç­”ä»¥ä¸‹çš„æŸ¥è¯¢ã€‚\"\n",
    "    \"ä½œä¸ºä¸€ä¸ªåŒ»ç–—äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ çš„å›ç­”è¦å°½å¯èƒ½ä¸¥è°¨ã€‚\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "\n",
    "# å®šä¹‰refine prompt\n",
    "refine_prompt_tmpl_str = (\n",
    "    \"åŸå§‹æŸ¥è¯¢å¦‚ä¸‹ï¼š{query_str}\"\n",
    "    \"æˆ‘ä»¬æä¾›äº†ç°æœ‰ç­”æ¡ˆï¼š{existing_answer}\"\n",
    "    \"æˆ‘ä»¬æœ‰æœºä¼šé€šè¿‡ä¸‹é¢çš„æ›´å¤šä¸Šä¸‹æ–‡æ¥å®Œå–„ç°æœ‰ç­”æ¡ˆï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰ã€‚\"\n",
    "    \"------------\"\n",
    "    \"{context_msg}\"\n",
    "    \"------------\"\n",
    "    \"è€ƒè™‘åˆ°æ–°çš„ä¸Šä¸‹æ–‡ï¼Œä¼˜åŒ–åŸå§‹ç­”æ¡ˆä»¥æ›´å¥½åœ°å›ç­”æŸ¥è¯¢ã€‚ å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰ç”¨ï¼Œè¯·è¿”å›åŸå§‹ç­”æ¡ˆã€‚\"\n",
    "    \"Refined Answer:\"\n",
    ")\n",
    "refine_prompt_tmpl = PromptTemplate(refine_prompt_tmpl_str)\n",
    "\n",
    "# ä½¿ç”¨llama-index-llm-huggingfaceè°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window = 4096,\n",
    "    max_new_tokens = 2048,\n",
    "    generate_kwargs = {\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt = query_wrapper_prompt,\n",
    "    tokenizer_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    model_name = \"/home/kevin/projects/models/Qwen/Qwen1.5-7B-Chat\",\n",
    "    device_map = \"auto\",\n",
    "    model_kwargs = {\"torch_dtype\": torch.float16},\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨LlamaDebugHandleræ„å»ºäº‹ä»¶å›æº¯å™¨ï¼Œä»¥è¿½è¸ªLlamaIndexæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿçš„äº‹ä»¶\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "# ä½¿ç”¨llama-index-embeddings-huggingfaceè°ƒç”¨æœ¬åœ°embeddingæ¨¡å‹\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"/home/kevin/projects/models/BAAI/bge-base-zh-v1.5\"\n",
    ")\n",
    "\n",
    "# ä»å­˜å‚¨æ–‡ä»¶ä¸­è¯»å–embeddingå‘é‡å’Œå‘é‡ç´¢å¼•\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"doc_emb\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# è¾“å‡ºæŸ¥è¯¢å¼•æ“ä¸­æ‰€æœ‰çš„promptç±»å‹\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "print(list(prompts_dict.keys()))\n",
    "\n",
    "# æ›´æ–°æŸ¥è¯¢å¼•æ“ä¸­çš„prompt template\n",
    "query_engine.update_prompts(\n",
    "    {\n",
    "        \"response_synthesizer:text_qa_template\": qa_prompt_tmpl,\n",
    "        \"response_synthesizer:refine_template\": refine_prompt_tmpl\n",
    "    }\n",
    ")\n",
    "\n",
    "# æŸ¥è¯¢è·å¾—ç­”æ¡ˆ\n",
    "response = query_engine.query(\"ä¸è€ç–²åŠ³ï¼Œå£ç‡¥ã€å’½å¹²å¯èƒ½æ˜¯å“ªäº›è¯å€™ï¼Ÿ\")\n",
    "print(response)\n",
    "\n",
    "# è¾“å‡ºformatted_prompt\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "print(event_pairs[0][1].payload[\"formatted_prompt\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
