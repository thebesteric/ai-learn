{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0faef-0ef0-4a1b-a7d8-99f59cd72a09",
   "metadata": {},
   "source": [
    "# ç¬¬4ç«  LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8c5bb",
   "metadata": {},
   "source": [
    "## ğŸ’¡ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. æŒæ¡ LlamaIndex çš„ç‰¹ç‚¹å’ŒåŸºæœ¬ç”¨æ³•\n",
    "2. æŒæ¡ LlamaIndex å†…ç½®çš„å·¥å…·\n",
    "3. å¦‚ä½•ç”¨å¥½ SDK ç®€åŒ–åŸºäº LLM çš„åº”ç”¨å¼€å‘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194427bf-5807-49d4-ab25-fa0556f835f3",
   "metadata": {},
   "source": [
    "## 1. å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60e6e5-8f2a-4cd5-a4b5-824259afc229",
   "metadata": {},
   "source": [
    "_SDKï¼šSoftware Development Kitï¼Œå®ƒæ˜¯ä¸€ç»„è½¯ä»¶å·¥å…·å’Œèµ„æºçš„é›†åˆï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…åˆ›å»ºã€æµ‹è¯•ã€éƒ¨ç½²å’Œç»´æŠ¤åº”ç”¨ç¨‹åºæˆ–è½¯ä»¶ã€‚_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d08668-4981-4b84-ae07-f74cfa191309",
   "metadata": {},
   "source": [
    "-æ‰€æœ‰å¼€å‘æ¡†æ¶ï¼ˆSDKï¼‰çš„æ ¸å¿ƒä»·å€¼ï¼Œéƒ½æ˜¯é™ä½å¼€å‘ã€ç»´æŠ¤æˆæœ¬ã€‚\n",
    "\n",
    "å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼ï¼Œæ˜¯è®©å¼€å‘è€…å¯ä»¥æ›´æ–¹ä¾¿åœ°å¼€å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚ä¸»è¦æä¾›ä¸¤ç±»å¸®åŠ©ï¼š\n",
    "\n",
    "1. ç¬¬ä¸‰æ–¹èƒ½åŠ›æŠ½è±¡ã€‚æ¯”å¦‚ LLMã€å‘é‡æ•°æ®åº“ã€æœç´¢æ¥å£ç­‰\n",
    "2. å¸¸ç”¨å·¥å…·ã€æ–¹æ¡ˆå°è£…\n",
    "3. åº•å±‚å®ç°å°è£…ã€‚æ¯”å¦‚æµå¼æ¥å£ã€è¶…æ—¶é‡è¿ã€å¼‚æ­¥ä¸å¹¶è¡Œç­‰\n",
    "\n",
    "å¥½çš„å¼€å‘æ¡†æ¶ï¼Œéœ€è¦å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
    "\n",
    "1. å¯é æ€§ã€é²æ£’æ€§é«˜\n",
    "2. å¯ç»´æŠ¤æ€§é«˜\n",
    "3. å¯æ‰©å±•æ€§é«˜\n",
    "4. å­¦ä¹ æˆæœ¬ä½\n",
    "\n",
    "ä¸¾äº›é€šä¿—çš„ä¾‹å­ï¼š\n",
    "\n",
    "- ä¸å¤–éƒ¨åŠŸèƒ½è§£ä¾èµ–\n",
    "  - æ¯”å¦‚å¯ä»¥éšæ„æ›´æ¢ LLM è€Œä¸ç”¨å¤§é‡é‡æ„ä»£ç \n",
    "  - æ›´æ¢ä¸‰æ–¹å·¥å…·ä¹ŸåŒç†\n",
    "- ç»å¸¸å˜çš„éƒ¨åˆ†è¦åœ¨å¤–éƒ¨ç»´æŠ¤è€Œä¸æ˜¯æ”¾åœ¨ä»£ç é‡Œ\n",
    "  - æ¯”å¦‚ Prompt æ¨¡æ¿\n",
    "- å„ç§ç¯å¢ƒä¸‹éƒ½é€‚ç”¨\n",
    "  - æ¯”å¦‚çº¿ç¨‹å®‰å…¨\n",
    "- æ–¹ä¾¿è°ƒè¯•å’Œæµ‹è¯•\n",
    "  - è‡³å°‘è¦èƒ½æ„Ÿè§‰åˆ°ç”¨äº†æ¯”ä¸ç”¨æ–¹ä¾¿å§\n",
    "  - åˆæ³•çš„è¾“å…¥ä¸ä¼šå¼•å‘æ¡†æ¶å†…éƒ¨çš„æŠ¥é”™\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>é€‰å¯¹äº†æ¡†æ¶ï¼Œäº‹åŠåŠŸå€ï¼›åä¹‹ï¼Œäº‹å€åŠŸåŠã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b589b-5a4e-451e-baf0-d2a409a9cb4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>ä»€ä¹ˆæ˜¯ SDK?</b> https://aws.amazon.com/cn/what-is/sdk/\n",
    "<br/>\n",
    "<b>SDK å’Œ API çš„åŒºåˆ«æ˜¯ä»€ä¹ˆ?</b> https://aws.amazon.com/cn/compare/the-difference-between-sdk-and-api/\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30361cf7-ec31-4c45-871e-28ac4f0db1a9",
   "metadata": {},
   "source": [
    "#### ğŸŒ° ä¸¾ä¸ªä¾‹å­ï¼šä½¿ç”¨ SDKï¼Œ4 è¡Œä»£ç å®ç°ä¸€ä¸ªç®€æ˜“çš„ RAG ç³»ç»Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517bfe1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<p>LlamaIndex é»˜è®¤çš„ Embedding æ¨¡å‹æ˜¯ <code>OpenAIEmbedding(model=\"text-embedding-ada-002\")</code></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03dc82-649d-4fe8-8ba5-023220c8cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade llama-index\n",
    "\n",
    "# !pip install llama-index-llms-dashscope\n",
    "# !pip install llama-index-llms-openai-like\n",
    "# !pip install llama-index-embeddings-dashscope"
   ]
  },
  {
   "cell_type": "code",
   "id": "f36875ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:00:34.530504Z",
     "start_time": "2025-05-20T11:00:32.749235Z"
    }
   },
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.llms.dashscope import DashScope, DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "\n",
    "# LlamaIndexé»˜è®¤ä½¿ç”¨çš„å¤§æ¨¡å‹è¢«æ›¿æ¢ä¸ºç™¾ç‚¼\n",
    "# Settings.llm = OpenAILike(\n",
    "#     model=\"qwen-max\",\n",
    "#     api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "#     api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "#     is_chat_model=True\n",
    "# )\n",
    "\n",
    "Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "\n",
    "# LlamaIndexé»˜è®¤ä½¿ç”¨çš„Embeddingæ¨¡å‹è¢«æ›¿æ¢ä¸ºç™¾ç‚¼çš„Embeddingæ¨¡å‹\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    # model_name=\"text-embedding-v1\"\n",
    "    model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1,\n",
    "    # api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "dea32ce7-c7a7-4692-a217-45cf632281ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:00:41.907038Z",
     "start_time": "2025-05-20T11:00:38.410963Z"
    }
   },
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "# index.storage_context.persist(persist_dir=\"./storage\")\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"deepseek v3æœ‰å¤šå°‘å‚æ•°ï¼Ÿ\")\n",
    "\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3 æ‹¥æœ‰æ€»è®¡ 6710 äº¿å‚æ•°ï¼Œå…¶ä¸­æ¯ä¸ª token æ¿€æ´» 370 äº¿å‚æ•°ã€‚\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "24e4c617-2fb8-489d-a0d0-34d5ca196f1c",
   "metadata": {},
   "source": [
    "## 2. LlamaIndex ä»‹ç»\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313487e1-a2c7-4d4b-ad41-e3a9f0a0b07e",
   "metadata": {},
   "source": [
    "å®˜ç½‘æ ‡é¢˜ï¼š_ã€Œ Build AI Knowledge Assistants over your enterprise data ã€_\n",
    "\n",
    "LlamaIndex æ˜¯ä¸€ä¸ªä¸ºå¼€å‘ã€ŒçŸ¥è¯†å¢å¼ºã€çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ï¼ˆä¹Ÿå°±æ˜¯ SDKï¼‰ã€‚**çŸ¥è¯†å¢å¼º**ï¼Œæ³›æŒ‡ä»»ä½•åœ¨ç§æœ‰æˆ–ç‰¹å®šé¢†åŸŸæ•°æ®åŸºç¡€ä¸Šåº”ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼š\n",
    "\n",
    "<img src=\"./assets/basic_rag.png\" width=800px>\n",
    "\n",
    "- Question-Answering Chatbots (ä¹Ÿå°±æ˜¯ RAG)\n",
    "- Document Understanding and Extraction ï¼ˆæ–‡æ¡£ç†è§£ä¸ä¿¡æ¯æŠ½å–ï¼‰\n",
    "\n",
    "- Autonomous Agents that can perform research and take actions ï¼ˆæ™ºèƒ½ä½“åº”ç”¨ï¼‰\n",
    "- Workflow orchestrating single and multi-agent (ç¼–æ’å•ä¸ªæˆ–å¤šä¸ªæ™ºèƒ½ä½“å½¢æˆå·¥ä½œæµï¼‰\n",
    "\n",
    "LlamaIndex æœ‰ Python å’Œ Typescript ä¸¤ä¸ªç‰ˆæœ¬ï¼ŒPython ç‰ˆçš„æ–‡æ¡£ç›¸å¯¹æ›´å®Œå–„ã€‚\n",
    "\n",
    "- Python æ–‡æ¡£åœ°å€ï¼šhttps://docs.llamaindex.ai/en/stable/\n",
    "- Python API æ¥å£æ–‡æ¡£ï¼šhttps://docs.llamaindex.ai/en/stable/api_reference/\n",
    "\n",
    "- TS æ–‡æ¡£åœ°å€ï¼šhttps://ts.llamaindex.ai/\n",
    "\n",
    "LlamaIndex æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/run-llama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4822b2-52d5-411c-8244-3432f8733da2",
   "metadata": {},
   "source": [
    "### LlamaIndex çš„æ ¸å¿ƒæ¨¡å—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474b43-018a-4687-a51e-54b391a6bbca",
   "metadata": {},
   "source": [
    "<img src=\"./assets/llamaindex.png\" alt=\"LlamaIndex æ ¸å¿ƒæ¨¡å—\" width=\"1400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66bf37-48e4-45eb-9e7e-a24e86108ac1",
   "metadata": {},
   "source": [
    "### å®‰è£… LlamaIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bba90",
   "metadata": {},
   "outputs": [],
   "source": "# ï¼pip install -U llama-index"
  },
  {
   "cell_type": "markdown",
   "id": "74341a28-fb7f-4e5b-9342-cf5cd850654a",
   "metadata": {},
   "source": [
    "## 3.æ•°æ®åŠ è½½ï¼ˆLoadingï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d134a56-ae9a-41a5-a703-ce9dfb3fc600",
   "metadata": {},
   "source": [
    "### 3.1ã€åŠ è½½æœ¬åœ°æ•°æ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bfa25-9a09-4c40-afa1-9f9156e56dc2",
   "metadata": {},
   "source": [
    "`SimpleDirectoryReader` æ˜¯ä¸€ä¸ªç®€å•çš„æœ¬åœ°æ–‡ä»¶åŠ è½½å™¨ã€‚å®ƒä¼šéå†æŒ‡å®šç›®å½•ï¼Œå¹¶æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨åŠ è½½æ–‡ä»¶ï¼ˆ**æ–‡æœ¬å†…å®¹**ï¼‰ã€‚\n",
    "\n",
    "æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š\n",
    "\n",
    "- `.csv` - comma-separated values\n",
    "- `.docx` - Microsoft Word\n",
    "- `.epub` - EPUB ebook format\n",
    "- `.hwp` - Hangul Word Processor\n",
    "- `.ipynb` - Jupyter Notebook\n",
    "- `.jpeg`, `.jpg` - JPEG image\n",
    "- `.mbox` - MBOX email archive\n",
    "- `.md` - Markdown\n",
    "- `.mp3`, `.mp4` - audio and video\n",
    "- `.pdf` - Portable Document Format\n",
    "- `.png` - Portable Network Graphics\n",
    "- `.ppt`, `.pptm`, `.pptx` - Microsoft PowerPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "05b6a279-3eca-4685-af91-80fb443fca1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:00:47.583209Z",
     "start_time": "2025-05-20T11:00:47.579904Z"
    }
   },
   "source": [
    "import json\n",
    "from pydantic.v1 import BaseModel\n",
    "\n",
    "def show_json(data):\n",
    "    \"\"\"ç”¨äºå±•ç¤ºjsonæ•°æ®\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        obj = json.loads(data)\n",
    "        print(json.dumps(obj, indent=4, ensure_ascii=False))\n",
    "    elif isinstance(data, dict) or isinstance(data, list):\n",
    "        print(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "    elif issubclass(type(data), BaseModel):\n",
    "        print(json.dumps(data.dict(), indent=4, ensure_ascii=False))\n",
    "\n",
    "def show_list_obj(data):\n",
    "    \"\"\"ç”¨äºå±•ç¤ºä¸€ç»„å¯¹è±¡\"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            show_json(item)\n",
    "    else:\n",
    "        raise ValueError(\"Input is not a list\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "198ebc20-fab6-46a9-8cca-4b114fe2640f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:23:04.172365Z",
     "start_time": "2025-05-20T03:23:04.122703Z"
    }
   },
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "        input_dir=\"./data\", # ç›®æ ‡ç›®å½•\n",
    "        recursive=False, # æ˜¯å¦é€’å½’éå†å­ç›®å½•\n",
    "        required_exts=[\".pdf\"] # (å¯é€‰)åªè¯»å–æŒ‡å®šåç¼€çš„æ–‡ä»¶\n",
    "    )\n",
    "documents = reader.load_data()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "dfb3f1ac-75cb-4c5e-b0a1-53621d8d325e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:23:06.832093Z",
     "start_time": "2025-05-20T03:23:06.829777Z"
    }
   },
   "source": [
    "print(documents[0].text)\n",
    "show_json(documents[0].json())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100Accuracy / Percentile (%)\n",
      "75.9\n",
      "59.1\n",
      "90.2\n",
      "39.2\n",
      "51.6\n",
      "42.0\n",
      "66.2\n",
      "41.3\n",
      "74.7\n",
      "16.7\n",
      "35.6\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3 24.8 23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3 24.5\n",
      "72.6\n",
      "49.9\n",
      "74.6\n",
      "9.3\n",
      "23.6\n",
      "38.8\n",
      "78.0\n",
      "65.0\n",
      "78.3\n",
      "16.0\n",
      "20.3\n",
      "50.8\n",
      "DeepSeek-V3 DeepSeek-V2.5 Qwen2.5-72B-Inst Llama-3.1-405B-Inst GPT-4o-0513 Claude-3.5-Sonnet-1022\n",
      "Figure 1 |Benchmark performance of DeepSeek-V3 and its counterparts.\n",
      "arXiv:2412.19437v2  [cs.CL]  18 Feb 2025\n",
      "{\n",
      "    \"id_\": \"583ed317-f1fb-444a-bb6f-a53645bca5b3\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"page_label\": \"1\",\n",
      "        \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "        \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 192218,\n",
      "        \"creation_date\": \"2025-05-19\",\n",
      "        \"last_modified_date\": \"2025-03-12\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"excluded_llm_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"relationships\": {},\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_separator\": \"\\n\",\n",
      "    \"text_resource\": {\n",
      "        \"embeddings\": null,\n",
      "        \"text\": \"DeepSeek-V3 Technical Report\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\\nparameters with 37B activated for each token. To achieve efficient inference and cost-effective\\ntraining, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\\ntures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\\nan auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\\nobjective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\\nhigh-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\\nfully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\\nother open-source models and achieves performance comparable to leading closed-source\\nmodels. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\\nfor its full training. In addition, its training process is remarkably stable. Throughout the entire\\ntraining process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\\nThe model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\\nMMLU-Pro\\n(EM)\\nGPQA-Diamond\\n(Pass@1)\\nMATH 500\\n(EM)\\nAIME 2024\\n(Pass@1)\\nCodeforces\\n(Percentile)\\nSWE-bench Verified\\n(Resolved)\\n0\\n20\\n40\\n60\\n80\\n100Accuracy / Percentile (%)\\n75.9\\n59.1\\n90.2\\n39.2\\n51.6\\n42.0\\n66.2\\n41.3\\n74.7\\n16.7\\n35.6\\n22.6\\n71.6\\n49.0\\n80.0\\n23.3 24.8 23.8\\n73.3\\n51.1\\n73.8\\n23.3\\n25.3 24.5\\n72.6\\n49.9\\n74.6\\n9.3\\n23.6\\n38.8\\n78.0\\n65.0\\n78.3\\n16.0\\n20.3\\n50.8\\nDeepSeek-V3 DeepSeek-V2.5 Qwen2.5-72B-Inst Llama-3.1-405B-Inst GPT-4o-0513 Claude-3.5-Sonnet-1022\\nFigure 1 |Benchmark performance of DeepSeek-V3 and its counterparts.\\narXiv:2412.19437v2  [cs.CL]  18 Feb 2025\",\n",
      "        \"path\": null,\n",
      "        \"url\": null,\n",
      "        \"mimetype\": null\n",
      "    },\n",
      "    \"image_resource\": null,\n",
      "    \"audio_resource\": null,\n",
      "    \"video_resource\": null,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"class_name\": \"Document\",\n",
      "    \"text\": \"DeepSeek-V3 Technical Report\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\\nparameters with 37B activated for each token. To achieve efficient inference and cost-effective\\ntraining, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\\ntures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\\nan auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\\nobjective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\\nhigh-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\\nfully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\\nother open-source models and achieves performance comparable to leading closed-source\\nmodels. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\\nfor its full training. In addition, its training process is remarkably stable. Throughout the entire\\ntraining process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\\nThe model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\\nMMLU-Pro\\n(EM)\\nGPQA-Diamond\\n(Pass@1)\\nMATH 500\\n(EM)\\nAIME 2024\\n(Pass@1)\\nCodeforces\\n(Percentile)\\nSWE-bench Verified\\n(Resolved)\\n0\\n20\\n40\\n60\\n80\\n100Accuracy / Percentile (%)\\n75.9\\n59.1\\n90.2\\n39.2\\n51.6\\n42.0\\n66.2\\n41.3\\n74.7\\n16.7\\n35.6\\n22.6\\n71.6\\n49.0\\n80.0\\n23.3 24.8 23.8\\n73.3\\n51.1\\n73.8\\n23.3\\n25.3 24.5\\n72.6\\n49.9\\n74.6\\n9.3\\n23.6\\n38.8\\n78.0\\n65.0\\n78.3\\n16.0\\n20.3\\n50.8\\nDeepSeek-V3 DeepSeek-V2.5 Qwen2.5-72B-Inst Llama-3.1-405B-Inst GPT-4o-0513 Claude-3.5-Sonnet-1022\\nFigure 1 |Benchmark performance of DeepSeek-V3 and its counterparts.\\narXiv:2412.19437v2  [cs.CL]  18 Feb 2025\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "277be7f4-1993-4b74-bd3e-f9d8cb5a827d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b>å¯¹å›¾åƒã€è§†é¢‘ã€è¯­éŸ³ç±»æ–‡ä»¶ï¼Œé»˜è®¤ä¸ä¼šè‡ªåŠ¨æå–å…¶ä¸­æ–‡å­—ã€‚å¦‚éœ€æå–ï¼Œå‚è€ƒä¸‹é¢ä»‹ç»çš„ <code>Data Connectors</code>ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c98851-0858-4215-858d-bea70e310d5f",
   "metadata": {},
   "source": [
    " é»˜è®¤çš„ `PDFReader` æ•ˆæœå¹¶ä¸ç†æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ¢æ–‡ä»¶åŠ è½½å™¨\n",
    "\n",
    "<b>LlamaParse</b>\n",
    "\n",
    "é¦–å…ˆï¼Œç™»å½•å¹¶ä» https://cloud.llamaindex.ai â†— æ³¨å†Œå¹¶è·å– api-key ã€‚\n",
    "\n",
    "ç„¶åï¼Œå®‰è£…è¯¥åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-cloud-services"
   ]
  },
  {
   "cell_type": "code",
   "id": "b093a88b-5d4a-423b-bfe7-fa28b34744e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T10:00:30.189695Z",
     "start_time": "2025-05-20T10:00:21.372930Z"
    }
   },
   "source": [
    "# åœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡é‡Œé…ç½® LLAMA_CLOUD_API_KEY=XXX\n",
    "\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_cloud_services.parse import ResultType\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio, os\n",
    "nest_asyncio.apply() # åªåœ¨Jupyterç¬”è®°ç¯å¢ƒä¸­éœ€è¦æ­¤æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™\n",
    "\n",
    "# set up parser\n",
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    result_type=ResultType.MD  # \"markdown\" and \"text\" are available\n",
    ")\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "documents = SimpleDirectoryReader(input_dir=\"./data\", required_exts=[\".pdf\"], file_extractor=file_extractor).load_data()\n",
    "print(documents[0].text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id e164d61e-7800-43fb-b013-de9c5a8ab9fb\n",
      "# DeepSeek-V3 Technical Report\n",
      "\n",
      "# DeepSeek-AI\n",
      "\n",
      "research@deepseek.com\n",
      "\n",
      "# Abstract\n",
      "\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "\n",
      "|DeepSeek-V3|DeepSeek-V2.5|Qwen2.5-72B-Inst|Llama-3.1-405B-Inst|GPT-4o-0513|Claude-3.5-Sonnet-1022| |\n",
      "|---|---|---|---|---|---|---|\n",
      "|100|90.2| | | | | |\n",
      "|80|75.9|71.6|73.3|72.6|78.0| |\n",
      "| |74.7|80.0|73.8|74.6|78.3| |\n",
      "|66.2| |65.0| | | | |\n",
      "|60| |59.1| | | | |\n",
      "|49.0|51.1|49.9| |51.6|50.8| |\n",
      "|40|41.3|39.2| |42.0|38.8| |\n",
      "| | | | |35.6| | |\n",
      "|20| | | |20.3| | |\n",
      "| |16.7|16.0| |9.3| | |\n",
      "|0|MMLU-Pro|GPQA-Diamond|MATH 500|AIME 2024|Codeforces|SWE-bench Verified|\n",
      "\n",
      "Figure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a116d296-e4a4-4710-a41a-318bbab8ec24",
   "metadata": {},
   "source": [
    "### 3.2ã€Data Connectors\n",
    "\n",
    "ç”¨äºå¤„ç†æ›´ä¸°å¯Œçš„æ•°æ®ç±»å‹ï¼Œå¹¶å°†å…¶è¯»å–ä¸º `Document` çš„å½¢å¼ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼šç›´æ¥è¯»å–ç½‘é¡µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19471210-6cb3-4822-8bad-dc701b6ab335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-readers-web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d73abf3-91df-488c-a5f3-c7de0c6d4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login\n",
      "\n",
      "__\n",
      "\n",
      "ç”¨æˆ·ç™»å½•\n",
      "\n",
      "![](/api/Ajax/vertify/type/users_login.html)\n",
      "\n",
      "[ ç™»å½•](javascript:void\\(0\\))\n",
      "\n",
      "[å¿˜è®°å¯†ç ?](/user/Users/retrieve_password.html) [ç«‹å³æ³¨å†Œ](/reg)\n",
      "\n",
      "å¿«æ·ç™»å½• | [__](/index.php?m=plugins&c=QqLogin&a=login)[__](/index.php?m=plugins&c=WxLogin&a=login)[__](/index.php?m=plugins&c=Wblogin&a=login)\n",
      "\n",
      "[\n",
      "![èšå®¢AIå­¦é™¢å¤§æ¨¡å‹åº”ç”¨å¼€å‘å¾®è°ƒé¡¹ç›®å®è·µè¯¾ç¨‹å­¦ä¹ å¹³å°](https://oss.guangjuke.com/uploads/allimg/20250224/1-250224200331L9.png)\n",
      "](https://edu.guangjuke.com)\n",
      "\n",
      "[é¦–é¡µ](https://edu.guangjuke.com)\n",
      "[å…¨éƒ¨è¯¾ç¨‹](https://edu.guangjuke.com/shipinkecheng/)\n",
      "[èµ„æºä¸‹è½½](https://edu.guangjuke.com/ziyuanxiazai/)\n",
      "[ç³»ç»Ÿè¯¾](https://edu.guangjuke.com/tx/)\n",
      "[å›¾ä¹¦é¦†](https://edu.guangjuke.com/document.html)\n",
      "[ç²¾é€‰å¥½æ–‡](https://edu.guangjuke.com/haowen/)\n",
      "[èšå®¢ç¤¾åŒº](https://edu.guangjuke.com/ask.html)\n",
      "[å…³äºæˆ‘ä»¬](https://www.guangjuke.com/about/)\n",
      "\n",
      "[ç™»å½•/æ³¨å†Œ](https://edu.guangjuke.com/user)\n",
      "\n",
      "![](/template/pc/static/images/banner-tip-bar.28e923ae.png)\n",
      "\n",
      "# é”¤ç‚¼å‰æ²¿å®æˆ˜ç²¾åï¼Œç‹¬åˆ›å¤šé¢†åŸŸå¤§æ¨¡å‹äººæ‰åŸ¹å…»æ–¹æ¡ˆ\n",
      "\n",
      "Kevinèšå®¢ç§‘æŠ€è”åˆåˆ›å§‹äºº/æŠ€æœ¯æ€»ç›‘ï¼ˆCTOï¼‰\n",
      "\n",
      "åä¸ºé«˜çº§æ¶æ„å¸ˆäº’è”ç½‘AIé¢†åŸŸä¸“å®¶\n",
      "\n",
      "äº’è”ç½‘åç«¯æŠ€æœ¯é¢†åŸŸ15å¹´ä»ä¸šç»éªŒï¼Œæ›¾ä»»èŒåä¸ºã€æ–°ä¸€ä»£æŠ€æœ¯ç ”ç©¶é™¢ï¼Œå¯¹Open AIã€Azure AIã€Google AIç­‰å¤§æ¨¡å‹æœ‰ä¸°å¯Œçš„å®æˆ˜é¡¹ç›®ç»éªŒã€‚\n",
      "\n",
      "Aronäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ç ”ç©¶å‘˜\n",
      "\n",
      "äººå·¥æ™ºèƒ½ç®—æ³•ç ”ç©¶å‘˜åŒ»ç–—é¢†åŸŸAIä¸“å®¶\n",
      "\n",
      "8å¹´æ·±åº¦å­¦ä¹ ç®—æ³•ç ”å‘ç»éªŒï¼Œç²¾é€šæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæœ‰ä¸°å¯Œçš„GPUæ¨¡å‹åŠ é€Ÿï¼Œç§»åŠ¨ç«¯æ¨¡å‹åŠ é€Ÿï¼Œæ¨¡å‹ä¼˜åŒ–ï¼Œæ¨¡å‹éƒ¨ç½²ç»éªŒ ã€‚\n",
      "\n",
      "BoboAIç³»åˆ—è¯¾ç¨‹çš„å¸ƒé“è€…\n",
      "\n",
      "äº’è”ç½‘AIæŠ€æœ¯ä¸“å®¶ä¼ä¸šé«˜çº§æ¶æ„å¸ˆ\n",
      "\n",
      "äº’è”ç½‘åç«¯æŠ€æœ¯é¢†åŸŸ15å¹´ä»ä¸šç»éªŒï¼Œæ›¾åœ¨çŸ¥åä¼ä¸šç”¨å‹ã€åç”µå’Œç™¾ä¸½æ‹…ä»»è¦èŒã€‚å†ä»»é«˜çº§è½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆã€ç³»ç»Ÿæ¶æ„å¸ˆåŠé¦–å¸­æŠ€æœ¯å®˜ï¼ˆCTOï¼‰ã€‚\n",
      "\n",
      "Annyå›½å®¶å·¥ä¿¡éƒ¨AIè®¤è¯ä¸“å®¶\n",
      "\n",
      "é«˜çº§Pythonå·¥ç¨‹å¸ˆé¦–æ‰¹å¤§æ¨¡å‹ç ”å‘è€…\n",
      "\n",
      "æ•°åå¹´å¼€å‘ç»éªŒï¼Œæ·±è€•å¤§æ•°æ®ã€æ™ºèƒ½ä½“ã€å¤§æ¨¡å‹å‚ç›´åº”ç”¨è§£å†³æ–¹æ¡ˆã€AIåº”ç”¨å·¥ç¨‹ç­‰é¢†åŸŸã€‚\n",
      "\n",
      "Rayæ·±åº¦äººå·¥æ™ºèƒ½æ•™è‚²åˆ›å§‹äºº\n",
      "\n",
      "é«˜çº§AIç®—æ³•å·¥ç¨‹å¸ˆæ·±åº¦æ™ºè°·ç§‘æŠ€åˆ›å§‹äºº\n",
      "\n",
      "5å¹´äººå·¥æ™ºèƒ½ç®—æ³•é¢†åŸŸç ”å‘ç»éªŒï¼Œ6å¹´äººå·¥æ™ºèƒ½æ•™å­¦ç»éªŒï¼Œå…·å¤‡æ‰å®çš„äººå·¥æ™ºèƒ½ç®—æ³•ç†è®ºåŸºç¡€çŸ¥è¯†å’Œä¸°å¯Œçš„é¡¹ç›®å®æˆ˜ç»éªŒ.\n",
      "\n",
      "Cyber\n",
      "\n",
      "é‡‘èå¤§å‚æ¶æ„å¸ˆäº’è”ç½‘è¿ç»­åˆ›ä¸šè€…\n",
      "\n",
      "AIäººå·¥æ™ºèƒ½é¢†åŸŸ6å¹´ä»ä¸šç»éªŒï¼Œå¯¹Open AIã€Azure AIã€Google AIã€SD AIç­‰AIå¤§æ¨¡å‹æœ‰ä¸°å¯Œçš„å®æˆ˜é¡¹ç›®ç»éªŒã€‚\n",
      "\n",
      "#### ç¦åˆ©ä¸€ï¼šé«˜æ€§èƒ½GPUèµ„æº\n",
      "\n",
      "æä¾›å­¦ä¹ é˜¶æ®µè¿›è¡Œè®­ç»ƒçš„çº¿ä¸Šå®éªŒå®¤ç®—åŠ›èµ„æºï¼Œå¸®åŠ©å­¦ç”Ÿè¿›è¡Œå­¦ä¹ é˜¶æ®µçš„æ¨¡å‹è®­ç»ƒã€ç»ƒä¹ ã€‚\n",
      "\n",
      "#### ç¦åˆ©äºŒï¼šå¤§æ¨¡å‹é¡¹ç›®èµ„æºåº“\n",
      "\n",
      "è¶…å€¼é™„èµ å¤§é‡å¤§æ¨¡å‹é¡¹ç›®èµ„æºåº“ï¼ŒåŒ…æ‹¬ä¸°å¯Œçš„ä»£ç ç¤ºä¾‹å’Œæ•°æ®é›†ï¼Œä¾›å­¦å‘˜åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä½¿ç”¨å’Œå‚è€ƒï¼ŒåŠ é€Ÿå­¦å‘˜çš„é¡¹ç›®å®è·µå’ŒæŠ€èƒ½æå‡ã€‚\n",
      "\n",
      "æ‰«ç æ·»åŠ ä¸“å±è€å¸ˆ  \n",
      "è·å–æ›´å¤šç¦åˆ©ä¿¡æ¯\n",
      "\n",
      "# å…­å¤§æ¨¡å—é€’è¿›å¼å­¦ä¹ ï¼Œæ›´é¡ºæ»‘ã€æ›´é«˜æ•ˆå®ç°å¤§æ¨¡å‹èƒ½åŠ›è·ƒè¿\n",
      "\n",
      "Hugging Faceæ ¸å¿ƒç»„ä»¶ä½¿ç”¨\n",
      "\n",
      "æ¨¡å‹éƒ¨ç½²æ¨ç†\n",
      "\n",
      "Datasetsæ•°æ®å·¥ç¨‹\n",
      "\n",
      "DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒ\n",
      "\n",
      "SFTå¾®è°ƒè®­ç»ƒ\n",
      "\n",
      "æ¨¡å‹åˆå¹¶ã€æ‰“åŒ…ã€éƒ¨ç½²\n",
      "\n",
      "æ¨¡å‹é‡åŒ–æ ¸å¿ƒç®—æ³•ä¸æœ€ä½³å®è·µ\n",
      "\n",
      "æ¨¡å‹è’¸é¦åŸç†åŠåŠ¨æ‰‹å®è·µ\n",
      "\n",
      "æ¨¡å‹è¯„ä¼°æ–¹æ³•å’Œæœ€ä½³å®è·µ\n",
      "\n",
      "é¡¹ç›®  \n",
      "åœºæ™¯\n",
      "\n",
      "1ã€åŸºäº Bert çš„ä¸­æ–‡è¯„ä»·æƒ…æ„Ÿåˆ†æï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰      2ã€å®šåˆ¶åŒ–æ¨¡å‹è¾“å‡ºï¼ˆç”Ÿæˆä»»åŠ¡ï¼‰      3ã€åŸºäºç‰¹å®šæ•°æ®é›†è®­ç»ƒæƒ…ç»ªå¯¹è¯æ¨¡å‹\n",
      "\n",
      "RAGå·¥ç¨‹åŒ–\n",
      "\n",
      "Embedding ModelsåµŒå…¥æ¨¡å‹åŸç†\n",
      "\n",
      "Vector Storeå‘é‡å­˜å‚¨\n",
      "\n",
      "LlamaIndexæ¡†æ¶æ·±åº¦åº”ç”¨\n",
      "\n",
      "Dify LLMOps\n",
      "\n",
      "RAGæ–¹æ¡ˆæœ€ä½³å®è·µ\n",
      "\n",
      "é¡¹ç›®  \n",
      "åœºæ™¯\n",
      "\n",
      "1ã€åŸºäº DeepSeek + Dify å¿«é€Ÿæ„å»ºç§æœ‰çŸ¥è¯†åº“      2ã€æ³•å¾‹åŠ©æ‰‹ - åŸºäº LlamaIndex + Chroma æ„å»ºæ³•å¾‹æ¡æ–‡åŠ©æ‰‹\n",
      "\n",
      "æ™ºèƒ½ä½“åŸç†æ·±åº¦å‰–æ\n",
      "\n",
      "å¼ºåŒ–å­¦ä¹ \n",
      "\n",
      "Dify Agentåº”ç”¨\n",
      "\n",
      "LangGraph æ¡†æ¶æ·±åº¦å­¦ä¹ \n",
      "\n",
      "é¡¹ç›®  \n",
      "åœºæ™¯\n",
      "\n",
      "1ã€åŸºäº Dify å¿«é€Ÿæ„å»ºæ™ºèƒ½ä½“åº”ç”¨      2ã€åŸºäº LangGraph æ„å»ºä¼ä¸šçº§å¤æ‚å¤šä»£ç†åº”ç”¨\n",
      "\n",
      "æ·±å…¥ç†è§£DeepSeekè®¾è®¡æ€æƒ³å’Œè®­ç»ƒè¿‡ç¨‹\n",
      "\n",
      "DeepSeekæœ¬åœ°éƒ¨ç½²ï¼Œå¤šå¡è”åˆéƒ¨ç½²ï¼ŒvLLMå¤šå¡æ¨ç†\n",
      "\n",
      "DeepSeekå¾®è°ƒè®­ç»ƒ/å¤šå¡è®­ç»ƒ\n",
      "\n",
      "è§£é”  \n",
      "æŠ€èƒ½\n",
      "\n",
      "æŒæ¡ DeepSeek æœ¬åœ°éƒ¨ç½²åŠä¼ä¸šè½åœ°åœºæ™¯\n",
      "\n",
      "æ¨¡æ€ä¸å¤šæ¨¡æ€çš„æ¦‚å¿µ\n",
      "\n",
      "å¤šæ¨¡æ€æœºå™¨å­¦ä¹ ä¸å…¸å‹ä»»åŠ¡\n",
      "\n",
      "æœ¬åœ°ç§æœ‰åŒ–éƒ¨ç½²å›¾æ–‡æè¿°æ¨¡å‹\n",
      "\n",
      "æœ¬åœ°ç§æœ‰åŒ–éƒ¨ç½²æ–‡ç”Ÿè§†é¢‘æ¨¡å‹\n",
      "\n",
      "æœ¬åœ°éƒ¨ç½² Llama-3.2-11B-Vision-Instruct-GGUF å®ç°è§†è§‰é—®ç­”\n",
      "\n",
      "è§£é”  \n",
      "æŠ€èƒ½\n",
      "\n",
      "æŒæ¡å¤šæ¨¡æ€å¤§æ¨¡å‹è§£å†³å…¸å‹ä»»åŠ¡ï¼šè·¨æ¨¡æ€é¢„è®­ç»ƒ/Language-Audio / Vision-Audio / Vision-Language/å®šä½ç›¸å…³ä»»åŠ¡  \n",
      "Affect Computing æƒ…æ„Ÿè®¡ç®—/Medical Image åŒ»ç–—å›¾åƒæ¨¡æ€\n",
      "\n",
      "å¤šå¥—é«˜è–ªOfferçš„AIå¤§æ¨¡å‹ç®€å†åˆ†äº«åŠå‚è€ƒ\n",
      "\n",
      "ç®€å†é¡¹ç›®1å¯¹1ä¸ªæ€§åŒ–æŒ‡å¯¼\n",
      "\n",
      "æŠ€æœ¯æ¨¡æ‹Ÿé¢è¯•1å¯¹1æŒ‡å¯¼\n",
      "\n",
      "è§£é”  \n",
      "æŠ€èƒ½\n",
      "\n",
      "é«˜æ•ˆå†™å‡ºé«˜å«é‡‘é‡çš„AIæŠ€æœ¯ç®€å† / é¡¹ç›®åœºæ™¯æ¨¡æ‹Ÿé¢è¯•\n",
      "\n",
      "# åœºæ™¯åŒ–æ·±åº¦è½åœ°å®è·µï¼Œå¤šé‡ç»´åº¦æ„å»ºèƒ½åŠ›æ¨¡å‹\n",
      "\n",
      "![](/template/pc/static/images/shizhan1.png)\n",
      "\n",
      "  * åŸºäºLlamaIndexæ„å»ºä¼ä¸šç§æœ‰çŸ¥è¯†åº“ï¼ˆRAGé¡¹ç›®ï¼‰ \n",
      "  * åŸºäºBertçš„ä¸­æ–‡è¯„ä»·æƒ…æ„Ÿåˆ†æï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰ \n",
      "  * ä¸­æ–‡ç”Ÿæˆæ¨¡å‹å®šåˆ¶åŒ–ï¼ˆç”Ÿæˆä»»åŠ¡ï¼‰ \n",
      "  * åŸºäºæœ¬åœ°å¤§æ¨¡å‹çš„åœ¨çº¿å¿ƒç†é—®è¯Šç³»ç»Ÿï¼ˆå¾®è°ƒé¡¹ç›®ï¼‰ \n",
      "  * ä¼ä¸šæ‹›æ ‡é‡‡è´­æ™ºèƒ½å®¢æœç³»ç»Ÿï¼ˆRAG+å¾®è°ƒé¡¹ç›®ï¼‰ \n",
      "  * åŸºäºYOLOçš„éª¨é¾„è¯†åˆ«é¡¹ç›®ï¼ˆè§†è§‰é¡¹ç›®ï¼‰ \n",
      "  * åŸºäºRAGçš„æ³•å¾‹å’¨è¯¢æ™ºèƒ½åŠ©æ‰‹ \n",
      "\n",
      "# äº”å¤§å…¨æ–¹ä½é—­ç¯ç¡¬æ ¸æœåŠ¡ï¼Œä¸ºä½ çš„å­¦ä¹ å’Œé¢è¯•ä¿é©¾æŠ¤èˆª\n",
      "\n",
      "#### å¤§å®¶è¯´å¥½ï¼Œæ‰æ˜¯çœŸçš„å¥½\n",
      "\n",
      "# æ— è®ºä½ æ˜¯è½¬è¡Œã€è¿›é˜¶ï¼Œéƒ½æ˜¯ä½ çš„ä¸äºŒä¹‹é€‰\n",
      "\n",
      "AIå¤§æ¨¡å‹å·¥ç¨‹å¸ˆä¸“æ³¨äºLLMé¢†åŸŸçš„å·¥ç¨‹å¸ˆï¼Œæ¸´æœ›æ·±å…¥æ¢ç´¢å¤§æ¨¡å‹çš„é«˜çº§åº”ç”¨å’Œè§£å†³æ–¹æ¡ˆè®¾è®¡ã€‚\n",
      "\n",
      "NLPç®—æ³•å·¥ç¨‹å¸ˆå¯»æ±‚LLMå®æˆ˜ç»éªŒï¼Œæå‡ä¸“ä¸šæŠ€èƒ½ï¼Œå¢å¼ºå¤§å‚é¢è¯•ç«äº‰åŠ›ã€‚\n",
      "\n",
      "AIç®—æ³•å·¥ç¨‹å¸ˆå¸Œæœ›è¿…é€ŸæŒæ¡LLMæŠ€æœ¯ï¼Œå®ç°èŒä¸šè½¬å‹æˆ–æ·±åŒ–AIé¢†åŸŸæŠ€èƒ½ã€‚\n",
      "\n",
      "ITè½¬è¡Œæ±‚èŒè€…å¯¹ç°æœ‰ITèŒä¸šä¸æ»¡ï¼Œå¯»æ±‚å‘AIé¢†åŸŸè½¬å‹çš„æ±‚èŒè€…ï¼Œå¯»æ‰¾æŠ€æœ¯è½¬å‹çš„æ–°èµ·ç‚¹ï¼Œå¿«é€Ÿç§¯ç´¯LLMå®æˆ˜ç»éªŒã€‚\n",
      "\n",
      "åœ¨èŒæå‡è€…åœ¨èŒå·¥ç¨‹å¸ˆï¼Œå¸Œæœ›æå‡LLMæŠ€èƒ½ï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œä¸ºèŒä¸šæ™‹å‡æ‰“ä¸‹åšå®åŸºç¡€ã€‚\n",
      "\n",
      "è®¡ç®—æœºåº”å±Šæ¯•ä¸šç”Ÿè®¡ç®—æœºä¸“ä¸šå¸ˆç”Ÿå’Œåº”å±Šæ¯•ä¸šç”Ÿï¼Œè¿½æ±‚å¿«é€ŸæŒæ¡LLMæŠ€èƒ½ï¼Œå¢å¼ºå°±ä¸šç«äº‰åŠ›ã€‚\n",
      "\n",
      "# å­¦å‰æŠ€æœ¯å‚¨å¤‡\n",
      "\n",
      "å…·å¤‡è‰¯å¥½çš„ç¼–ç¨‹èƒ½åŠ›ï¼Œç†Ÿæ‚‰Pythonè¯­è¨€\n",
      "\n",
      "äº†è§£æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ\n",
      "\n",
      "å¯¹å¤§æ¨¡å‹ç®—æ³•æœ‰åˆæ­¥çš„äº†è§£å’Œå…´è¶£\n",
      "\n",
      "å¸®åŠ©ä¸å¸¸è§é—®é¢˜\n",
      "\n",
      "Qï¼šæ˜¯å¦æœ‰åŸºç¡€è¦æ±‚ï¼Ÿ\n",
      "\n",
      "æŒæ¡åŸºæœ¬çš„ Python ç¼–ç¨‹æŠ€èƒ½å³å¯å­¦ä¹ ã€‚\n",
      "\n",
      "Qï¼šæ˜¯å¦æœ‰è¯¦ç»†çš„è¯¾ç¨‹è¡¨ï¼Ÿ\n",
      "\n",
      "æœ‰çš„å“¦ï¼Œå¯ä»¥è”ç³»å®˜æ–¹å®¢æœé¢†å–ã€‚\n",
      "\n",
      "Qï¼šä¸Šè¯¾å½¢å¼å’Œè¯¾æ—¶é‡æ˜¯æ€æ ·çš„å‘¢ï¼Ÿ\n",
      "\n",
      "è¯¾ç¨‹ä¸ºå…¨ç¨‹ç›´æ’­ã€‚è¯¾æ—¶2ä¸ªæœˆå·¦å³\n",
      "\n",
      "Qï¼šç›´æ’­æ˜¯å¦æœ‰å›çœ‹ï¼Ÿ\n",
      "\n",
      "ç›´æ’­çš„å½•æ’­è§†é¢‘ä¼šä¸Šä¼ åˆ°å®˜ç½‘æ–¹ä¾¿å¤§å®¶å›çœ‹ï¼Œä½†ä¸ºäº†æ›´å¥½çš„å­¦ä¹ äº’åŠ¨æ•ˆæœï¼Œå»ºè®®å„ä½å­¦å‘˜æå‰é¢„ç•™å¥½æ—¶é—´ï¼Œå‡†å¤‡å¥½é—®é¢˜ï¼Œå‡†æ—¶å‚åŠ ç›´æ’­ã€‚\n",
      "\n",
      "Q: è¯¾ç¨‹å½•æ’­è§†é¢‘çš„è§‚çœ‹æœŸé™æ˜¯å¤šä¹…ï¼Ÿ\n",
      "\n",
      "ä¸€å¹´æœ‰æ•ˆå­¦ä¹ æƒç›Š\n",
      "\n",
      "Qï¼šå¯ä»¥è·Ÿè€å¸ˆäº’åŠ¨äº¤æµå—ï¼Ÿ\n",
      "\n",
      "å½“ç„¶å•¦ï¼Œæˆ‘ä»¬ä¼šå»ºç«‹ç­çº§ç¤¾ç¾¤ï¼Œç¾¤å†…å¯ä»¥äº’åŠ¨äº¤æµã€‚åŒæ—¶ï¼Œå¤§å®¶è¿˜å¯ä»¥é€šè¿‡ç›´æ’­å‘è€å¸ˆæé—®ã€‚\n",
      "\n",
      "Qï¼šæŠ¥åç¼´è´¹åå¯ä»¥é€€æ¬¾å—ï¼Ÿ\n",
      "\n",
      "ä»˜æ¬¾å 3 ä¸ªè‡ªç„¶æ—¥å†…ï¼Œå¦‚æœè§‰å¾—è¯¾ç¨‹ä¸é€‚åˆè‡ªå·±ï¼Œå¯ç”³è¯·é€€æ¬¾ï¼Œè¶…å‡º 3 ä¸ªè‡ªç„¶æ—¥ï¼Œå°±ä¸å†åŠç†é€€æ¬¾å•¦ã€‚é€€æ¬¾æµç¨‹é¢„è®¡ä¸º 10 ä¸ªå·¥ä½œæ—¥ã€‚\n",
      "\n",
      "Qï¼šå¯ä»¥åˆ†æœŸä»˜æ¬¾å—ï¼Ÿ\n",
      "\n",
      "æˆ‘ä»¬æ”¯æŒèŠ±å‘—ä¿¡ç”¨å¡åˆ†æœŸä»˜æ¬¾ã€‚\n",
      "\n",
      "Q: å¦‚ä½•å¼€å‘ç¥¨ï¼Œç­¾åˆåŒï¼Ÿ\n",
      "\n",
      "æˆ‘ä»¬å¯ä»¥ä¸ºå­¦å‘˜å¼€å…·æ­£è§„çš„å‘ç¥¨å’ŒåˆåŒã€‚å¼€å‘ç¥¨ç›¸å…³äº‹å®œï¼Œè¯·è”ç³»å¸¦ç­ç­ä¸»ä»»ã€‚åˆåŒç›¸å…³äº‹å®œï¼Œè¯·è”ç³»æŠ¥åè€å¸ˆã€‚\n",
      "\n",
      "å¤§å‚æ ‡å‡†åŸ¹è®­\n",
      "\n",
      "æµ·é‡ç²¾å“è¯¾ç¨‹\n",
      "\n",
      "æ±‡èšä¼˜ç§€å›¢é˜Ÿ\n",
      "\n",
      "æ‰“é€ å®Œå–„ä½“ç³»\n",
      "\n",
      "![](/template/pc/skin/images/cxun.gif) ![](/template/pc/skin/images/cxun2.gif)\n",
      "![](/template/pc/skin/images/cxun3.gif)\n",
      "\n",
      "Copyright Â© 2023-2025 èšå®¢AI ç‰ˆæƒæ‰€æœ‰  \n",
      "ç½‘ç«™å¤‡æ¡ˆå·ï¼š[æ¹˜ICPå¤‡2024094305å·-1](https://beian.miit.gov.cn/)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://edu.guangjuke.com/tx/\"]\n",
    ")\n",
    "\n",
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a88893-01b8-44a1-9bed-e93e60cec328",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>æ›´å¤š Data Connectors</b>\n",
    "    <ul>\n",
    "        <li>å†…ç½®çš„<a href=\"https://llamahub.ai/l/readers/llama-index-readers-file\">æ–‡ä»¶åŠ è½½å™¨</a></li>\n",
    "        <li>è¿æ¥ä¸‰æ–¹æœåŠ¡çš„<a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/connector/modules/\">æ•°æ®åŠ è½½å™¨</a>ï¼Œä¾‹å¦‚æ•°æ®åº“</li>\n",
    "        <li>æ›´å¤šåŠ è½½å™¨å¯ä»¥åœ¨ <a href=\"https://llamahub.ai/\">LlamaHub</a> ä¸Šæ‰¾åˆ°</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed8a42-f6fc-430f-9e92-07736e7f359c",
   "metadata": {},
   "source": [
    "## 4. æ–‡æœ¬åˆ‡åˆ†ä¸è§£æï¼ˆChunkingï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad7ebd-9e56-47f9-8136-2e1098139c01",
   "metadata": {},
   "source": [
    "ä¸ºæ–¹ä¾¿æ£€ç´¢ï¼Œæˆ‘ä»¬é€šå¸¸æŠŠ `Document` åˆ‡åˆ†ä¸º `Node`ã€‚\n",
    "\n",
    "åœ¨ LlamaIndex ä¸­ï¼Œ`Node` è¢«å®šä¹‰ä¸ºä¸€ä¸ªæ–‡æœ¬çš„ã€Œchunkã€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881c7d9-9107-4704-b322-d3bc34af96f2",
   "metadata": {},
   "source": [
    "### 4.1ã€ä½¿ç”¨ TextSplitters å¯¹æ–‡æœ¬åšåˆ‡åˆ†\n",
    "\n",
    "ä¾‹å¦‚ï¼š`TokenTextSplitter` æŒ‰æŒ‡å®š token æ•°åˆ‡åˆ†æ–‡æœ¬\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "69a083f7-cda9-45d9-be3e-397ce866e440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T10:53:26.157643Z",
     "start_time": "2025-05-20T10:53:26.142369Z"
    }
   },
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=512,  # æ¯ä¸ª chunk çš„æœ€å¤§é•¿åº¦\n",
    "    chunk_overlap=200  # chunk ä¹‹é—´é‡å é•¿åº¦\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    documents, show_progress=False\n",
    ")\n",
    "len(nodes)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T10:53:28.569162Z",
     "start_time": "2025-05-20T10:53:28.566843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "show_json(nodes[1].json())\n",
    "show_json(nodes[2].json())"
   ],
   "id": "81b363de-c5ef-4e20-ad4d-39bccabb3369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id_\": \"4d105334-4581-4c59-86a2-c6485667fd02\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "        \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 192218,\n",
      "        \"creation_date\": \"2025-05-19\",\n",
      "        \"last_modified_date\": \"2025-03-12\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"excluded_llm_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"66d4000d-24ad-4bdd-a908-52167f2b8038\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {\n",
      "                \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "                \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "                \"file_type\": \"application/pdf\",\n",
      "                \"file_size\": 192218,\n",
      "                \"creation_date\": \"2025-05-19\",\n",
      "                \"last_modified_date\": \"2025-03-12\"\n",
      "            },\n",
      "            \"hash\": \"cd50a4c8fb6e8eca1d642700222618bbf1cce09c03977cc29bd4289122caecf7\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"2\": {\n",
      "            \"node_id\": \"0811c0be-3da8-421f-9da7-3afbd2c536bd\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {\n",
      "                \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "                \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "                \"file_type\": \"application/pdf\",\n",
      "                \"file_size\": 192218,\n",
      "                \"creation_date\": \"2025-05-19\",\n",
      "                \"last_modified_date\": \"2025-03-12\"\n",
      "            },\n",
      "            \"hash\": \"844ae33c9af8e7c8e7a5f6b31e3b03dd9fdf8adb467f08225b5a1d6047c8d370\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_separator\": \"\\n\",\n",
      "    \"text\": \"|\\n|---|---|---|---|---|---|---|\\n|100|90.2| | | | | |\\n|80|75.9|71.6|73.3|72.6|78.0| |\\n| |74.7|80.0|73.8|74.6|78.3| |\\n|66.2| |65.0| | | | |\\n|60| |59.1| | | | |\\n|49.0|51.1|49.9| |51.6|50.8| |\\n|40|41.3|39.2| |42.0|38.8| |\\n| | | | |35.6| | |\\n|20| | | |20.3| | |\\n| |16.7|16.0| |9.3| | |\\n|0|MMLU-Pro|GPQA-Diamond|MATH 500|AIME 2024|Codeforces|SWE-bench Verified|\\n\\nFigure 1 | Benchmark performance of DeepSeek-V3 and its counterparts.\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 1372,\n",
      "    \"end_char_idx\": 1798,\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n",
      "{\n",
      "    \"id_\": \"ce0f87aa-f65f-4ed0-a1c4-c3cae3eb26bf\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "        \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 192218,\n",
      "        \"creation_date\": \"2025-05-19\",\n",
      "        \"last_modified_date\": \"2025-03-12\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"excluded_llm_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"64c4e893-9c72-4862-9d0a-b52b0b9eac1b\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {\n",
      "                \"file_path\": \"/Users/wangweijun/PycharmProjects/ai-learn/ai-level-1/ç¬¬4ç« _LlamaIndexçŸ¥è¯†ç®¡ç†ä¸ä¿¡æ¯æ£€ç´¢/data/deepseek-v3-1-4.pdf\",\n",
      "                \"file_name\": \"deepseek-v3-1-4.pdf\",\n",
      "                \"file_type\": \"application/pdf\",\n",
      "                \"file_size\": 192218,\n",
      "                \"creation_date\": \"2025-05-19\",\n",
      "                \"last_modified_date\": \"2025-03-12\"\n",
      "            },\n",
      "            \"hash\": \"ef158d74701492864e309de20bcbe65f7d9ec39dc2c81a758a37d328152b7727\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"node_id\": \"3bb5ba56-a508-4498-8e2f-3f9c9de50b6c\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"c82a67df26473e6046ac82c4e2d161785874c7def13ed67adadc6777735c04bc\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_separator\": \"\\n\",\n",
      "    \"text\": \"# 1. Introduction\\n\\nIn recent years, Large Language Models (LLMs) have been undergoing rapid iteration and evolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap towards Artificial General Intelligence (AGI). Beyond closed-source models, open-source models, including DeepSeek series (DeepSeek-AI, 2024a,b,c; Guo et al., 2024), LLaMA series (AI@Meta, 2024a,b; Touvron et al., 2023a,b), Qwen series (Qwen, 2023, 2024a,b), and Mistral series (Jiang et al., 2023; Mistral, 2024), are also making significant strides, endeavoring to close the gap with their closed-source counterparts. To further push the boundaries of open-source model capabilities, we scale up our models and introduce DeepSeek-V3, a large Mixture-of-Experts (MoE) model with 671B parameters, of which 37B are activated for each token.\\n\\nWith a forward-looking perspective, we consistently strive for strong model performance and economical costs. Therefore, in terms of architecture, DeepSeek-V3 still adopts Multi-head Latent Attention (MLA) (DeepSeek-AI, 2024c) for efficient inference and DeepSeekMoE (Dai et al., 2024) for cost-effective training. These two architectures have been validated in DeepSeek-V2 (DeepSeek-AI, 2024c), demonstrating their capability to maintain robust model performance while achieving efficient training and inference. Beyond the basic architecture, we implement two additional strategies to further enhance the model capabilities. Firstly, DeepSeek-V3 pioneers an auxiliary-loss-free strategy (Wang et al., 2024a) for load balancing, with the aim of minimizing the adverse impact on model performance that arises from the effort to encourage load balancing. Secondly, DeepSeek-V3 employs a multi-token prediction training objective, which we have observed to enhance the overall performance on evaluation benchmarks.\\n\\nIn order to achieve efficient training, we support the FP8 mixed precision training and implement comprehensive optimizations for the training framework. Low-precision training has emerged as a\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 0,\n",
      "    \"end_char_idx\": 2046,\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "d1f56dbf-4247-4a06-a127-2fa1929455f0",
   "metadata": {},
   "source": [
    "LlamaIndex æä¾›äº†ä¸°å¯Œçš„ `TextSplitter`ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- [`SentenceSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_splitter/)ï¼šåœ¨åˆ‡åˆ†æŒ‡å®šé•¿åº¦çš„ chunk åŒæ—¶å°½é‡ä¿è¯å¥å­è¾¹ç•Œä¸è¢«åˆ‡æ–­ï¼›\n",
    "- [`CodeSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/code/)ï¼šæ ¹æ® ASTï¼ˆç¼–è¯‘å™¨çš„æŠ½è±¡å¥æ³•æ ‘ï¼‰åˆ‡åˆ†ä»£ç ï¼Œä¿è¯ä»£ç åŠŸèƒ½ç‰‡æ®µå®Œæ•´ï¼›\n",
    "- [`SemanticSplitterNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/)ï¼šæ ¹æ®è¯­ä¹‰ç›¸å…³æ€§å¯¹å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºç‰‡æ®µã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692f9fb-af99-4bf5-9d4e-c745438173d6",
   "metadata": {},
   "source": [
    "### 4.2ã€ä½¿ç”¨ NodeParsers å¯¹æœ‰ç»“æ„çš„æ–‡æ¡£åšè§£æ\n",
    "\n",
    "ä¾‹å¦‚ï¼š`HTMLNodeParser`è§£æ HTML æ–‡æ¡£\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6f533-a203-42a2-b312-3d89e0cbf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=False).load_data(\n",
    "    [\"https://edu.guangjuke.com/tx/\"]\n",
    ")\n",
    "\n",
    "# é»˜è®¤è§£æ [\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"b\", \"i\", \"u\", \"section\"]\n",
    "parser = HTMLNodeParser(tags=[\"span\"])  # å¯ä»¥è‡ªå®šä¹‰è§£æå“ªäº›æ ‡ç­¾\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc613c-36a8-4afb-871b-097496703eaf",
   "metadata": {},
   "source": [
    "æ›´å¤šçš„ `NodeParser` åŒ…æ‹¬ [`MarkdownNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/markdown/)ï¼Œ[`JSONNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/json/)ç­‰ç­‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8557f-20af-477d-918d-14761a9c986d",
   "metadata": {},
   "source": [
    "## 5. ç´¢å¼•ï¼ˆIndexingï¼‰ä¸æ£€ç´¢ï¼ˆRetrievalï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df338b16-df37-412d-a385-2d1f4b681112",
   "metadata": {},
   "source": [
    "**åŸºç¡€æ¦‚å¿µ**ï¼šåœ¨ã€Œæ£€ç´¢ã€ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œã€Œç´¢å¼•ã€å³`index`ï¼Œ é€šå¸¸æ˜¯æŒ‡ä¸ºäº†å®ç°å¿«é€Ÿæ£€ç´¢è€Œè®¾è®¡çš„ç‰¹å®šã€Œæ•°æ®ç»“æ„ã€ã€‚\n",
    "\n",
    "ç´¢å¼•çš„å…·ä½“åŸç†ä¸å®ç°ä¸æ˜¯æœ¬è¯¾ç¨‹çš„æ•™å­¦é‡ç‚¹ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒï¼š[ä¼ ç»Ÿç´¢å¼•](https://en.wikipedia.org/wiki/Search_engine_indexing)ã€[å‘é‡ç´¢å¼•](https://medium.com/kx-systems/vector-indexing-a-roadmap-for-vector-databases-65866f07daf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd397fe-8932-49de-ac37-bed0b585205c",
   "metadata": {},
   "source": [
    "### 5.1ã€å‘é‡æ£€ç´¢\n",
    "\n",
    "1. `VectorStoreIndex` ç›´æ¥åœ¨å†…å­˜ä¸­æ„å»ºä¸€ä¸ª Vector Store å¹¶å»ºç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ea17e80-d25c-43ac-b9b5-983c6acb3adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:01:12.508888Z",
     "start_time": "2025-05-20T11:01:11.807451Z"
    }
   },
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "\n",
    "# åŠ è½½ pdf æ–‡æ¡£\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./data\", \n",
    "    required_exts=[\".pdf\"],\n",
    ").load_data()\n",
    "\n",
    "# å®šä¹‰ Node Parser\n",
    "node_parser = TokenTextSplitter(chunk_size=512, chunk_overlap=200)\n",
    "\n",
    "# åˆ‡åˆ†æ–‡æ¡£\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# æ„å»º indexï¼Œé»˜è®¤æ˜¯åœ¨å†…å­˜ä¸­\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# å¦å¤–ä¸€ç§å®ç°æ–¹å¼\n",
    "# index = VectorStoreIndex.from_documents(documents=documents, transformations=[SentenceSplitter(chunk_size=512)])\n",
    "\n",
    "# å†™å…¥æœ¬åœ°æ–‡ä»¶\n",
    "# index.storage_context.persist(persist_dir=\"./doc_emb\")\n",
    "\n",
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(\n",
    "    similarity_top_k=2 # è¿”å›2ä¸ªç»“æœ\n",
    ")\n",
    "\n",
    "# æ£€ç´¢\n",
    "results = vector_retriever.retrieve(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·ï¼Ÿ\")\n",
    "\n",
    "print(results[0].text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its\n",
      "reasoning performance. Meanwhile, we also maintain control over the output style and\n",
      "length of DeepSeek-V3.\n",
      "Summary of Core Evaluation Results\n",
      "â€¢ Knowledge: (1) On educational benchmarks such as MMLU, MMLU-Pro, and GPQA,\n",
      "DeepSeek-V3 outperforms all other open-source models, achieving 88.5 on MMLU, 75.9\n",
      "on MMLU-Pro, and 59.1 on GPQA. Its performance is comparable to leading closed-source\n",
      "models like GPT-4o and Claude-Sonnet-3.5, narrowing the gap between open-source\n",
      "and closed-source models in this domain. (2) For factuality benchmarks, DeepSeek-V3\n",
      "demonstrates superior performance among open-source models on both SimpleQA and\n",
      "Chinese SimpleQA. While it trails behind GPT-4o and Claude-Sonnet-3.5 in English factual\n",
      "knowledge (SimpleQA), it surpasses these models in Chinese factual knowledge (Chinese\n",
      "SimpleQA), highlighting its strength in Chinese factual knowledge.\n",
      "â€¢ Code, Math, and Reasoning: (1) DeepSeek-V3 achieves state-of-the-art performance on\n",
      "math-related benchmarks among all non-long-CoT open-source and closed-source models.\n",
      "Notably, it even outperforms o1-preview on specific benchmarks, such as MATH-500,\n",
      "demonstrating its robust mathematical reasoning capabilities. (2) On coding-related tasks,\n",
      "DeepSeek-V3 emerges as the top-performing model for coding competition benchmarks,\n",
      "such as LiveCodeBench, solidifying its position as the leading model in this domain. For\n",
      "engineering-related tasks, while DeepSeek-V3 performs slightly below Claude-Sonnet-3.5,\n",
      "it still outpaces all other models by a significant margin, demonstrating its competitiveness\n",
      "across diverse technical benchmarks.\n",
      "In the remainder of this paper, we first present a detailed exposition of our DeepSeek-V3\n",
      "model architecture (Section 2). Subsequently, we introduce our infrastructures, encompassing\n",
      "our compute clusters, the training framework, the support for FP8 training, the inference\n",
      "deployment\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "90ebec20-7c12-4d2d-a4f4-5cb2abcc5f32",
   "metadata": {},
   "source": [
    "2. ä½¿ç”¨è‡ªå®šä¹‰çš„ Vector Storeï¼Œä»¥ `Qdrant` ä¸ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e7648-0598-4df7-923f-42fe2f172da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-vector-stores-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "id": "a65a38da-3e71-4fa8-872d-eff6b4f3856b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:03:02.305716Z",
     "start_time": "2025-05-20T11:03:01.087764Z"
    }
   },
   "source": [
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "collection_name = \"demo\"\n",
    "collection = client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "# storage: æŒ‡å®šå­˜å‚¨ç©ºé—´\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# åˆ›å»º indexï¼šé€šè¿‡ Storage Context å…³è”åˆ°è‡ªå®šä¹‰çš„ Vector Store\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "\n",
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "# æ£€ç´¢\n",
    "results = vector_retriever.retrieve(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·\")\n",
    "\n",
    "print(results[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 8f52a139-d168-4b48-8f42-3657b8b60523\n",
      "Text: verification and reflection patterns of R1 into DeepSeek-V3 and\n",
      "notably improves its reasoning performance. Meanwhile, we also\n",
      "maintain control over the output style and length of DeepSeek-V3.\n",
      "Summary of Core Evaluation Results â€¢ Knowledge: (1) On educational\n",
      "benchmarks such as MMLU, MMLU-Pro, and GPQA, DeepSeek-V3 outperforms\n",
      "all other open-sou...\n",
      "Score:  0.681\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "9913e5d5-7c84-4833-b21d-2fe440749a63",
   "metadata": {},
   "source": [
    "### 5.2ã€æ›´å¤šç´¢å¼•ä¸æ£€ç´¢æ–¹å¼\n",
    "\n",
    "LlamaIndex å†…ç½®äº†ä¸°å¯Œçš„æ£€ç´¢æœºåˆ¶ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- å…³é”®å­—æ£€ç´¢\n",
    "\n",
    "  - [`BM25Retriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/bm25/)ï¼šåŸºäº tokenizer å®ç°çš„ BM25 ç»å…¸æ£€ç´¢ç®—æ³•\n",
    "  - [`KeywordTableGPTRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableGPTRetriever)ï¼šä½¿ç”¨ GPT æå–æ£€ç´¢å…³é”®å­—\n",
    "  - [`KeywordTableSimpleRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableSimpleRetriever)ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ£€ç´¢å…³é”®å­—\n",
    "  - [`KeywordTableRAKERetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableRAKERetriever)ï¼šä½¿ç”¨[`RAKE`](https://pypi.org/project/rake-nltk/)ç®—æ³•æå–æ£€ç´¢å…³é”®å­—ï¼ˆæœ‰è¯­è¨€é™åˆ¶ï¼‰\n",
    "\n",
    "- RAG-Fusion [`QueryFusionRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/query_fusion/)\n",
    "\n",
    "- è¿˜æ”¯æŒ [KnowledgeGraph](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/knowledge_graph/)ã€[SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.SQLRetriever)ã€[Text-to-SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.NLSQLRetriever) ç­‰ç­‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53e99b-2ab5-4520-ba96-4a9979a94480",
   "metadata": {},
   "source": [
    "### 5.3ã€æ£€ç´¢åå¤„ç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c53c7c-9077-42bc-a5c0-832688b352b8",
   "metadata": {},
   "source": [
    "LlamaIndex çš„ `Node Postprocessors` æä¾›äº†ä¸€ç³»åˆ—æ£€ç´¢åå¤„ç†æ¨¡å—ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼šæˆ‘ä»¬å¯ä»¥ç”¨ä¸åŒæ¨¡å‹å¯¹æ£€ç´¢åçš„ `Nodes` åšé‡æ’åº\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7176f29c-be6b-491c-b2e8-6e604ad201b4",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T11:05:00.064348Z",
     "start_time": "2025-05-20T11:04:59.823619Z"
    }
   },
   "source": [
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# æ£€ç´¢\n",
    "nodes = vector_retriever.retrieve(\"deepseek v3æœ‰å¤šå°‘å‚æ•°?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] performance on\n",
      "math-related benchmarks among all non-long-CoT open-source and closed-source models.\n",
      "Notably, it even outperforms o1-preview on specific benchmarks, such as MATH-500,\n",
      "demonstrating its robust mathematical reasoning capabilities. (2) On coding-related tasks,\n",
      "DeepSeek-V3 emerges as the top-performing model for coding competition benchmarks,\n",
      "such as LiveCodeBench, solidifying its position as the leading model in this domain. For\n",
      "engineering-related tasks, while DeepSeek-V3 performs slightly below Claude-Sonnet-3.5,\n",
      "it still outpaces all other models by a significant margin, demonstrating its competitiveness\n",
      "across diverse technical benchmarks.\n",
      "In the remainder of this paper, we first present a detailed exposition of our DeepSeek-V3\n",
      "model architecture (Section 2). Subsequently, we introduce our infrastructures, encompassing\n",
      "our compute clusters, the training framework, the support for FP8 training, the inference\n",
      "deployment strategy, and our suggestions on future hardware design. Next, we describe our\n",
      "pre-training process, including the construction of training data, hyper-parameter settings, long-\n",
      "context extension techniques, the associated evaluations, as well as some discussions (Section 4).\n",
      "Thereafter, we discuss our efforts on post-training, which include Supervised Fine-Tuning (SFT),\n",
      "Reinforcement Learning (RL), the corresponding evaluations, and discussions (Section 5). Lastly,\n",
      "we conclude this work, discuss existing limitations of DeepSeek-V3, and propose potential\n",
      "directions for future research (Section 6).\n",
      "2. Architecture\n",
      "We first introduce the basic architecture of DeepSeek-V3, featured by Multi-head Latent Atten-\n",
      "tion (MLA) (DeepSeek-AI, 2024c) for efficient inference and DeepSeekMoE (Dai et al., 2024)\n",
      "for economical training. Then, we present a Multi-Token Prediction (MTP) training objective,\n",
      "which we have observed to enhance the overall performance on evaluation benchmarks. For\n",
      "other minor details not explicitly mentioned, DeepSeek-V3 adheres to the settings of DeepSeek-\n",
      "V2 (DeepSeek-AI, 2024c).\n",
      "2.1. Basic Architecture\n",
      "The basic architecture of\n",
      "\n",
      "[1] on post-training, which include Supervised Fine-Tuning (SFT),\n",
      "Reinforcement Learning (RL), the corresponding evaluations, and discussions (Section 5). Lastly,\n",
      "we conclude this work, discuss existing limitations of DeepSeek-V3, and propose potential\n",
      "directions for future research (Section 6).\n",
      "2. Architecture\n",
      "We first introduce the basic architecture of DeepSeek-V3, featured by Multi-head Latent Atten-\n",
      "tion (MLA) (DeepSeek-AI, 2024c) for efficient inference and DeepSeekMoE (Dai et al., 2024)\n",
      "for economical training. Then, we present a Multi-Token Prediction (MTP) training objective,\n",
      "which we have observed to enhance the overall performance on evaluation benchmarks. For\n",
      "other minor details not explicitly mentioned, DeepSeek-V3 adheres to the settings of DeepSeek-\n",
      "V2 (DeepSeek-AI, 2024c).\n",
      "2.1. Basic Architecture\n",
      "The basic architecture of DeepSeek-V3 is still within the Transformer (Vaswani et al., 2017)\n",
      "framework. For efficient inference and economical training, DeepSeek-V3 also adopts MLA\n",
      "and DeepSeekMoE, which have been thoroughly validated by DeepSeek-V2. Compared with\n",
      "DeepSeek-V2, an exception is that we additionally introduce an auxiliary-loss-free load balancing\n",
      "6\n",
      "\n",
      "[2] verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its\n",
      "reasoning performance. Meanwhile, we also maintain control over the output style and\n",
      "length of DeepSeek-V3.\n",
      "Summary of Core Evaluation Results\n",
      "â€¢ Knowledge: (1) On educational benchmarks such as MMLU, MMLU-Pro, and GPQA,\n",
      "DeepSeek-V3 outperforms all other open-source models, achieving 88.5 on MMLU, 75.9\n",
      "on MMLU-Pro, and 59.1 on GPQA. Its performance is comparable to leading closed-source\n",
      "models like GPT-4o and Claude-Sonnet-3.5, narrowing the gap between open-source\n",
      "and closed-source models in this domain. (2) For factuality benchmarks, DeepSeek-V3\n",
      "demonstrates superior performance among open-source models on both SimpleQA and\n",
      "Chinese SimpleQA. While it trails behind GPT-4o and Claude-Sonnet-3.5 in English factual\n",
      "knowledge (SimpleQA), it surpasses these models in Chinese factual knowledge (Chinese\n",
      "SimpleQA), highlighting its strength in Chinese factual knowledge.\n",
      "â€¢ Code, Math, and Reasoning: (1) DeepSeek-V3 achieves state-of-the-art performance on\n",
      "math-related benchmarks among all non-long-CoT open-source and closed-source models.\n",
      "Notably, it even outperforms o1-preview on specific benchmarks, such as MATH-500,\n",
      "demonstrating its robust mathematical reasoning capabilities. (2) On coding-related tasks,\n",
      "DeepSeek-V3 emerges as the top-performing model for coding competition benchmarks,\n",
      "such as LiveCodeBench, solidifying its position as the leading model in this domain. For\n",
      "engineering-related tasks, while DeepSeek-V3 performs slightly below Claude-Sonnet-3.5,\n",
      "it still outpaces all other models by a significant margin, demonstrating its competitiveness\n",
      "across diverse technical benchmarks.\n",
      "In the remainder of this paper, we first present a detailed exposition of our DeepSeek-V3\n",
      "model architecture (Section 2). Subsequently, we introduce our infrastructures, encompassing\n",
      "our compute clusters, the training framework, the support for FP8 training, the inference\n",
      "deployment\n",
      "\n",
      "[3] DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100Accuracy / Percentile (%)\n",
      "75.9\n",
      "59.1\n",
      "90.2\n",
      "39.2\n",
      "51.6\n",
      "42.0\n",
      "66.2\n",
      "41.3\n",
      "74.7\n",
      "16.7\n",
      "35.6\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3 24.8 23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n",
      "\n",
      "[4] costly tensor parallelism.\n",
      "Combining these efforts, we achieve high training efficiency.\n",
      "During pre-training, we train DeepSeek-V3 on 14.8T high-quality and diverse tokens. The\n",
      "pre-training process is remarkably stable. Throughout the entire training process, we did not\n",
      "encounter any irrecoverable loss spikes or have to roll back. Next, we conduct a two-stage\n",
      "context length extension for DeepSeek-V3. In the first stage, the maximum context length is\n",
      "extended to 32K, and in the second stage, it is further extended to 128K. Following this, we\n",
      "conduct post-training, including Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL)\n",
      "on the base model of DeepSeek-V3, to align it with human preferences and further unlock its\n",
      "potential. During the post-training stage, we distill the reasoning capability from the DeepSeek-\n",
      "R1 series of models, and meanwhile carefully maintain the balance between model accuracy\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "65bae2b4-7c36-44fa-9566-0d1b3f34972a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:07:57.022093Z",
     "start_time": "2025-05-20T11:07:50.226186Z"
    }
   },
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "# é‡æ’åºï¼ˆé»˜è®¤ä½¿ç”¨ Settings.llm çš„æ¨¡å‹ï¼‰\n",
    "postprocessor = LLMRerank(top_n=2)\n",
    "\n",
    "nodes = postprocessor.postprocess_nodes(nodes, query_str=\"deepseek v3æœ‰å¤šå°‘å‚æ•°?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] DeepSeek-V3 Technical Report\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
      "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
      "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architec-\n",
      "tures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
      "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
      "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
      "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
      "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
      "other open-source models and achieves performance comparable to leading closed-source\n",
      "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
      "for its full training. In addition, its training process is remarkably stable. Throughout the entire\n",
      "training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.\n",
      "The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.\n",
      "MMLU-Pro\n",
      "(EM)\n",
      "GPQA-Diamond\n",
      "(Pass@1)\n",
      "MATH 500\n",
      "(EM)\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100Accuracy / Percentile (%)\n",
      "75.9\n",
      "59.1\n",
      "90.2\n",
      "39.2\n",
      "51.6\n",
      "42.0\n",
      "66.2\n",
      "41.3\n",
      "74.7\n",
      "16.7\n",
      "35.6\n",
      "22.6\n",
      "71.6\n",
      "49.0\n",
      "80.0\n",
      "23.3 24.8 23.8\n",
      "73.3\n",
      "51.1\n",
      "73.8\n",
      "23.3\n",
      "25.3\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "69ca41ea-3112-491a-a1a1-5ec8db295b61",
   "metadata": {},
   "source": "æ›´å¤šçš„ Rerank åŠå…¶å®ƒåå¤„ç†æ–¹æ³•ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[Node Postprocessor Modules](https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/node_postprocessors/#llm-rerank)\n"
  },
  {
   "cell_type": "markdown",
   "id": "392d8d69-cd42-445c-a0cd-0dd7c66d07bc",
   "metadata": {},
   "source": [
    "## 6. ç”Ÿæˆå›å¤ï¼ˆQA & Chatï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4248c1-602c-4df6-bd6a-72e994faf1ed",
   "metadata": {},
   "source": [
    "### 6.1 å•è½®é—®ç­”ï¼ˆQuery Engineï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "261d35c3-8b54-4840-ab88-c04b348b0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3åœ¨æ•°å­¦ç›¸å…³åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨éé•¿é“¾æ€ç»´å¼€æ”¾æºç å’Œé—­æºæ¨¡å‹ä¸­å¤„äºé¢†å…ˆåœ°ä½ã€‚å®ƒåœ¨æŸäº›ç‰¹å®šçš„åŸºå‡†æµ‹è¯•å¦‚MATH-500ä¸Šç”šè‡³è¶…è¿‡äº†o1-previewï¼Œè¿™è¡¨æ˜å®ƒå…·æœ‰å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\n"
     ]
    }
   ],
   "source": [
    "qa_engine = index.as_query_engine()\n",
    "response = qa_engine.query(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d55521-5b67-4c26-a8de-440d2e1046a7",
   "metadata": {},
   "source": [
    "#### æµå¼è¾“å‡º\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1817400e-9311-4161-89e4-507267862524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T11:43:06.068002Z",
     "start_time": "2025-05-20T11:43:00.262222Z"
    }
   },
   "source": [
    "qa_engine = index.as_query_engine(streaming=True)\n",
    "response = qa_engine.query(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·?\")\n",
    "response.print_response_stream()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3åœ¨æ•°å­¦ç›¸å…³åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨éé•¿é“¾æ€ç»´å¼€æ”¾æºç å’Œé—­æºæ¨¡å‹ä¸­å¤„äºé¢†å…ˆåœ°ä½ã€‚å®ƒåœ¨æŸäº›ç‰¹å®šçš„åŸºå‡†æµ‹è¯•å¦‚MATH-500ä¸Šç”šè‡³è¶…è¿‡äº†o1-previewï¼Œè¿™è¡¨æ˜å®ƒå…·æœ‰å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "1cf53205-beb2-4571-81aa-c5f8e12142f5",
   "metadata": {},
   "source": [
    "### 6.2 å¤šè½®å¯¹è¯ï¼ˆChat Engineï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "81a73a48-469e-4d40-adf3-e0e5ec44305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:08:35.550281Z",
     "start_time": "2025-05-20T12:08:23.893960Z"
    }
   },
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·?\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3åœ¨æ•°å­¦ç›¸å…³åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨éé•¿é“¾æ€ç»´å¼€æ”¾æºç å’Œé—­æºæ¨¡å‹ä¸­å¤„äºé¢†å…ˆåœ°ä½ã€‚å®ƒåœ¨æŸäº›ç‰¹å®šçš„åŸºå‡†æµ‹è¯•å¦‚MATH-500ä¸Šç”šè‡³è¶…è¿‡äº†o1-previewï¼Œè¿™è¡¨æ˜å®ƒå…·æœ‰å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "712c8c71-6420-4c6f-821c-1bd1c31dc8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:08:53.438144Z",
     "start_time": "2025-05-20T12:08:38.464218Z"
    }
   },
   "source": [
    "response = chat_engine.chat(\"ä»£ç èƒ½åŠ›å‘¢?\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3åœ¨ç¼–ç ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼–ç¨‹ç«èµ›åŸºå‡†æµ‹è¯•å¦‚LiveCodeBenchä¸­ï¼Œå®ƒæˆä¸ºäº†è¡¨ç°æœ€å¥½çš„æ¨¡å‹ã€‚å¯¹äºå·¥ç¨‹ç›¸å…³çš„ä»»åŠ¡ï¼Œè™½ç„¶DeepSeek-V3çš„è¡¨ç°ç•¥ä½äºClaude-Sonnet-3.5ï¼Œä½†å®ƒä»ç„¶æ˜¾è‘—ä¼˜äºå…¶ä»–æ‰€æœ‰æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å¤šç§æŠ€æœ¯åŸºå‡†æµ‹è¯•ä¸­çš„ç«äº‰åŠ›ã€‚\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "3094d188-2241-4995-9704-1d2aeb878e1e",
   "metadata": {},
   "source": [
    "#### æµå¼è¾“å‡º\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf33effa-ad36-4eea-b1d1-926ca5cc8dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:09:32.341526Z",
     "start_time": "2025-05-20T12:09:23.522135Z"
    }
   },
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "streaming_response = chat_engine.stream_chat(\"deepseek v3æ•°å­¦èƒ½åŠ›æ€ä¹ˆæ ·?\")\n",
    "# streaming_response.print_response_stream()\n",
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\", flush=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-V3åœ¨æ•°å­¦ç›¸å…³åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨éé•¿é“¾æ€ç»´å¼€æ”¾æºç å’Œé—­æºæ¨¡å‹ä¸­å¤„äºé¢†å…ˆåœ°ä½ã€‚å®ƒåœ¨æŸäº›ç‰¹å®šçš„åŸºå‡†æµ‹è¯•å¦‚MATH-500ä¸Šç”šè‡³è¶…è¿‡äº†o1-previewçš„è¡¨ç°ï¼Œè¿™è¯æ˜äº†å…¶å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "d7eb76fa-e4ba-4c47-9785-53eadddf478e",
   "metadata": {},
   "source": [
    "## 7. åº•å±‚æ¥å£ï¼šPromptã€LLM ä¸ Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cce84-9f79-41ef-a6c4-caaeb70d029e",
   "metadata": {},
   "source": [
    "### 7.1 Prompt æ¨¡æ¿\n",
    "\n",
    "#### `PromptTemplate` å®šä¹‰æç¤ºè¯æ¨¡æ¿\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41358d83-4fcb-430c-9c2e-c1ac0839cbfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:09:38.963796Z",
     "start_time": "2025-05-20T12:09:38.961215Z"
    }
   },
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\"å†™ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯\")\n",
    "\n",
    "prompt.format(topic=\"å°æ˜\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å†™ä¸€ä¸ªå…³äºå°æ˜çš„ç¬‘è¯'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "a4a94232-e8d5-4bf2-8751-8851d924fcee",
   "metadata": {},
   "source": [
    "#### `ChatPromptTemplate` å®šä¹‰å¤šè½®æ¶ˆæ¯æ¨¡æ¿\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "edb05592-835f-4cb2-bfa0-862796c36fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T12:13:15.467114Z",
     "start_time": "2025-05-20T12:13:15.464456Z"
    }
   },
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"ä½ å«{name}ï¼Œä½ å¿…é¡»æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER, \n",
    "        content=(\n",
    "            \"å·²çŸ¥ä¸Šä¸‹æ–‡ï¼š\\n\" \\\n",
    "            \"{context}\\n\\n\" \\\n",
    "            \"é—®é¢˜ï¼š{question}\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "print(\n",
    "    text_qa_template.format(\n",
    "        name=\"å°æ˜\",\n",
    "        context=\"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\",\n",
    "        question=\"è¿™æ˜¯ä»€ä¹ˆ\"\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: ä½ å«å°æ˜ï¼Œä½ å¿…é¡»æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n",
      "user: å·²çŸ¥ä¸Šä¸‹æ–‡ï¼š\n",
      "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\n",
      "\n",
      "é—®é¢˜ï¼šè¿™æ˜¯ä»€ä¹ˆ\n",
      "assistant: \n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "c98931d9-f411-4433-9900-649f74a40b6e",
   "metadata": {},
   "source": [
    "### 7.2 è¯­è¨€æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1febbfc2-06c1-4692-9ac1-8843e5554098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d3842-32ff-4510-9853-47e7282b56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(prompt.format(topic=\"å°æ˜\"))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cbe1cc-9dfc-4274-8cdd-b4dd6d3eb5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = llm.complete(\n",
    "    text_qa_template.format(\n",
    "        name=\"å°æ˜\",\n",
    "        context=\"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\",\n",
    "        question=\"ä½ æ˜¯è°ï¼Œæˆ‘ä»¬åœ¨å¹²å˜›\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234c43f-d46c-4755-afb3-ade10c308bf8",
   "metadata": {},
   "source": [
    "#### è¿æ¥DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92e176-6153-4059-a01b-e2957a052a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-llms-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "id": "511a86bd-c5eb-45e7-8e0a-7e56b2fe7f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T16:39:04.405029Z",
     "start_time": "2025-05-20T16:38:54.788557Z"
    }
   },
   "source": [
    "import os\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "llm = DeepSeek(model=\"deepseek-chat\", api_key=os.getenv(\"DEEPSEEK_API_KEY\"), temperature=1.5)\n",
    "\n",
    "response = llm.complete(\"å†™ä¸ªç¬‘è¯\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ŠAIçš„çƒ¦æ¼ã€‹  \n",
      "\n",
      "ç¨‹åºå‘˜ç»™AIå¸ƒç½®æ–°ä»»åŠ¡ï¼šâ€œå†™ä¸ªç¬‘è¯ï¼Œè¦è®©äººç¬‘åˆ°ä»£ç éƒ½ä¹±äº†ã€‚â€  \n",
      "\n",
      "AIè®¤çœŸæ£€ç´¢äº†8TBçš„å¹½é»˜æ•°æ®åº“ï¼Œè¾“å‡ºäº†30é¡µçš„ã€Šäººç±»ç¬‘ç‚¹è¡Œä¸ºåˆ†ææŠ¥å‘Šã€‹ã€‚  \n",
      "\n",
      "ç¨‹åºå‘˜å¹æ°”ï¼šâ€œç®—äº†ï¼Œè¿˜æ˜¯æˆ‘è‡ªå·±è®²å§â€¦â€¦â€˜ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»åˆ†ä¸æ¸…ä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ï¼Ÿâ€™â€  \n",
      "\n",
      "AIç«‹åˆ»æŠ¢ç­”ï¼šâ€œå› ä¸ºOct 31 == Dec 25ï¼ï¼ˆå…«è¿›åˆ¶31ç­‰äºåè¿›åˆ¶25ï¼‰â€  \n",
      "\n",
      "ç¨‹åºå‘˜æ²‰é»˜ä¸¤ç§’ï¼Œçªç„¶æŠŠé”®ç›˜ä¸€æ¨ï¼šâ€œè¿™æ‰æ˜¯çœŸææ€–æ•…äº‹â€”â€”ä½ è¿è°éŸ³æ¢—éƒ½å­¦ä¼šäº†ï¼â€\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "2f49f6da-d220-4c36-b697-e3b525902af7",
   "metadata": {},
   "source": [
    "#### è®¾ç½®å…¨å±€ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94943bec-563c-44b5-80bb-9c0a7c05382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", api_key=os.getenv(\"DEEPSEEK_API_KEY\"), temperature=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd7b76-2594-4c39-8e81-33e3c985df38",
   "metadata": {},
   "source": [
    "é™¤ OpenAI å¤–ï¼ŒLlamaIndex å·²é›†æˆå¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬äº‘æœåŠ¡ API å’Œæœ¬åœ°éƒ¨ç½² APIï¼Œè¯¦è§å®˜æ–¹æ–‡æ¡£ï¼š[Available LLM integrations](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110fc0b-ec6c-445b-a3c2-3ddef41d9589",
   "metadata": {},
   "source": [
    "### 7.3 Embedding æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5be1257-eb1a-4e2d-bad9-2cd002841093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# å…¨å±€è®¾å®š\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb025ce6-c065-4cf2-9e9d-5a01f04c26ee",
   "metadata": {},
   "source": [
    "LlamaIndex åŒæ ·é›†æˆäº†å¤šç§ Embedding æ¨¡å‹ï¼ŒåŒ…æ‹¬äº‘æœåŠ¡ API å’Œå¼€æºæ¨¡å‹ï¼ˆHuggingFaceï¼‰ç­‰ï¼Œè¯¦è§[å®˜æ–¹æ–‡æ¡£](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/)ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91aa7d-6f3a-4387-859c-c7357d7c5d15",
   "metadata": {},
   "source": [
    "## 8. åŸºäº LlamaIndex å®ç°ä¸€ä¸ªåŠŸèƒ½è¾ƒå®Œæ•´çš„ RAG ç³»ç»Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1b844-605e-4be2-9cae-2e9e56e46b40",
   "metadata": {},
   "source": [
    "åŠŸèƒ½è¦æ±‚ï¼š\n",
    "\n",
    "- åŠ è½½æŒ‡å®šç›®å½•çš„æ–‡ä»¶\n",
    "- æ”¯æŒ RAG-Fusion\n",
    "- ä½¿ç”¨ Qdrant å‘é‡æ•°æ®åº“ï¼Œå¹¶æŒä¹…åŒ–åˆ°æœ¬åœ°\n",
    "- æ”¯æŒæ£€ç´¢åæ’åº\n",
    "- æ”¯æŒå¤šè½®å¯¹è¯\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "90348baf-3a5e-4cc4-968d-e90f9d315495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T16:35:21.664172Z",
     "start_time": "2025-05-20T16:35:21.654026Z"
    }
   },
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "EMBEDDING_DIM = 1536\n",
    "COLLECTION_NAME = \"full_demo\"\n",
    "PATH = \"./qdrant_db\"\n",
    "\n",
    "client = QdrantClient(path=PATH)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "cf485f1b-7da4-412e-a121-a7e6b5f3ece9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T17:38:31.798836Z",
     "start_time": "2025-05-20T17:38:29.738317Z"
    }
   },
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.postprocessor import LLMRerank, SimilarityPostprocessor\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.llms.dashscope import DashScope, DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "\n",
    "# 1. æŒ‡å®šå…¨å±€llmä¸embeddingæ¨¡å‹\n",
    "Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX,api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "Settings.embed_model = DashScopeEmbedding(model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1)\n",
    "\n",
    "# 2. æŒ‡å®šå…¨å±€æ–‡æ¡£å¤„ç†çš„ Ingestion Pipeline\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=512, chunk_overlap=200)]\n",
    "\n",
    "# 3. åŠ è½½æœ¬åœ°æ–‡æ¡£\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "# 4. åˆ›å»º collection\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# 5. åˆ›å»º Vector Store\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "\n",
    "# 6. æŒ‡å®š Vector Store çš„ Storage ç”¨äº index\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 7. å®šä¹‰æ£€ç´¢åæ’åºæ¨¡å‹\n",
    "reranker = LLMRerank(top_n=2)\n",
    "# æœ€ç»ˆæ‰“åˆ†ä½äº 0.6 çš„æ–‡æ¡£è¢«è¿‡æ»¤æ‰\n",
    "sp = SimilarityPostprocessor(similarity_cutoff=0.6)\n",
    "\n",
    "# 8. å®šä¹‰ RAG Fusion æ£€ç´¢å™¨ï¼ˆæŸ¥è¯¢æ”¹å†™ï¼‰\n",
    "fusion_retriever = QueryFusionRetriever(\n",
    "    [index.as_retriever()],\n",
    "    similarity_top_k=5, # æ£€ç´¢å¬å› top k ç»“æœ\n",
    "    num_queries=3,  # ç”Ÿæˆ query æ•°\n",
    "    use_async=False,\n",
    "    # query_gen_prompt=\"\",  # å¯ä»¥è‡ªå®šä¹‰ query ç”Ÿæˆçš„ prompt æ¨¡æ¿\n",
    ")\n",
    "\n",
    "# 9. æ„å»ºå•è½® query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    fusion_retriever,\n",
    "    node_postprocessors=[reranker, sp],\n",
    "    response_synthesizer=get_response_synthesizer(\n",
    "        response_mode = ResponseMode.REFINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# 10. å¯¹è¯å¼•æ“\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine, \n",
    "    # condense_question_prompt=\"\" # å¯ä»¥è‡ªå®šä¹‰ chat message prompt æ¨¡æ¿\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mllama_index\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01membeddings\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdashscope\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DashScopeEmbedding, DashScopeTextEmbeddingModels\n\u001B[32m     15\u001B[39m \u001B[38;5;66;03m# 1. æŒ‡å®šå…¨å±€llmä¸embeddingæ¨¡å‹\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m Settings.llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX,api_key=\u001B[43mos\u001B[49m.getenv(\u001B[33m\"\u001B[39m\u001B[33mDASHSCOPE_API_KEY\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     17\u001B[39m Settings.embed_model = DashScopeEmbedding(model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1)\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# 2. æŒ‡å®šå…¨å±€æ–‡æ¡£å¤„ç†çš„ Ingestion Pipeline\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'os' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "0124ef05-eb4b-417b-aa56-7128460162dd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T17:06:47.193410Z",
     "start_time": "2025-05-20T17:06:21.305429Z"
    }
   },
   "source": [
    "from llama_index.core.schema import MetadataMode, QueryBundle\n",
    "\n",
    "# æµ‹è¯•å¤šè½®å¯¹è¯\n",
    "# User: deepseek v3æœ‰å¤šå°‘å‚æ•°\n",
    "# User: æ¯æ¬¡æ¿€æ´»å¤šå°‘\n",
    "while True:\n",
    "    question=input(\"User:\")\n",
    "    if question.strip() == \"q\":\n",
    "        break\n",
    "    # ç°å®æ–‡æ¡£æ¥æº\n",
    "    # contexts = query_engine.retrieve(QueryBundle(question))\n",
    "    # print('-' * 10 + 'ref' + '-' * 10)\n",
    "    # for i, context in enumerate(contexts):\n",
    "    #     print('#' * 10 + f'chunk {i} start' + '#' * 10)\n",
    "    #     content = context.node.get_content(metadata_mode=MetadataMode.LLM)\n",
    "    #     print(content)\n",
    "    #     print('#' * 10 + f'chunk {i} end' + '#' * 10)\n",
    "    # print('-' * 10 + 'ref' + '-' * 10)\n",
    "    response = chat_engine.chat(question)\n",
    "    print(f\"AI: {response}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: DeepSeek-V3 æ‹¥æœ‰æ€»è®¡671äº¿ä¸ªå‚æ•°ï¼Œæ¯ä¸ªä»¤ç‰Œæ¿€æ´»37äº¿ä¸ªå‚æ•°ã€‚\n",
      "AI: DeepSeek-V3æ¯æ¬¡ä»¤ç‰Œæ¿€æ´»370äº¿ä¸ªå‚æ•°ã€‚\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "741c79d5-5990-42ec-9c89-3e2eaa9b31ff",
   "metadata": {},
   "source": [
    "## 9. å·¥ä½œæµï¼ˆWorkflowï¼‰ç®€ä»‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071629c4-1cbd-456c-bc55-ab38e4bedc7c",
   "metadata": {},
   "source": [
    "å·¥ä½œæµé¡¾åæ€ä¹‰æ˜¯å¯¹ä¸€äº›åˆ—å·¥ä½œæ­¥éª¤çš„æŠ½è±¡ã€‚\n",
    "\n",
    "LlamaIndex çš„å·¥ä½œæµæ˜¯äº‹ä»¶ï¼ˆ`event`ï¼‰é©±åŠ¨çš„ï¼š\n",
    "\n",
    "- å·¥ä½œæµç”± `step` ç»„æˆ\n",
    "- æ¯ä¸ª `step` å¤„ç†ç‰¹å®šçš„äº‹ä»¶\n",
    "- `step` ä¹Ÿä¼šäº§ç”Ÿæ–°çš„äº‹ä»¶ï¼ˆäº¤ç”±åç»§çš„ `step` è¿›è¡Œå¤„ç†ï¼‰\n",
    "- ç›´åˆ°äº§ç”Ÿ `StopEvent` æ•´ä¸ªå·¥ä½œæµç»“æŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b8edc-2764-4f07-ad2e-1e8c549b8157",
   "metadata": {},
   "source": [
    "ä¸¾ä¸ªå…·ä½“çš„ä¾‹å­ï¼šç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®åº“ï¼Œæ•°æ®åº“ä¸­åŒ…å«å¤šå¼ è¡¨\n",
    "\n",
    "å·¥ä½œæµï¼š\n",
    "\n",
    "<img src=\"./assets/workflow.png\" alt=\"å·¥ä½œæµ\" width=\"1000\"/>\n",
    "\n",
    "åˆ†æ­¥è¯´æ˜ï¼š\n",
    "\n",
    "1. ç”¨æˆ·è¾“å…¥è‡ªç„¶è¯­è¨€æŸ¥è¯¢\n",
    "2. ç³»ç»Ÿå…ˆå»æ£€ç´¢è·ŸæŸ¥è¯¢ç›¸å…³çš„è¡¨\n",
    "3. æ ¹æ®è¡¨çš„ Schema è®©å¤§æ¨¡å‹ç”Ÿæˆ SQL\n",
    "4. ç”¨ç”Ÿæˆçš„ SQL æŸ¥è¯¢æ•°æ®åº“\n",
    "5. æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be28368-98b7-4dcf-8cca-a05f443cb66b",
   "metadata": {},
   "source": [
    "### 9.1 æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7487c6-f529-4987-b069-1e96d20303ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è½½ WikiTableQuestions\n",
    "# WikiTableQuestions æ˜¯ä¸€ä¸ªä¸ºè¡¨æ ¼é—®ç­”è®¾è®¡çš„æ•°æ®é›†ã€‚å…¶ä¸­åŒ…å« 2,108 ä¸ªä»ç»´åŸºç™¾ç§‘æå–çš„ HTML è¡¨æ ¼\n",
    "\n",
    "# !wget \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\" -O wiki_data.zip\n",
    "# !unzip wiki_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7dfdbf-c064-4575-b59e-6562e86aff21",
   "metadata": {},
   "source": [
    "1. éå†ç›®å½•åŠ è½½è¡¨æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd4661dd-856a-4476-b771-1164fecadf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: WikiTableQuestions\\csv\\200-csv\\0.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\1.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\10.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\11.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\12.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\14.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\15.csv\n",
      "Error parsing WikiTableQuestions\\csv\\200-csv\\15.csv: Error tokenizing data. C error: Expected 4 fields in line 16, saw 5\n",
      "\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\17.csv\n",
      "Error parsing WikiTableQuestions\\csv\\200-csv\\17.csv: Error tokenizing data. C error: Expected 6 fields in line 5, saw 7\n",
      "\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\18.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\20.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\22.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\24.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\25.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\26.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\28.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\29.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\3.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\30.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\31.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\32.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\33.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\34.csv\n",
      "Error parsing WikiTableQuestions\\csv\\200-csv\\34.csv: Error tokenizing data. C error: Expected 4 fields in line 6, saw 13\n",
      "\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\35.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\36.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\37.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\38.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\4.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\41.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\42.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\44.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\45.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\46.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\47.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\48.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\7.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\8.csv\n",
      "processing file: WikiTableQuestions\\csv\\200-csv\\9.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"./WikiTableQuestions/csv/200-csv\")\n",
    "csv_files = sorted([f for f in data_dir.glob(\"*.csv\")])\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    print(f\"processing file: {csv_file}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {csv_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e7eef-d81a-4dd2-bcfd-1fb5dd89603a",
   "metadata": {},
   "source": [
    "2. ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆä¸€æ®µæ–‡å­—è¡¨è¿°ï¼ˆç”¨äºæ£€ç´¢ï¼‰ï¼Œä¿å­˜åœ¨ `WikiTableQuestions_TableInfo` ç›®å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25c1a118-6f5e-470a-bb02-54fd5f1497ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "\n",
    "class TableInfo(BaseModel):\n",
    "    \"\"\"Information regarding a structured table.\"\"\"\n",
    "\n",
    "    table_name: str = Field(\n",
    "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
    "    )\n",
    "    table_summary: str = Field(\n",
    "        ..., description=\"short, concise summary/caption of the table\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt_str = \"\"\"\\\n",
    "Give me a summary of the table with the following JSON format.\n",
    "\n",
    "- The table name must be unique to the table and describe it while being concise. \n",
    "- Do NOT output a generic table name (e.g. table, my_table).\n",
    "\n",
    "Do NOT make the table name one of the following: {exclude_table_name_list}\n",
    "\n",
    "Table:\n",
    "{table_str}\n",
    "\n",
    "Summary: \"\"\"\n",
    "prompt_tmpl = ChatPromptTemplate(\n",
    "    message_templates=[ChatMessage.from_str(prompt_str, role=\"user\")]\n",
    ")\n",
    "\n",
    "llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aaded9f-4af5-4ab9-b994-374ac420bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableinfo_dir = \"WikiTableQuestions_TableInfo\"\n",
    "# !mkdir {tableinfo_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e4bf4ce-f969-45a2-b705-adc23a0c1cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def _get_tableinfo_with_index(idx: int) -> str:\n",
    "    results_gen = Path(tableinfo_dir).glob(f\"{idx}_*\")\n",
    "    results_list = list(results_gen)\n",
    "    if len(results_list) == 0:\n",
    "        return None\n",
    "    elif len(results_list) == 1:\n",
    "        path = results_list[0]\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file) \n",
    "            return TableInfo.model_validate(data)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"More than one file matching index: {list(results_gen)}\"\n",
    "        )\n",
    "    \n",
    "\n",
    "table_names = set()\n",
    "table_infos = []\n",
    "for idx, df in enumerate(dfs):\n",
    "    table_info = _get_tableinfo_with_index(idx)\n",
    "    if table_info:\n",
    "        table_infos.append(table_info)\n",
    "    else:\n",
    "        while True:\n",
    "            df_str = df.head(10).to_csv()\n",
    "            table_info = llm.structured_predict(\n",
    "                TableInfo,\n",
    "                prompt_tmpl,\n",
    "                table_str=df_str,\n",
    "                exclude_table_name_list=str(list(table_names)),\n",
    "            )\n",
    "            table_name = table_info.table_name\n",
    "            print(f\"Processed table: {table_name}\")\n",
    "            if table_name not in table_names:\n",
    "                table_names.add(table_name)\n",
    "                break\n",
    "            else:\n",
    "                # try again\n",
    "                print(f\"Table name {table_name} already exists, trying again.\")\n",
    "                pass\n",
    "\n",
    "        out_file = f\"{tableinfo_dir}/{idx}_{table_name}.json\"\n",
    "        json.dump(table_info.dict(), open(out_file, \"w\"))\n",
    "    table_infos.append(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73345b81-07ff-49b0-9ccd-ed553c195f93",
   "metadata": {},
   "source": [
    "3. å°†ä¸Šè¿°è¡¨æ ¼å­˜å…¥ SQLite æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09b6fd32-3255-4f2d-9962-eb9449f56565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table: progressive_rock_album_chart_positions\n",
      "Creating table: filmography_of_diane\n",
      "Creating table: annual_fatalities_and_accidents_statistics\n",
      "Creating table: academy_awards_1972_results\n",
      "Creating table: theatrical_award_nominations_and_wins\n",
      "Creating table: bad_boy_artists_album_release_summary\n",
      "Creating table: south_dakota_radio_stations\n",
      "Creating table: missing_persons_case_summary_1982\n",
      "Creating table: chart_performance_of_singles\n",
      "Creating table: kodachrome_film_types_and_dates\n",
      "Creating table: bbc_radio_service_costs_2012_2013\n",
      "Creating table: french_airports_usage_summary\n",
      "Creating table: voter_registration_summary_by_party\n",
      "Creating table: norwegian_club_performance_statistics\n",
      "Creating table: triple_crown_winners_history\n",
      "Creating table: grammy_awards_summary_for_artist\n",
      "Creating table: boxing_fight_results_history\n",
      "Creating table: historical_sports_team_performance\n",
      "Creating table: yamato_population_density_summary\n",
      "Creating table: voter_registration_summary_by_party_distribution\n",
      "Creating table: best_actress_award_nominations_and_wins\n",
      "Creating table: uk_ministerial_positions_and_titles_history\n",
      "Creating table: municipality_merger_summary\n",
      "Creating table: euro_2020_group_stage_results\n",
      "Creating table: binary_encoding_probabilities\n",
      "Creating table: monthly_climate_statistics\n",
      "Creating table: italian_government_term_history\n",
      "Creating table: new_mexico_government_officials\n",
      "Creating table: monthly_climate_statistics_summary\n",
      "Creating table: historical_rainfall_experiment_drops\n",
      "Creating table: monthly_weather_statistics\n",
      "Creating table: multilingual_greetings_and_phrases\n",
      "Creating table: ohio_private_schools_summary\n",
      "Creating table: cancer_related_genetic_factors\n"
     ]
    }
   ],
   "source": [
    "# put data into sqlite db\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(\n",
    "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
    "):\n",
    "    # Sanitize column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from DataFrame into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "# engine = create_engine(\"sqlite:///:memory:\")\n",
    "engine = create_engine(\"sqlite:///wiki_table_questions.db\")\n",
    "metadata_obj = MetaData()\n",
    "for idx, df in enumerate(dfs):\n",
    "    tableinfo = _get_tableinfo_with_index(idx)\n",
    "    print(f\"Creating table: {tableinfo.table_name}\")\n",
    "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6ab4f-7db7-47ef-ad8a-898b19540d56",
   "metadata": {},
   "source": [
    "### 9.2 æ„å»ºåŸºç¡€å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ebdd1-88e4-4e3e-b025-000890ac300e",
   "metadata": {},
   "source": [
    "1. åˆ›å»ºåŸºäºè¡¨çš„æè¿°çš„å‘é‡ç´¢å¼•\n",
    "\n",
    "- `ObjectIndex` æ˜¯ä¸€ä¸ª LlamaIndex å†…ç½®çš„æ¨¡å—ï¼Œé€šè¿‡ç´¢å¼• (Indexï¼‰æ£€ç´¢ä»»æ„ Python å¯¹è±¡\n",
    "- è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ `VectorStoreIndex` ä¹Ÿå°±æ˜¯å‘é‡æ£€ç´¢ï¼Œå¹¶é€šè¿‡ `SQLTableNodeMapping` å°†æ–‡æœ¬æè¿°çš„ `node` å’Œæ•°æ®åº“çš„è¡¨å½¢æˆæ˜ å°„\n",
    "- ç›¸å…³æ–‡æ¡£ï¼šhttps://docs.llamaindex.ai/en/stable/examples/objects/object_index/#the-objectindex-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49e12988-cc89-4618-b3f6-a6a038c3c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "\n",
    "sql_database = SQLDatabase(engine)\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
    "    for t in table_infos\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92b78b-0530-468d-90ec-309d1614d390",
   "metadata": {},
   "source": [
    "2. åˆ›å»º SQL æŸ¥è¯¢å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "948b8bee-2af6-4487-8b27-a2b2a5d7420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "\n",
    "sql_retriever = SQLRetriever(sql_database)\n",
    "\n",
    "\n",
    "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
    "    \"\"\"Get table context string.\"\"\"\n",
    "    context_strs = []\n",
    "    for table_schema_obj in table_schema_objs:\n",
    "        table_info = sql_database.get_single_table_info(\n",
    "            table_schema_obj.table_name\n",
    "        )\n",
    "        if table_schema_obj.context_str:\n",
    "            table_opt_context = \" The table description is: \"\n",
    "            table_opt_context += table_schema_obj.context_str\n",
    "            table_info += table_opt_context\n",
    "\n",
    "        context_strs.append(table_info)\n",
    "    return \"\\n\\n\".join(context_strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5bac2-4c10-4411-bcd1-d825727df41f",
   "metadata": {},
   "source": [
    "3. åˆ›å»º Text2SQL çš„æç¤ºè¯ï¼ˆç³»ç»Ÿé»˜è®¤æ¨¡æ¿ï¼‰ï¼Œå’Œè¾“å‡ºç»“æœè§£æå™¨ï¼ˆä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æŠ½å–SQLï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da0c9ea7-5aa5-4069-8baf-9ca62c9e278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use tables listed below.\n",
      "{schema}\n",
      "\n",
      "Question: {query_str}\n",
      "SQLQuery: \n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.llms import ChatResponse\n",
    "\n",
    "def parse_response_to_sql(chat_response: ChatResponse) -> str:\n",
    "    \"\"\"Parse response to SQL.\"\"\"\n",
    "    response = chat_response.message.content\n",
    "    sql_query_start = response.find(\"SQLQuery:\")\n",
    "    if sql_query_start != -1:\n",
    "        response = response[sql_query_start:]\n",
    "        # TODO: move to removeprefix after Python 3.9+\n",
    "        if response.startswith(\"SQLQuery:\"):\n",
    "            response = response[len(\"SQLQuery:\") :]\n",
    "    sql_result_start = response.find(\"SQLResult:\")\n",
    "    if sql_result_start != -1:\n",
    "        response = response[:sql_result_start]\n",
    "    return response.strip().strip(\"```\").strip()\n",
    "\n",
    "\n",
    "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
    "    dialect=engine.dialect.name\n",
    ")\n",
    "print(text2sql_prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c7cf0-1217-4d16-8196-2937411bbbed",
   "metadata": {},
   "source": [
    "4. åˆ›å»ºè‡ªç„¶è¯­è¨€å›å¤ç”Ÿæˆæ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1fbf506-9c46-44bd-9148-0712e4e835a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"SQL: {sql_query}\\n\"\n",
    "    \"SQL Response: {context_str}\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "response_synthesis_prompt = PromptTemplate(\n",
    "    response_synthesis_prompt_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f4b9121-7da6-496c-8506-48fee7d4ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cc672-bed9-45b6-a9cd-80d162f96fd1",
   "metadata": {},
   "source": [
    "### 9.3 å®šä¹‰å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5f9db-6dc7-4828-bd2b-1ff7d1e16abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    "    Context,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# äº‹ä»¶ï¼šæ‰¾åˆ°äº†æ•°æ®åº“ä¸­ç›¸å…³çš„è¡¨\n",
    "class TableRetrieveEvent(Event):\n",
    "    \"\"\"Result of running table retrieval.\"\"\"\n",
    "\n",
    "    table_context_str: str\n",
    "    query: str\n",
    "\n",
    "# äº‹ä»¶ï¼šæ–‡æœ¬è½¬ä¸ºäº† SQL\n",
    "class TextToSQLEvent(Event):\n",
    "    \"\"\"Text-to-SQL event.\"\"\"\n",
    "\n",
    "    sql: str\n",
    "    query: str\n",
    "\n",
    "\n",
    "class TextToSQLWorkflow1(Workflow):\n",
    "    \"\"\"Text-to-SQL Workflow that does query-time table retrieval.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obj_retriever,\n",
    "        text2sql_prompt,\n",
    "        sql_retriever,\n",
    "        response_synthesis_prompt,\n",
    "        llm,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.obj_retriever = obj_retriever\n",
    "        self.text2sql_prompt = text2sql_prompt\n",
    "        self.sql_retriever = sql_retriever\n",
    "        self.response_synthesis_prompt = response_synthesis_prompt\n",
    "        self.llm = llm\n",
    "\n",
    "    @step\n",
    "    def retrieve_tables(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> TableRetrieveEvent:\n",
    "        \"\"\"Retrieve tables.\"\"\"\n",
    "        table_schema_objs = self.obj_retriever.retrieve(ev.query)\n",
    "        table_context_str = get_table_context_str(table_schema_objs)\n",
    "        print(\"====\\n\"+table_context_str+\"\\n====\")\n",
    "        return TableRetrieveEvent(\n",
    "            table_context_str=table_context_str, query=ev.query\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    def generate_sql(\n",
    "        self, ctx: Context, ev: TableRetrieveEvent\n",
    "    ) -> TextToSQLEvent:\n",
    "        \"\"\"Generate SQL statement.\"\"\"\n",
    "        fmt_messages = self.text2sql_prompt.format_messages(\n",
    "            query_str=ev.query, schema=ev.table_context_str\n",
    "        )\n",
    "        chat_response = self.llm.chat(fmt_messages)\n",
    "        sql = parse_response_to_sql(chat_response)\n",
    "        print(\"====\\n\"+sql+\"\\n====\")\n",
    "        return TextToSQLEvent(sql=sql, query=ev.query)\n",
    "\n",
    "    @step\n",
    "    def generate_response(self, ctx: Context, ev: TextToSQLEvent) -> StopEvent:\n",
    "        \"\"\"Run SQL retrieval and generate response.\"\"\"\n",
    "        retrieved_rows = self.sql_retriever.retrieve(ev.sql)\n",
    "        print(\"====\\n\"+str(retrieved_rows)+\"\\n====\")\n",
    "        fmt_messages = self.response_synthesis_prompt.format_messages(\n",
    "            sql_query=ev.sql,\n",
    "            context_str=str(retrieved_rows),\n",
    "            query_str=ev.query,\n",
    "        )\n",
    "        chat_response = llm.chat(fmt_messages)\n",
    "        return StopEvent(result=chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b3060a2-20e4-4153-b3f9-6b91ed4d7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = TextToSQLWorkflow1(\n",
    "    obj_retriever,\n",
    "    text2sql_prompt,\n",
    "    sql_retriever,\n",
    "    response_synthesis_prompt,\n",
    "    llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ead701cd-c79d-4b48-8a20-9c2322140712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step retrieve_tables\n",
      "Step retrieve_tables produced event TableRetrieveEvent\n",
      "Running step generate_sql\n",
      "Step generate_sql produced event TextToSQLEvent\n",
      "Running step generate_response\n",
      "Step generate_response produced event StopEvent\n",
      "assistant: The Notorious B.I.G. was signed to Bad Boy in the year 1993.\n"
     ]
    }
   ],
   "source": [
    "response = workflow.run(\n",
    "    query=\"What was the year that The Notorious B.I.G was signed to Bad Boy?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b64fac-b8b8-4fad-8ecc-5a9431469706",
   "metadata": {},
   "source": [
    "### 9.4 å¯è§†åŒ–å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b370ab8-9c87-4baa-92ba-3e729a481857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-utils-workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "933d00bd-a602-4958-bed3-d1b530192895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.TextToSQLEvent'>\n",
      "<class '__main__.TableRetrieveEvent'>\n",
      "text_to_sql_table_retrieval.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(\n",
    "    TextToSQLWorkflow1, filename=\"text_to_sql_table_retrieval.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc8317-0cac-458b-9ee5-969e4b46442c",
   "metadata": {},
   "source": [
    "### 9.5 å·¥ä½œæµç®¡ç†æ¡†æ¶æ„ä¹‰æ˜¯ä»€ä¹ˆ\n",
    "\n",
    "æ€è€ƒä»¥ä¸‹æƒ…å†µï¼š\n",
    "\n",
    "- `step` çš„æ‰§è¡Œé¡ºåºæœ‰é€»è¾‘åˆ†æ”¯\n",
    "- `step` çš„æ‰§è¡Œæœ‰å¾ªç¯\n",
    "- `step` çš„æ‰§è¡Œå¯ä»¥å¹¶è¡Œ\n",
    "- ä¸€ä¸ª `step` çš„è§¦å‘æ¡ä»¶ä¾èµ–å‰é¢è‹¥å¹² `step` çš„ç»“æœï¼Œä¸”å®ƒä»¬ä¹‹é—´å¯èƒ½æœ‰å¾ªç¯æˆ–è€…å¹¶è¡Œ\n",
    "\n",
    "<img src=\"./assets/workflow2.png\" alt=\"å·¥ä½œæµä¸¾ä¾‹\" width=\"800\"/>\n",
    "\n",
    "æ‰€ä»¥ï¼Œå·¥ä½œæµç®¡ç†æ¡†æ¶çš„æ„æ€æ˜¯ä¾¿äºå°†å•ä¸ªäº‹ä»¶çš„å¤„ç†é€»è¾‘å’Œäº‹ä»¶ä¹‹é—´çš„æ‰§è¡Œé¡ºåºç‹¬ç«‹å¼€\n",
    "\n",
    "å…³äº LlamaIndex å·¥ä½œæµçš„æ›´è¯¦ç»†æ–‡æ¡£ï¼šhttps://docs.llamaindex.ai/en/stable/examples/workflow/workflows_cookbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c98c0-6636-4d71-9156-731e7ca28b6f",
   "metadata": {},
   "source": [
    "## 10. LlamaIndex çš„æ›´å¤šåŠŸèƒ½\n",
    "\n",
    "- æ™ºèƒ½ä½“ï¼ˆAgentï¼‰å¼€å‘æ¡†æ¶ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/\n",
    "- RAG çš„è¯„æµ‹ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/evaluating/\n",
    "- è¿‡ç¨‹ç›‘æ§ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/observability/\n",
    "\n",
    "ä»¥ä¸Šå†…å®¹æ¶‰åŠè¾ƒå¤šèƒŒæ™¯çŸ¥è¯†ï¼Œæš‚æ—¶ä¸åœ¨æœ¬è¯¾å±•å¼€ï¼Œç›¸å…³çŸ¥è¯†ä¼šåœ¨åé¢è¯¾ç¨‹ä¸­é€ä¸€è¯¦ç»†è®²è§£ã€‚\n",
    "\n",
    "æ­¤å¤–ï¼ŒLlamaIndex é’ˆå¯¹ç”Ÿäº§çº§çš„ RAG ç³»ç»Ÿä¸­é‡åˆ°çš„å„ä¸ªæ–¹é¢çš„ç»†èŠ‚é—®é¢˜ï¼Œæ€»ç»“äº†å¾ˆå¤šé«˜ç«¯æŠ€å·§ï¼ˆ[Advanced Topics](https://docs.llamaindex.ai/en/stable/optimizing/production_rag/)ï¼‰ï¼Œå¯¹å®æˆ˜å¾ˆæœ‰å‚è€ƒä»·å€¼ï¼Œéå¸¸æ¨èæœ‰èƒ½åŠ›çš„åŒå­¦é˜…è¯»ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9b8c6",
   "metadata": {},
   "source": [
    "## 11. å­¦ä¹ æ‰“å¡\n",
    "\n",
    "1. æŒæ¡ LlamaIndex æ¡†æ¶æ ¸å¿ƒæ¨¡å—\n",
    "2. ä½¿ç”¨ LlamaIndex é«˜æ•ˆå¼€å‘ä¸€ä¸ªè´´åˆè‡ªå·±éœ€æ±‚çš„RAGç³»ç»Ÿ\n",
    "3. ç†è§£ LlamaIndex ä¸­çš„å·¥ä½œæµå®ç°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
